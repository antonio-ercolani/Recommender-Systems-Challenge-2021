{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ec60ead",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-12-10T17:04:30.835552Z",
     "iopub.status.busy": "2021-12-10T17:04:30.834848Z",
     "iopub.status.idle": "2021-12-10T17:04:33.212226Z",
     "shell.execute_reply": "2021-12-10T17:04:33.211386Z",
     "shell.execute_reply.started": "2021-12-10T14:46:15.339044Z"
    },
    "papermill": {
     "duration": 2.405932,
     "end_time": "2021-12-10T17:04:33.212397",
     "exception": false,
     "start_time": "2021-12-10T17:04:30.806465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp -r ../input/d/romanofrancesco/recsys-repo/RecSys_Course_AT_PoliMi-master/* ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f6ff456",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-10T17:04:33.256206Z",
     "iopub.status.busy": "2021-12-10T17:04:33.255476Z",
     "iopub.status.idle": "2021-12-10T17:04:36.181879Z",
     "shell.execute_reply": "2021-12-10T17:04:36.181157Z",
     "shell.execute_reply.started": "2021-12-09T15:27:56.39209Z"
    },
    "papermill": {
     "duration": 2.951929,
     "end_time": "2021-12-10T17:04:36.182023",
     "exception": false,
     "start_time": "2021-12-10T17:04:33.230094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sps\n",
    "import matplotlib.pyplot as pyplot\n",
    "from Data_manager.split_functions.split_train_validation_random_holdout import split_train_in_two_percentage_global_sample\n",
    "\n",
    "URM_path = \"../input/recommender-system-2021-challenge-polimi/data_train.csv\"\n",
    "URM_all_dataframe = pd.read_csv(filepath_or_buffer=URM_path, \n",
    "                                sep=\",\",\n",
    "                                dtype={0:int, 1:int, 2:float},\n",
    "                                header=0)\n",
    "URM_all_dataframe.columns = [\"UserID\", \"ItemID\", \"Interaction\"]\n",
    "\n",
    "userID_unique = URM_all_dataframe[\"UserID\"].unique()\n",
    "itemID_unique = URM_all_dataframe[\"ItemID\"].unique()\n",
    "\n",
    "n_users = len(userID_unique)\n",
    "n_items = len(itemID_unique)\n",
    "n_interactions = len(URM_all_dataframe)\n",
    "\n",
    "URM_all = sps.coo_matrix((URM_all_dataframe[\"Interaction\"].values, \n",
    "                          (URM_all_dataframe[\"UserID\"].values, URM_all_dataframe[\"ItemID\"].values)))\n",
    "URM_all = URM_all.tocsr() # to obtain fast access to rows (users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adb47788",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-10T17:04:36.221452Z",
     "iopub.status.busy": "2021-12-10T17:04:36.220702Z",
     "iopub.status.idle": "2021-12-10T17:04:50.784120Z",
     "shell.execute_reply": "2021-12-10T17:04:50.784690Z",
     "shell.execute_reply.started": "2021-12-09T15:28:56.225556Z"
    },
    "papermill": {
     "duration": 14.585584,
     "end_time": "2021-12-10T17:04:50.784876",
     "exception": false,
     "start_time": "2021-12-10T17:04:36.199292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 4 (0.03 %) of 13650 users have no sampled items\n"
     ]
    }
   ],
   "source": [
    "from Data_manager.split_functions.split_train_validation_random_holdout import split_train_in_two_percentage_global_sample\n",
    "\n",
    "# split data into train and validation data 80/20\n",
    "URM_train, URM_valid = split_train_in_two_percentage_global_sample(URM_all, train_percentage = 0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c01db02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-10T17:04:50.825629Z",
     "iopub.status.busy": "2021-12-10T17:04:50.824533Z",
     "iopub.status.idle": "2021-12-10T17:04:50.890704Z",
     "shell.execute_reply": "2021-12-10T17:04:50.891631Z",
     "shell.execute_reply.started": "2021-12-09T15:29:07.614164Z"
    },
    "papermill": {
     "duration": 0.089523,
     "end_time": "2021-12-10T17:04:50.891897",
     "exception": false,
     "start_time": "2021-12-10T17:04:50.802374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Ignoring 13646 ( 0.0%) Users that have less than 1 test interactions\n"
     ]
    }
   ],
   "source": [
    "from Evaluation.Evaluator import EvaluatorHoldout\n",
    "\n",
    "#create an evaluator object to evaluate validation set\n",
    "#we will use it for hyperparameter tuning\n",
    "evaluator_valid = EvaluatorHoldout(URM_valid, cutoff_list=[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0c0b5ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-10T17:04:50.933803Z",
     "iopub.status.busy": "2021-12-10T17:04:50.932974Z",
     "iopub.status.idle": "2021-12-10T17:04:52.227509Z",
     "shell.execute_reply": "2021-12-10T17:04:52.226868Z",
     "shell.execute_reply.started": "2021-12-09T15:29:13.212669Z"
    },
    "papermill": {
     "duration": 1.316909,
     "end_time": "2021-12-10T17:04:52.227674",
     "exception": false,
     "start_time": "2021-12-10T17:04:50.910765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sps\n",
    "from Recommenders.Recommender_utils import check_matrix\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from Recommenders.BaseSimilarityMatrixRecommender import BaseItemSimilarityMatrixRecommender\n",
    "from Utils.seconds_to_biggest_unit import seconds_to_biggest_unit\n",
    "import time, sys\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# os.environ[\"PYTHONWARNINGS\"] = ('ignore::exceptions.ConvergenceWarning:sklearn.linear_model')\n",
    "# os.environ[\"PYTHONWARNINGS\"] = ('ignore:Objective did not converge:ConvergenceWarning:')\n",
    "\n",
    "class SLIMElasticNetRecommender(BaseItemSimilarityMatrixRecommender):\n",
    "    \"\"\"\n",
    "    Train a Sparse Linear Methods (SLIM) item similarity model.\n",
    "    NOTE: ElasticNet solver is parallel, a single intance of SLIM_ElasticNet will\n",
    "          make use of half the cores available\n",
    "    See:\n",
    "        Efficient Top-N Recommendation by Linear Regression,\n",
    "        M. Levy and K. Jack, LSRS workshop at RecSys 2013.\n",
    "        SLIM: Sparse linear methods for top-n recommender systems,\n",
    "        X. Ning and G. Karypis, ICDM 2011.\n",
    "        http://glaros.dtc.umn.edu/gkhome/fetch/papers/SLIM2011icdm.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    RECOMMENDER_NAME = \"SLIMElasticNetRecommender\"\n",
    "\n",
    "    def __init__(self, URM_train, verbose = True):\n",
    "        super(SLIMElasticNetRecommender, self).__init__(URM_train, verbose = verbose)\n",
    "\n",
    "    @ignore_warnings(category=ConvergenceWarning)\n",
    "    def fit(self, l1_ratio=0.1, alpha = 1.0, positive_only=True, topK = 100,**earlystopping_kwargs):\n",
    "\n",
    "        assert l1_ratio>= 0 and l1_ratio<=1, \"{}: l1_ratio must be between 0 and 1, provided value was {}\".format(self.RECOMMENDER_NAME, l1_ratio)\n",
    "\n",
    "        self.l1_ratio = l1_ratio\n",
    "        self.positive_only = positive_only\n",
    "        self.topK = topK\n",
    "\n",
    "\n",
    "        # initialize the ElasticNet model\n",
    "        self.model = ElasticNet(alpha=alpha,\n",
    "                                l1_ratio=self.l1_ratio,\n",
    "                                positive=self.positive_only,\n",
    "                                fit_intercept=False,\n",
    "                                copy_X=False,\n",
    "                                precompute=True,\n",
    "                                selection='random',\n",
    "                                max_iter=100,\n",
    "                                tol=1e-4)\n",
    "\n",
    "        URM_train = check_matrix(self.URM_train, 'csc', dtype=np.float32)\n",
    "\n",
    "        n_items = URM_train.shape[1]\n",
    "\n",
    "        # Use array as it reduces memory requirements compared to lists\n",
    "        dataBlock = 10000000\n",
    "\n",
    "        rows = np.zeros(dataBlock, dtype=np.int32)\n",
    "        cols = np.zeros(dataBlock, dtype=np.int32)\n",
    "        values = np.zeros(dataBlock, dtype=np.float32)\n",
    "\n",
    "        numCells = 0\n",
    "\n",
    "        start_time = time.time()\n",
    "        start_time_printBatch = start_time\n",
    "\n",
    "        # fit each item's factors sequentially (not in parallel)\n",
    "        for currentItem in range(n_items):\n",
    "\n",
    "            # get the target column\n",
    "            y = URM_train[:, currentItem].toarray()\n",
    "\n",
    "            # set the j-th column of X to zero\n",
    "            start_pos = URM_train.indptr[currentItem]\n",
    "            end_pos = URM_train.indptr[currentItem + 1]\n",
    "\n",
    "            current_item_data_backup = URM_train.data[start_pos: end_pos].copy()\n",
    "            URM_train.data[start_pos: end_pos] = 0.0\n",
    "\n",
    "            # fit one ElasticNet model per column\n",
    "            self.model.fit(URM_train, y)\n",
    "\n",
    "            # self.model.coef_ contains the coefficient of the ElasticNet model\n",
    "            # let's keep only the non-zero values\n",
    "\n",
    "            # Select topK values\n",
    "            # Sorting is done in three steps. Faster then plain np.argsort for higher number of items\n",
    "            # - Partition the data to extract the set of relevant items\n",
    "            # - Sort only the relevant items\n",
    "            # - Get the original item index\n",
    "\n",
    "            nonzero_model_coef_index = self.model.sparse_coef_.indices\n",
    "            nonzero_model_coef_value = self.model.sparse_coef_.data\n",
    "\n",
    "            local_topK = min(len(nonzero_model_coef_value)-1, self.topK)\n",
    "\n",
    "            relevant_items_partition = (-nonzero_model_coef_value).argpartition(local_topK)[0:local_topK]\n",
    "            relevant_items_partition_sorting = np.argsort(-nonzero_model_coef_value[relevant_items_partition])\n",
    "            ranking = relevant_items_partition[relevant_items_partition_sorting]\n",
    "\n",
    "            for index in range(len(ranking)):\n",
    "\n",
    "                if numCells == len(rows):\n",
    "                    rows = np.concatenate((rows, np.zeros(dataBlock, dtype=np.int32)))\n",
    "                    cols = np.concatenate((cols, np.zeros(dataBlock, dtype=np.int32)))\n",
    "                    values = np.concatenate((values, np.zeros(dataBlock, dtype=np.float32)))\n",
    "\n",
    "\n",
    "                rows[numCells] = nonzero_model_coef_index[ranking[index]]\n",
    "                cols[numCells] = currentItem\n",
    "                values[numCells] = nonzero_model_coef_value[ranking[index]]\n",
    "\n",
    "                numCells += 1\n",
    "\n",
    "            # finally, replace the original values of the j-th column\n",
    "            URM_train.data[start_pos:end_pos] = current_item_data_backup\n",
    "\n",
    "            elapsed_time = time.time() - start_time\n",
    "            new_time_value, new_time_unit = seconds_to_biggest_unit(elapsed_time)\n",
    "\n",
    "\n",
    "            if time.time() - start_time_printBatch > 300 or currentItem == n_items-1:\n",
    "                self._print(\"Processed {} ({:4.1f}%) in {:.2f} {}. Items per second: {:.2f}\".format(\n",
    "                    currentItem+1,\n",
    "                    100.0* float(currentItem+1)/n_items,\n",
    "                    new_time_value,\n",
    "                    new_time_unit,\n",
    "                    float(currentItem)/elapsed_time))\n",
    "\n",
    "                sys.stdout.flush()\n",
    "                sys.stderr.flush()\n",
    "\n",
    "                start_time_printBatch = time.time()\n",
    "\n",
    "        # generate the sparse weight matrix\n",
    "        self.W_sparse = sps.csr_matrix((values[:numCells], (rows[:numCells], cols[:numCells])),\n",
    "                                       shape=(n_items, n_items), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55a4c04d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-10T17:04:52.270528Z",
     "iopub.status.busy": "2021-12-10T17:04:52.268535Z",
     "iopub.status.idle": "2021-12-10T18:03:40.380439Z",
     "shell.execute_reply": "2021-12-10T18:03:40.379757Z",
     "shell.execute_reply.started": "2021-12-09T15:29:16.957636Z"
    },
    "papermill": {
     "duration": 3528.135706,
     "end_time": "2021-12-10T18:03:40.380603",
     "exception": false,
     "start_time": "2021-12-10T17:04:52.244897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLIMElasticNetRecommender: Processed 1529 ( 8.5%) in 5.00 min. Items per second: 5.09\n",
      "SLIMElasticNetRecommender: Processed 3052 (16.9%) in 10.00 min. Items per second: 5.08\n",
      "SLIMElasticNetRecommender: Processed 4590 (25.4%) in 15.01 min. Items per second: 5.10\n",
      "SLIMElasticNetRecommender: Processed 6131 (33.9%) in 20.01 min. Items per second: 5.11\n",
      "SLIMElasticNetRecommender: Processed 7667 (42.5%) in 25.01 min. Items per second: 5.11\n",
      "SLIMElasticNetRecommender: Processed 9214 (51.0%) in 30.01 min. Items per second: 5.12\n",
      "SLIMElasticNetRecommender: Processed 10766 (59.6%) in 35.01 min. Items per second: 5.12\n",
      "SLIMElasticNetRecommender: Processed 12310 (68.2%) in 40.01 min. Items per second: 5.13\n",
      "SLIMElasticNetRecommender: Processed 13841 (76.6%) in 45.01 min. Items per second: 5.12\n",
      "SLIMElasticNetRecommender: Processed 15391 (85.2%) in 50.02 min. Items per second: 5.13\n",
      "SLIMElasticNetRecommender: Processed 16908 (93.6%) in 55.02 min. Items per second: 5.12\n",
      "SLIMElasticNetRecommender: Processed 18059 (100.0%) in 58.80 min. Items per second: 5.12\n"
     ]
    }
   ],
   "source": [
    "recommender_SLIMElasticNet = SLIMElasticNetRecommender(URM_train)\n",
    "recommender_SLIMElasticNet.fit(epochs = 500, l1_ratio = 0.0023170159712850467, alpha = 0.09078974149197175, \n",
    "                positive_only = True, topK = 363)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c29b19d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-10T18:03:40.427072Z",
     "iopub.status.busy": "2021-12-10T18:03:40.426107Z",
     "iopub.status.idle": "2021-12-10T18:06:46.599757Z",
     "shell.execute_reply": "2021-12-10T18:06:46.599181Z",
     "shell.execute_reply.started": "2021-12-09T16:29:01.912654Z"
    },
    "papermill": {
     "duration": 186.198156,
     "end_time": "2021-12-10T18:06:46.599919",
     "exception": false,
     "start_time": "2021-12-10T18:03:40.401763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_compile_all_cython: Found 10 Cython files in 4 folders...\r\n",
      "run_compile_all_cython: All files will be compiled using your current python environment: '/opt/conda/bin/python'\r\n",
      "Compiling [1/10]: MatrixFactorization_Cython_Epoch.pyx... \r\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1822\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[KMatrixFactorization_Cython_Epoch.c:620\u001b[m\u001b[K:\r\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\r\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\r\n",
      "\u001b[01m\u001b[KMatrixFactorization_Cython_Epoch.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[K__pyx_pf_32MatrixFactorization_Cython_Epoch_32MatrixFactorization_Cython_Epoch_10epochIteration_Cython_ASY_SVD_SGD\u001b[m\u001b[K’:\r\n",
      "\u001b[01m\u001b[KMatrixFactorization_Cython_Epoch.c:8519:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_v_end_pos_seen_items\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\r\n",
      " 8519 |         \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K (__pyx_t_19 = __pyx_v_start_pos_seen_items; __pyx_t_19 < __pyx_t_18; __pyx_t_19+=1) {\r\n",
      "      |         \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\r\n",
      "\u001b[01m\u001b[KMatrixFactorization_Cython_Epoch.c:8519:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_v_start_pos_seen_items\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/MatrixFactorization/Cython/MatrixFactorization_Cython_Epoch.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "Compiling [1/10]: MatrixFactorization_Cython_Epoch.pyx... PASS\r\n",
      "\r\n",
      "Compiling [2/10]: MatrixFactorizationImpressions_Cython_Epoch.pyx... \r\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1822\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[KMatrixFactorizationImpressions_Cython_Epoch.c:620\u001b[m\u001b[K:\r\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\r\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\r\n",
      "\u001b[01m\u001b[KMatrixFactorizationImpressions_Cython_Epoch.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[K__pyx_f_43MatrixFactorizationImpressions_Cython_Epoch_32MatrixFactorization_Cython_Epoch_sampleBPR_Cython\u001b[m\u001b[K’:\r\n",
      "\u001b[01m\u001b[KMatrixFactorizationImpressions_Cython_Epoch.c:12608:17:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_v_start_pos_impression_items\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\r\n",
      "12608 |       \u001b[01;35m\u001b[K__pyx_t_4 = (__pyx_v_start_pos_impression_items + __pyx_v_index)\u001b[m\u001b[K;\r\n",
      "      |       \u001b[01;35m\u001b[K~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\r\n",
      "\u001b[01m\u001b[KMatrixFactorizationImpressions_Cython_Epoch.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[K__pyx_pf_43MatrixFactorizationImpressions_Cython_Epoch_32MatrixFactorization_Cython_Epoch_10epochIteration_Cython_ASY_SVD_SGD\u001b[m\u001b[K’:\r\n",
      "\u001b[01m\u001b[KMatrixFactorizationImpressions_Cython_Epoch.c:8586:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_v_end_pos_seen_items\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\r\n",
      " 8586 |       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K (__pyx_t_19 = __pyx_v_start_pos_seen_items; __pyx_t_19 < __pyx_t_18; __pyx_t_19+=1) {\r\n",
      "      |       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\r\n",
      "\u001b[01m\u001b[KMatrixFactorizationImpressions_Cython_Epoch.c:8586:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_v_start_pos_seen_items\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/MatrixFactorization/Cython/MatrixFactorizationImpressions_Cython_Epoch.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "Compiling [2/10]: MatrixFactorizationImpressions_Cython_Epoch.pyx... PASS\r\n",
      "\r\n",
      "Compiling [3/10]: Compute_Similarity_Cython.pyx... \r\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1822\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[KCompute_Similarity_Cython.c:620\u001b[m\u001b[K:\r\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\r\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/Similarity/Cython/Compute_Similarity_Cython.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "Compiling [3/10]: Compute_Similarity_Cython.pyx... PASS\r\n",
      "\r\n",
      "Compiling [4/10]: Triangular_Matrix.pyx... \r\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1822\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[KTriangular_Matrix.c:620\u001b[m\u001b[K:\r\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\r\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/SLIM/Cython/Triangular_Matrix.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "Compiling [4/10]: Triangular_Matrix.pyx... PASS\r\n",
      "\r\n",
      "Compiling [5/10]: SLIM_BPR_Cython_Epoch.pyx... \r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:633:34: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:633:66: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:818:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:818:52: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:917:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:917:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:917:69: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1052:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1052:42: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1053:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1053:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1822\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[KSLIM_BPR_Cython_Epoch.c:620\u001b[m\u001b[K:\r\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\r\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\r\n",
      "\u001b[01m\u001b[KSLIM_BPR_Cython_Epoch.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[K__pyx_f_21SLIM_BPR_Cython_Epoch_22Sparse_Matrix_Tree_CSR_test_list_tee_conversion\u001b[m\u001b[K’:\r\n",
      "\u001b[01m\u001b[KSLIM_BPR_Cython_Epoch.c:10691:15:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_v_previous_element\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\r\n",
      "10691 |     \u001b[01;35m\u001b[K__pyx_t_7 = __pyx_v_current_element->lower\u001b[m\u001b[K;\r\n",
      "      |     \u001b[01;35m\u001b[K~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/SLIM/Cython/SLIM_BPR_Cython_Epoch.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:633:34: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:633:66: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:818:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:818:52: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:917:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:917:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:917:69: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1052:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1052:42: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1053:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1053:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "Compiling [5/10]: SLIM_BPR_Cython_Epoch.pyx... PASS\r\n",
      "\r\n",
      "Compiling [6/10]: Sparse_Matrix_Tree_CSR.pyx... \r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:132:34: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:132:66: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:343:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:343:52: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:442:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:442:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:442:69: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:577:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:577:42: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:578:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:578:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1822\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[KSparse_Matrix_Tree_CSR.c:620\u001b[m\u001b[K:\r\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\r\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\r\n",
      "\u001b[01m\u001b[KSparse_Matrix_Tree_CSR.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[K__pyx_f_22Sparse_Matrix_Tree_CSR_22Sparse_Matrix_Tree_CSR_test_list_tree_conversion\u001b[m\u001b[K’:\r\n",
      "\u001b[01m\u001b[KSparse_Matrix_Tree_CSR.c:5696:15:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_v_previous_element\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\r\n",
      " 5696 |     \u001b[01;35m\u001b[K__pyx_t_7 = __pyx_v_current_element->lower\u001b[m\u001b[K;\r\n",
      "      |     \u001b[01;35m\u001b[K~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/SLIM/Cython/Sparse_Matrix_Tree_CSR.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:132:34: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:132:66: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:343:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:343:52: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:442:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:442:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:442:69: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:577:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:577:42: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:578:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:578:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\r\n",
      "Compiling [6/10]: Sparse_Matrix_Tree_CSR.pyx... PASS\r\n",
      "\r\n",
      "Compiling [7/10]: HP3_Similarity_Cython_SGD.pyx... \r\n",
      "warning: HP3_Similarity_Cython_SGD.pyx:113:40: Index should be typed for more efficient access\r\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1822\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[KHP3_Similarity_Cython_SGD.c:620\u001b[m\u001b[K:\r\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\r\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\r\n",
      "\u001b[01m\u001b[KHP3_Similarity_Cython_SGD.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[K__pyx_pf_25HP3_Similarity_Cython_SGD_25HP3_Similarity_Cython_SGD_4fit\u001b[m\u001b[K’:\r\n",
      "\u001b[01m\u001b[KHP3_Similarity_Cython_SGD.c:6147:55:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_v_sample_num\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\r\n",
      " 6147 |   __pyx_t_1 = PyFloat_FromDouble((__pyx_v_cum_loss / \u001b[01;35m\u001b[K((double)__pyx_v_sample_num)\u001b[m\u001b[K)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 291, __pyx_L1_error)\r\n",
      "      |                                                      \u001b[01;35m\u001b[K~^~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/FeatureWeighting/Cython/HP3_Similarity_Cython_SGD.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "warning: HP3_Similarity_Cython_SGD.pyx:113:40: Index should be typed for more efficient access\r\n",
      "Compiling [7/10]: HP3_Similarity_Cython_SGD.pyx... PASS\r\n",
      "\r\n",
      "Compiling [8/10]: FBSM_Rating_Cython_SGD.pyx... \r\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1822\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[KFBSM_Rating_Cython_SGD.c:620\u001b[m\u001b[K:\r\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\r\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\r\n",
      "\u001b[01m\u001b[KFBSM_Rating_Cython_SGD.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[K__pyx_pf_22FBSM_Rating_Cython_SGD_22FBSM_Rating_Cython_SGD_2fit\u001b[m\u001b[K’:\r\n",
      "\u001b[01m\u001b[KFBSM_Rating_Cython_SGD.c:8875:55:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_v_num_sample\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\r\n",
      " 8875 |   __pyx_t_5 = PyFloat_FromDouble((__pyx_v_cum_loss / \u001b[01;35m\u001b[K((double)__pyx_v_num_sample)\u001b[m\u001b[K)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 551, __pyx_L1_error)\r\n",
      "      |                                                      \u001b[01;35m\u001b[K~^~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/FeatureWeighting/Cython/FBSM_Rating_Cython_SGD.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "Compiling [8/10]: FBSM_Rating_Cython_SGD.pyx... PASS\r\n",
      "\r\n",
      "Compiling [9/10]: CFW_DVV_Similarity_Cython_SGD.pyx... \r\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1822\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[KCFW_DVV_Similarity_Cython_SGD.c:620\u001b[m\u001b[K:\r\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\r\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/FeatureWeighting/Cython/CFW_DVV_Similarity_Cython_SGD.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "Compiling [9/10]: CFW_DVV_Similarity_Cython_SGD.pyx... PASS\r\n",
      "\r\n",
      "Compiling [10/10]: CFW_D_Similarity_Cython_SGD.pyx... \r\n",
      "In file included from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarraytypes.h:1822\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\r\n",
      "                 from \u001b[01m\u001b[KCFW_D_Similarity_Cython_SGD.c:620\u001b[m\u001b[K:\r\n",
      "\u001b[01m\u001b[K/opt/conda/lib/python3.7/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\r\n",
      "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\r\n",
      "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\r\n",
      "\u001b[01m\u001b[KCFW_D_Similarity_Cython_SGD.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[K__pyx_pf_27CFW_D_Similarity_Cython_SGD_27CFW_D_Similarity_Cython_SGD_6fit\u001b[m\u001b[K’:\r\n",
      "\u001b[01m\u001b[KCFW_D_Similarity_Cython_SGD.c:5900:55:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_v_sample_num\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\r\n",
      " 5900 |   __pyx_t_3 = PyFloat_FromDouble((__pyx_v_cum_loss / \u001b[01;35m\u001b[K((double)__pyx_v_sample_num)\u001b[m\u001b[K)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 290, __pyx_L1_error)\r\n",
      "      |                                                      \u001b[01;35m\u001b[K~^~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\r\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /kaggle/working/Recommenders/FeatureWeighting/Cython/CFW_D_Similarity_Cython_SGD.pyx\r\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\r\n",
      "Compiling [10/10]: CFW_D_Similarity_Cython_SGD.pyx... PASS\r\n",
      "\r\n",
      "run_compile_all_cython: Compilation finished. SUCCESS.\r\n",
      "Compilation log can be found here: './result_experiments/run_compile_all_cython.txt'\r\n"
     ]
    }
   ],
   "source": [
    "import pyximport\n",
    "pyximport.install()\n",
    "!python run_compile_all_cython.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fb2f2ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-10T18:06:46.675119Z",
     "iopub.status.busy": "2021-12-10T18:06:46.674096Z",
     "iopub.status.idle": "2021-12-10T18:13:47.878899Z",
     "shell.execute_reply": "2021-12-10T18:13:47.879504Z",
     "shell.execute_reply.started": "2021-12-09T16:32:03.591062Z"
    },
    "papermill": {
     "duration": 421.244042,
     "end_time": "2021-12-10T18:13:47.879864",
     "exception": false,
     "start_time": "2021-12-10T18:06:46.635822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLIM_BPR_Recommender: Automatic selection of fastest train mode. Available RAM is 16723.00 MB (92.90%) of 18001.00 MB, required is 1304.51 MB. Using dense matrix.\n",
      "Processed 13650 (100.0%) in 1.15 sec. BPR loss is 2.67E-01. Sample per second: 11864\n",
      "SLIM_BPR_Recommender: Epoch 1 of 650. Elapsed time 0.56 sec\n",
      "Processed 13650 (100.0%) in 0.70 sec. BPR loss is 1.10E+00. Sample per second: 19432\n",
      "SLIM_BPR_Recommender: Epoch 2 of 650. Elapsed time 1.11 sec\n",
      "Processed 13650 (100.0%) in 1.26 sec. BPR loss is 1.90E+00. Sample per second: 10789\n",
      "SLIM_BPR_Recommender: Epoch 3 of 650. Elapsed time 1.68 sec\n",
      "Processed 13650 (100.0%) in 0.81 sec. BPR loss is 2.70E+00. Sample per second: 16844\n",
      "SLIM_BPR_Recommender: Epoch 4 of 650. Elapsed time 2.22 sec\n",
      "Processed 13650 (100.0%) in 1.37 sec. BPR loss is 3.44E+00. Sample per second: 9959\n",
      "SLIM_BPR_Recommender: Epoch 5 of 650. Elapsed time 2.78 sec\n",
      "Processed 13650 (100.0%) in 0.94 sec. BPR loss is 3.99E+00. Sample per second: 14476\n",
      "SLIM_BPR_Recommender: Epoch 6 of 650. Elapsed time 3.36 sec\n",
      "Processed 13650 (100.0%) in 1.53 sec. BPR loss is 4.71E+00. Sample per second: 8894\n",
      "SLIM_BPR_Recommender: Epoch 7 of 650. Elapsed time 3.95 sec\n",
      "Processed 13650 (100.0%) in 1.11 sec. BPR loss is 5.17E+00. Sample per second: 12294\n",
      "SLIM_BPR_Recommender: Epoch 8 of 650. Elapsed time 4.52 sec\n",
      "Processed 13650 (100.0%) in 0.71 sec. BPR loss is 5.80E+00. Sample per second: 19275\n",
      "SLIM_BPR_Recommender: Epoch 9 of 650. Elapsed time 5.12 sec\n",
      "Processed 13650 (100.0%) in 1.27 sec. BPR loss is 6.23E+00. Sample per second: 10704\n",
      "SLIM_BPR_Recommender: Epoch 10 of 650. Elapsed time 5.69 sec\n",
      "Processed 13650 (100.0%) in 0.84 sec. BPR loss is 6.52E+00. Sample per second: 16157\n",
      "SLIM_BPR_Recommender: Epoch 11 of 650. Elapsed time 6.26 sec\n",
      "Processed 13650 (100.0%) in 1.41 sec. BPR loss is 7.24E+00. Sample per second: 9700\n",
      "SLIM_BPR_Recommender: Epoch 12 of 650. Elapsed time 6.82 sec\n",
      "Processed 13650 (100.0%) in 0.97 sec. BPR loss is 7.44E+00. Sample per second: 14060\n",
      "SLIM_BPR_Recommender: Epoch 13 of 650. Elapsed time 7.38 sec\n",
      "Processed 13650 (100.0%) in 1.52 sec. BPR loss is 8.07E+00. Sample per second: 8961\n",
      "SLIM_BPR_Recommender: Epoch 14 of 650. Elapsed time 7.94 sec\n",
      "Processed 13650 (100.0%) in 1.07 sec. BPR loss is 8.26E+00. Sample per second: 12727\n",
      "SLIM_BPR_Recommender: Epoch 15 of 650. Elapsed time 8.49 sec\n",
      "Processed 13650 (100.0%) in 0.62 sec. BPR loss is 8.81E+00. Sample per second: 22134\n",
      "SLIM_BPR_Recommender: Epoch 16 of 650. Elapsed time 9.03 sec\n",
      "Processed 13650 (100.0%) in 1.19 sec. BPR loss is 9.06E+00. Sample per second: 11492\n",
      "SLIM_BPR_Recommender: Epoch 17 of 650. Elapsed time 9.60 sec\n",
      "Processed 13650 (100.0%) in 0.75 sec. BPR loss is 9.32E+00. Sample per second: 18117\n",
      "SLIM_BPR_Recommender: Epoch 18 of 650. Elapsed time 10.17 sec\n",
      "Processed 13650 (100.0%) in 1.30 sec. BPR loss is 9.82E+00. Sample per second: 10493\n",
      "SLIM_BPR_Recommender: Epoch 19 of 650. Elapsed time 10.71 sec\n",
      "Processed 13650 (100.0%) in 0.86 sec. BPR loss is 1.01E+01. Sample per second: 15959\n",
      "SLIM_BPR_Recommender: Epoch 20 of 650. Elapsed time 11.27 sec\n",
      "Processed 13650 (100.0%) in 1.47 sec. BPR loss is 1.02E+01. Sample per second: 9259\n",
      "SLIM_BPR_Recommender: Epoch 21 of 650. Elapsed time 11.89 sec\n",
      "Processed 13650 (100.0%) in 1.03 sec. BPR loss is 1.01E+01. Sample per second: 13287\n",
      "SLIM_BPR_Recommender: Epoch 22 of 650. Elapsed time 12.44 sec\n",
      "Processed 13650 (100.0%) in 0.57 sec. BPR loss is 1.09E+01. Sample per second: 23945\n",
      "SLIM_BPR_Recommender: Epoch 23 of 650. Elapsed time 12.98 sec\n",
      "Processed 13650 (100.0%) in 1.13 sec. BPR loss is 1.12E+01. Sample per second: 12044\n",
      "SLIM_BPR_Recommender: Epoch 24 of 650. Elapsed time 13.55 sec\n",
      "Processed 13650 (100.0%) in 0.69 sec. BPR loss is 1.17E+01. Sample per second: 19651\n",
      "SLIM_BPR_Recommender: Epoch 25 of 650. Elapsed time 14.11 sec\n",
      "Processed 13650 (100.0%) in 1.26 sec. BPR loss is 1.16E+01. Sample per second: 10847\n",
      "SLIM_BPR_Recommender: Epoch 26 of 650. Elapsed time 14.67 sec\n",
      "Processed 13650 (100.0%) in 0.81 sec. BPR loss is 1.17E+01. Sample per second: 16788\n",
      "SLIM_BPR_Recommender: Epoch 27 of 650. Elapsed time 15.23 sec\n",
      "Processed 13650 (100.0%) in 1.40 sec. BPR loss is 1.18E+01. Sample per second: 9768\n",
      "SLIM_BPR_Recommender: Epoch 28 of 650. Elapsed time 15.81 sec\n",
      "Processed 13650 (100.0%) in 0.95 sec. BPR loss is 1.19E+01. Sample per second: 14341\n",
      "SLIM_BPR_Recommender: Epoch 29 of 650. Elapsed time 16.36 sec\n",
      "Processed 13650 (100.0%) in 1.50 sec. BPR loss is 1.21E+01. Sample per second: 9080\n",
      "SLIM_BPR_Recommender: Epoch 30 of 650. Elapsed time 16.92 sec\n",
      "Processed 13650 (100.0%) in 1.06 sec. BPR loss is 1.23E+01. Sample per second: 12817\n",
      "SLIM_BPR_Recommender: Epoch 31 of 650. Elapsed time 17.48 sec\n",
      "Processed 13650 (100.0%) in 0.63 sec. BPR loss is 1.30E+01. Sample per second: 21818\n",
      "SLIM_BPR_Recommender: Epoch 32 of 650. Elapsed time 18.04 sec\n",
      "Processed 13650 (100.0%) in 1.18 sec. BPR loss is 1.26E+01. Sample per second: 11569\n",
      "SLIM_BPR_Recommender: Epoch 33 of 650. Elapsed time 18.59 sec\n",
      "Processed 13650 (100.0%) in 0.73 sec. BPR loss is 1.33E+01. Sample per second: 18616\n",
      "SLIM_BPR_Recommender: Epoch 34 of 650. Elapsed time 19.15 sec\n",
      "Processed 13650 (100.0%) in 1.29 sec. BPR loss is 1.32E+01. Sample per second: 10552\n",
      "SLIM_BPR_Recommender: Epoch 35 of 650. Elapsed time 19.71 sec\n",
      "Processed 13650 (100.0%) in 0.85 sec. BPR loss is 1.32E+01. Sample per second: 15993\n",
      "SLIM_BPR_Recommender: Epoch 36 of 650. Elapsed time 20.27 sec\n",
      "Processed 13650 (100.0%) in 1.39 sec. BPR loss is 1.34E+01. Sample per second: 9831\n",
      "SLIM_BPR_Recommender: Epoch 37 of 650. Elapsed time 20.80 sec\n",
      "Processed 13650 (100.0%) in 0.94 sec. BPR loss is 1.36E+01. Sample per second: 14442\n",
      "SLIM_BPR_Recommender: Epoch 38 of 650. Elapsed time 21.36 sec\n",
      "Processed 13650 (100.0%) in 1.50 sec. BPR loss is 1.39E+01. Sample per second: 9093\n",
      "SLIM_BPR_Recommender: Epoch 39 of 650. Elapsed time 21.91 sec\n",
      "Processed 13650 (100.0%) in 1.05 sec. BPR loss is 1.42E+01. Sample per second: 12954\n",
      "SLIM_BPR_Recommender: Epoch 40 of 650. Elapsed time 22.47 sec\n",
      "Processed 13650 (100.0%) in 0.61 sec. BPR loss is 1.43E+01. Sample per second: 22525\n",
      "SLIM_BPR_Recommender: Epoch 41 of 650. Elapsed time 23.02 sec\n",
      "Processed 13650 (100.0%) in 1.17 sec. BPR loss is 1.39E+01. Sample per second: 11696\n",
      "SLIM_BPR_Recommender: Epoch 42 of 650. Elapsed time 23.58 sec\n",
      "Processed 13650 (100.0%) in 0.74 sec. BPR loss is 1.42E+01. Sample per second: 18514\n",
      "SLIM_BPR_Recommender: Epoch 43 of 650. Elapsed time 24.15 sec\n",
      "Processed 13650 (100.0%) in 1.31 sec. BPR loss is 1.51E+01. Sample per second: 10453\n",
      "SLIM_BPR_Recommender: Epoch 44 of 650. Elapsed time 24.72 sec\n",
      "Processed 13650 (100.0%) in 0.88 sec. BPR loss is 1.50E+01. Sample per second: 15554\n",
      "SLIM_BPR_Recommender: Epoch 45 of 650. Elapsed time 25.29 sec\n",
      "Processed 13650 (100.0%) in 1.44 sec. BPR loss is 1.49E+01. Sample per second: 9499\n",
      "SLIM_BPR_Recommender: Epoch 46 of 650. Elapsed time 25.85 sec\n",
      "Processed 13650 (100.0%) in 1.00 sec. BPR loss is 1.49E+01. Sample per second: 13615\n",
      "SLIM_BPR_Recommender: Epoch 47 of 650. Elapsed time 26.42 sec\n",
      "Processed 13650 (100.0%) in 0.58 sec. BPR loss is 1.57E+01. Sample per second: 23390\n",
      "SLIM_BPR_Recommender: Epoch 48 of 650. Elapsed time 27.00 sec\n",
      "Processed 13650 (100.0%) in 1.14 sec. BPR loss is 1.52E+01. Sample per second: 11930\n",
      "SLIM_BPR_Recommender: Epoch 49 of 650. Elapsed time 27.56 sec\n",
      "Processed 13650 (100.0%) in 0.70 sec. BPR loss is 1.58E+01. Sample per second: 19594\n",
      "SLIM_BPR_Recommender: Epoch 50 of 650. Elapsed time 28.11 sec\n",
      "Processed 13650 (100.0%) in 1.23 sec. BPR loss is 1.54E+01. Sample per second: 11065\n",
      "SLIM_BPR_Recommender: Epoch 51 of 650. Elapsed time 28.65 sec\n",
      "Processed 13650 (100.0%) in 0.78 sec. BPR loss is 1.58E+01. Sample per second: 17461\n",
      "SLIM_BPR_Recommender: Epoch 52 of 650. Elapsed time 29.19 sec\n",
      "Processed 13650 (100.0%) in 1.33 sec. BPR loss is 1.55E+01. Sample per second: 10244\n",
      "SLIM_BPR_Recommender: Epoch 53 of 650. Elapsed time 29.74 sec\n",
      "Processed 13650 (100.0%) in 0.86 sec. BPR loss is 1.56E+01. Sample per second: 15896\n",
      "SLIM_BPR_Recommender: Epoch 54 of 650. Elapsed time 30.27 sec\n",
      "Processed 13650 (100.0%) in 1.39 sec. BPR loss is 1.64E+01. Sample per second: 9802\n",
      "SLIM_BPR_Recommender: Epoch 55 of 650. Elapsed time 30.80 sec\n",
      "Processed 13650 (100.0%) in 0.94 sec. BPR loss is 1.67E+01. Sample per second: 14486\n",
      "SLIM_BPR_Recommender: Epoch 56 of 650. Elapsed time 31.35 sec\n",
      "Processed 13650 (100.0%) in 1.51 sec. BPR loss is 1.61E+01. Sample per second: 9062\n",
      "SLIM_BPR_Recommender: Epoch 57 of 650. Elapsed time 31.92 sec\n",
      "Processed 13650 (100.0%) in 1.05 sec. BPR loss is 1.65E+01. Sample per second: 13021\n",
      "SLIM_BPR_Recommender: Epoch 58 of 650. Elapsed time 32.46 sec\n",
      "Processed 13650 (100.0%) in 0.60 sec. BPR loss is 1.66E+01. Sample per second: 22658\n",
      "SLIM_BPR_Recommender: Epoch 59 of 650. Elapsed time 33.02 sec\n",
      "Processed 13650 (100.0%) in 1.17 sec. BPR loss is 1.72E+01. Sample per second: 11665\n",
      "SLIM_BPR_Recommender: Epoch 60 of 650. Elapsed time 33.58 sec\n",
      "Processed 13650 (100.0%) in 0.73 sec. BPR loss is 1.72E+01. Sample per second: 18715\n",
      "SLIM_BPR_Recommender: Epoch 61 of 650. Elapsed time 34.14 sec\n",
      "Processed 13650 (100.0%) in 1.28 sec. BPR loss is 1.70E+01. Sample per second: 10659\n",
      "SLIM_BPR_Recommender: Epoch 62 of 650. Elapsed time 34.69 sec\n",
      "Processed 13650 (100.0%) in 0.84 sec. BPR loss is 1.66E+01. Sample per second: 16311\n",
      "SLIM_BPR_Recommender: Epoch 63 of 650. Elapsed time 35.25 sec\n",
      "Processed 13650 (100.0%) in 1.40 sec. BPR loss is 1.74E+01. Sample per second: 9751\n",
      "SLIM_BPR_Recommender: Epoch 64 of 650. Elapsed time 35.81 sec\n",
      "Processed 13650 (100.0%) in 0.97 sec. BPR loss is 1.76E+01. Sample per second: 14122\n",
      "SLIM_BPR_Recommender: Epoch 65 of 650. Elapsed time 36.38 sec\n",
      "Processed 13650 (100.0%) in 1.52 sec. BPR loss is 1.70E+01. Sample per second: 8951\n",
      "SLIM_BPR_Recommender: Epoch 66 of 650. Elapsed time 36.94 sec\n",
      "Processed 13650 (100.0%) in 1.08 sec. BPR loss is 1.72E+01. Sample per second: 12594\n",
      "SLIM_BPR_Recommender: Epoch 67 of 650. Elapsed time 37.50 sec\n",
      "Processed 13650 (100.0%) in 0.67 sec. BPR loss is 1.74E+01. Sample per second: 20456\n",
      "SLIM_BPR_Recommender: Epoch 68 of 650. Elapsed time 38.08 sec\n",
      "Processed 13650 (100.0%) in 1.22 sec. BPR loss is 1.66E+01. Sample per second: 11194\n",
      "SLIM_BPR_Recommender: Epoch 69 of 650. Elapsed time 38.63 sec\n",
      "Processed 13650 (100.0%) in 0.77 sec. BPR loss is 1.72E+01. Sample per second: 17716\n",
      "SLIM_BPR_Recommender: Epoch 70 of 650. Elapsed time 39.18 sec\n",
      "Processed 13650 (100.0%) in 1.32 sec. BPR loss is 1.73E+01. Sample per second: 10331\n",
      "SLIM_BPR_Recommender: Epoch 71 of 650. Elapsed time 39.73 sec\n",
      "Processed 13650 (100.0%) in 0.86 sec. BPR loss is 1.72E+01. Sample per second: 15853\n",
      "SLIM_BPR_Recommender: Epoch 72 of 650. Elapsed time 40.27 sec\n",
      "Processed 13650 (100.0%) in 1.39 sec. BPR loss is 1.77E+01. Sample per second: 9794\n",
      "SLIM_BPR_Recommender: Epoch 73 of 650. Elapsed time 40.81 sec\n",
      "Processed 13650 (100.0%) in 0.95 sec. BPR loss is 1.76E+01. Sample per second: 14412\n",
      "SLIM_BPR_Recommender: Epoch 74 of 650. Elapsed time 41.36 sec\n",
      "Processed 13650 (100.0%) in 1.49 sec. BPR loss is 1.79E+01. Sample per second: 9142\n",
      "SLIM_BPR_Recommender: Epoch 75 of 650. Elapsed time 41.91 sec\n",
      "Processed 13650 (100.0%) in 1.04 sec. BPR loss is 1.78E+01. Sample per second: 13111\n",
      "SLIM_BPR_Recommender: Epoch 76 of 650. Elapsed time 42.45 sec\n",
      "Processed 13650 (100.0%) in 0.58 sec. BPR loss is 1.82E+01. Sample per second: 23395\n",
      "SLIM_BPR_Recommender: Epoch 77 of 650. Elapsed time 43.00 sec\n",
      "Processed 13650 (100.0%) in 1.19 sec. BPR loss is 1.83E+01. Sample per second: 11481\n",
      "SLIM_BPR_Recommender: Epoch 78 of 650. Elapsed time 43.60 sec\n",
      "Processed 13650 (100.0%) in 0.77 sec. BPR loss is 1.82E+01. Sample per second: 17835\n",
      "SLIM_BPR_Recommender: Epoch 79 of 650. Elapsed time 44.18 sec\n",
      "Processed 13650 (100.0%) in 1.33 sec. BPR loss is 1.83E+01. Sample per second: 10283\n",
      "SLIM_BPR_Recommender: Epoch 80 of 650. Elapsed time 44.74 sec\n",
      "Processed 13650 (100.0%) in 0.90 sec. BPR loss is 1.77E+01. Sample per second: 15221\n",
      "SLIM_BPR_Recommender: Epoch 81 of 650. Elapsed time 45.31 sec\n",
      "Processed 13650 (100.0%) in 1.46 sec. BPR loss is 1.78E+01. Sample per second: 9361\n",
      "SLIM_BPR_Recommender: Epoch 82 of 650. Elapsed time 45.87 sec\n",
      "Processed 13650 (100.0%) in 1.02 sec. BPR loss is 1.82E+01. Sample per second: 13400\n",
      "SLIM_BPR_Recommender: Epoch 83 of 650. Elapsed time 46.43 sec\n",
      "Processed 13650 (100.0%) in 0.55 sec. BPR loss is 1.80E+01. Sample per second: 24670\n",
      "SLIM_BPR_Recommender: Epoch 84 of 650. Elapsed time 46.97 sec\n",
      "Processed 13650 (100.0%) in 1.10 sec. BPR loss is 1.90E+01. Sample per second: 12448\n",
      "SLIM_BPR_Recommender: Epoch 85 of 650. Elapsed time 47.51 sec\n",
      "Processed 13650 (100.0%) in 0.65 sec. BPR loss is 1.85E+01. Sample per second: 20992\n",
      "SLIM_BPR_Recommender: Epoch 86 of 650. Elapsed time 48.06 sec\n",
      "Processed 13650 (100.0%) in 1.21 sec. BPR loss is 1.87E+01. Sample per second: 11266\n",
      "SLIM_BPR_Recommender: Epoch 87 of 650. Elapsed time 48.62 sec\n",
      "Processed 13650 (100.0%) in 0.76 sec. BPR loss is 1.84E+01. Sample per second: 17872\n",
      "SLIM_BPR_Recommender: Epoch 88 of 650. Elapsed time 49.18 sec\n",
      "Processed 13650 (100.0%) in 1.32 sec. BPR loss is 1.86E+01. Sample per second: 10362\n",
      "SLIM_BPR_Recommender: Epoch 89 of 650. Elapsed time 49.73 sec\n",
      "Processed 13650 (100.0%) in 0.87 sec. BPR loss is 1.88E+01. Sample per second: 15716\n",
      "SLIM_BPR_Recommender: Epoch 90 of 650. Elapsed time 50.28 sec\n",
      "Processed 13650 (100.0%) in 1.41 sec. BPR loss is 1.83E+01. Sample per second: 9684\n",
      "SLIM_BPR_Recommender: Epoch 91 of 650. Elapsed time 50.82 sec\n",
      "Processed 13650 (100.0%) in 0.95 sec. BPR loss is 1.86E+01. Sample per second: 14313\n",
      "SLIM_BPR_Recommender: Epoch 92 of 650. Elapsed time 51.37 sec\n",
      "Processed 13650 (100.0%) in 1.51 sec. BPR loss is 1.93E+01. Sample per second: 9054\n",
      "SLIM_BPR_Recommender: Epoch 93 of 650. Elapsed time 51.92 sec\n",
      "Processed 13650 (100.0%) in 1.07 sec. BPR loss is 1.87E+01. Sample per second: 12768\n",
      "SLIM_BPR_Recommender: Epoch 94 of 650. Elapsed time 52.48 sec\n",
      "Processed 13650 (100.0%) in 0.62 sec. BPR loss is 1.89E+01. Sample per second: 22004\n",
      "SLIM_BPR_Recommender: Epoch 95 of 650. Elapsed time 53.03 sec\n",
      "Processed 13650 (100.0%) in 1.18 sec. BPR loss is 1.85E+01. Sample per second: 11543\n",
      "SLIM_BPR_Recommender: Epoch 96 of 650. Elapsed time 53.60 sec\n",
      "Processed 13650 (100.0%) in 0.74 sec. BPR loss is 1.87E+01. Sample per second: 18525\n",
      "SLIM_BPR_Recommender: Epoch 97 of 650. Elapsed time 54.15 sec\n",
      "Processed 13650 (100.0%) in 1.30 sec. BPR loss is 1.86E+01. Sample per second: 10512\n",
      "SLIM_BPR_Recommender: Epoch 98 of 650. Elapsed time 54.71 sec\n",
      "Processed 13650 (100.0%) in 0.84 sec. BPR loss is 1.95E+01. Sample per second: 16150\n",
      "SLIM_BPR_Recommender: Epoch 99 of 650. Elapsed time 55.26 sec\n",
      "Processed 13650 (100.0%) in 1.42 sec. BPR loss is 1.94E+01. Sample per second: 9615\n",
      "SLIM_BPR_Recommender: Epoch 100 of 650. Elapsed time 55.83 sec\n",
      "Processed 13650 (100.0%) in 0.98 sec. BPR loss is 1.88E+01. Sample per second: 13917\n",
      "SLIM_BPR_Recommender: Epoch 101 of 650. Elapsed time 56.39 sec\n",
      "Processed 13650 (100.0%) in 1.52 sec. BPR loss is 1.88E+01. Sample per second: 8997\n",
      "SLIM_BPR_Recommender: Epoch 102 of 650. Elapsed time 56.93 sec\n",
      "Processed 13650 (100.0%) in 1.08 sec. BPR loss is 1.85E+01. Sample per second: 12675\n",
      "SLIM_BPR_Recommender: Epoch 103 of 650. Elapsed time 57.49 sec\n",
      "Processed 13650 (100.0%) in 0.63 sec. BPR loss is 1.95E+01. Sample per second: 21645\n",
      "SLIM_BPR_Recommender: Epoch 104 of 650. Elapsed time 58.04 sec\n",
      "Processed 13650 (100.0%) in 1.18 sec. BPR loss is 1.95E+01. Sample per second: 11598\n",
      "SLIM_BPR_Recommender: Epoch 105 of 650. Elapsed time 58.59 sec\n",
      "Processed 13650 (100.0%) in 0.72 sec. BPR loss is 1.90E+01. Sample per second: 18951\n",
      "SLIM_BPR_Recommender: Epoch 106 of 650. Elapsed time 59.13 sec\n",
      "Processed 13650 (100.0%) in 1.30 sec. BPR loss is 1.93E+01. Sample per second: 10490\n",
      "SLIM_BPR_Recommender: Epoch 107 of 650. Elapsed time 59.71 sec\n",
      "Processed 13650 (100.0%) in 0.86 sec. BPR loss is 1.94E+01. Sample per second: 15881\n",
      "SLIM_BPR_Recommender: Epoch 108 of 650. Elapsed time 1.00 min\n",
      "Processed 13650 (100.0%) in 1.41 sec. BPR loss is 1.92E+01. Sample per second: 9687\n",
      "SLIM_BPR_Recommender: Epoch 109 of 650. Elapsed time 1.01 min\n",
      "Processed 13650 (100.0%) in 0.96 sec. BPR loss is 1.97E+01. Sample per second: 14181\n",
      "SLIM_BPR_Recommender: Epoch 110 of 650. Elapsed time 1.02 min\n",
      "Processed 13650 (100.0%) in 1.50 sec. BPR loss is 1.99E+01. Sample per second: 9075\n",
      "SLIM_BPR_Recommender: Epoch 111 of 650. Elapsed time 1.03 min\n",
      "Processed 13650 (100.0%) in 1.05 sec. BPR loss is 1.99E+01. Sample per second: 13012\n",
      "SLIM_BPR_Recommender: Epoch 112 of 650. Elapsed time 1.04 min\n",
      "Processed 13650 (100.0%) in 0.61 sec. BPR loss is 1.96E+01. Sample per second: 22478\n",
      "SLIM_BPR_Recommender: Epoch 113 of 650. Elapsed time 1.05 min\n",
      "Processed 13650 (100.0%) in 1.15 sec. BPR loss is 1.96E+01. Sample per second: 11847\n",
      "SLIM_BPR_Recommender: Epoch 114 of 650. Elapsed time 1.06 min\n",
      "Processed 13650 (100.0%) in 0.70 sec. BPR loss is 2.01E+01. Sample per second: 19574\n",
      "SLIM_BPR_Recommender: Epoch 115 of 650. Elapsed time 1.07 min\n",
      "Processed 13650 (100.0%) in 1.25 sec. BPR loss is 1.96E+01. Sample per second: 10888\n",
      "SLIM_BPR_Recommender: Epoch 116 of 650. Elapsed time 1.08 min\n",
      "Processed 13650 (100.0%) in 0.82 sec. BPR loss is 1.93E+01. Sample per second: 16712\n",
      "SLIM_BPR_Recommender: Epoch 117 of 650. Elapsed time 1.09 min\n",
      "Processed 13650 (100.0%) in 1.36 sec. BPR loss is 1.99E+01. Sample per second: 10023\n",
      "SLIM_BPR_Recommender: Epoch 118 of 650. Elapsed time 1.10 min\n",
      "Processed 13650 (100.0%) in 0.91 sec. BPR loss is 1.97E+01. Sample per second: 14970\n",
      "SLIM_BPR_Recommender: Epoch 119 of 650. Elapsed time 1.11 min\n",
      "Processed 13650 (100.0%) in 1.46 sec. BPR loss is 1.95E+01. Sample per second: 9358\n",
      "SLIM_BPR_Recommender: Epoch 120 of 650. Elapsed time 1.11 min\n",
      "Processed 13650 (100.0%) in 1.01 sec. BPR loss is 1.97E+01. Sample per second: 13451\n",
      "SLIM_BPR_Recommender: Epoch 121 of 650. Elapsed time 1.12 min\n",
      "Processed 13650 (100.0%) in 0.57 sec. BPR loss is 2.03E+01. Sample per second: 23957\n",
      "SLIM_BPR_Recommender: Epoch 122 of 650. Elapsed time 1.13 min\n",
      "Processed 13650 (100.0%) in 1.12 sec. BPR loss is 2.01E+01. Sample per second: 12190\n",
      "SLIM_BPR_Recommender: Epoch 123 of 650. Elapsed time 1.14 min\n",
      "Processed 13650 (100.0%) in 0.67 sec. BPR loss is 2.01E+01. Sample per second: 20472\n",
      "SLIM_BPR_Recommender: Epoch 124 of 650. Elapsed time 1.15 min\n",
      "Processed 13650 (100.0%) in 1.22 sec. BPR loss is 2.05E+01. Sample per second: 11194\n",
      "SLIM_BPR_Recommender: Epoch 125 of 650. Elapsed time 1.16 min\n",
      "Processed 13650 (100.0%) in 0.76 sec. BPR loss is 2.04E+01. Sample per second: 17864\n",
      "SLIM_BPR_Recommender: Epoch 126 of 650. Elapsed time 1.17 min\n",
      "Processed 13650 (100.0%) in 1.35 sec. BPR loss is 2.04E+01. Sample per second: 10077\n",
      "SLIM_BPR_Recommender: Epoch 127 of 650. Elapsed time 1.18 min\n",
      "Processed 13650 (100.0%) in 0.96 sec. BPR loss is 2.02E+01. Sample per second: 14227\n",
      "SLIM_BPR_Recommender: Epoch 128 of 650. Elapsed time 1.19 min\n",
      "Processed 13650 (100.0%) in 1.53 sec. BPR loss is 2.03E+01. Sample per second: 8915\n",
      "SLIM_BPR_Recommender: Epoch 129 of 650. Elapsed time 1.20 min\n",
      "Processed 13650 (100.0%) in 1.11 sec. BPR loss is 2.07E+01. Sample per second: 12257\n",
      "SLIM_BPR_Recommender: Epoch 130 of 650. Elapsed time 1.21 min\n",
      "Processed 13650 (100.0%) in 0.70 sec. BPR loss is 2.09E+01. Sample per second: 19458\n",
      "SLIM_BPR_Recommender: Epoch 131 of 650. Elapsed time 1.22 min\n",
      "Processed 13650 (100.0%) in 1.29 sec. BPR loss is 2.11E+01. Sample per second: 10556\n",
      "SLIM_BPR_Recommender: Epoch 132 of 650. Elapsed time 1.23 min\n",
      "Processed 13650 (100.0%) in 0.87 sec. BPR loss is 2.10E+01. Sample per second: 15624\n",
      "SLIM_BPR_Recommender: Epoch 133 of 650. Elapsed time 1.24 min\n",
      "Processed 13650 (100.0%) in 1.45 sec. BPR loss is 2.05E+01. Sample per second: 9384\n",
      "SLIM_BPR_Recommender: Epoch 134 of 650. Elapsed time 1.25 min\n",
      "Processed 13650 (100.0%) in 1.06 sec. BPR loss is 2.08E+01. Sample per second: 12927\n",
      "SLIM_BPR_Recommender: Epoch 135 of 650. Elapsed time 1.26 min\n",
      "Processed 13650 (100.0%) in 0.62 sec. BPR loss is 2.10E+01. Sample per second: 21882\n",
      "SLIM_BPR_Recommender: Epoch 136 of 650. Elapsed time 1.27 min\n",
      "Processed 13650 (100.0%) in 1.20 sec. BPR loss is 2.09E+01. Sample per second: 11409\n",
      "SLIM_BPR_Recommender: Epoch 137 of 650. Elapsed time 1.28 min\n",
      "Processed 13650 (100.0%) in 0.76 sec. BPR loss is 2.13E+01. Sample per second: 17957\n",
      "SLIM_BPR_Recommender: Epoch 138 of 650. Elapsed time 1.29 min\n",
      "Processed 13650 (100.0%) in 1.31 sec. BPR loss is 2.09E+01. Sample per second: 10415\n",
      "SLIM_BPR_Recommender: Epoch 139 of 650. Elapsed time 1.30 min\n",
      "Processed 13650 (100.0%) in 0.87 sec. BPR loss is 2.05E+01. Sample per second: 15655\n",
      "SLIM_BPR_Recommender: Epoch 140 of 650. Elapsed time 1.30 min\n",
      "Processed 13650 (100.0%) in 1.42 sec. BPR loss is 2.10E+01. Sample per second: 9618\n",
      "SLIM_BPR_Recommender: Epoch 141 of 650. Elapsed time 1.31 min\n",
      "Processed 13650 (100.0%) in 0.97 sec. BPR loss is 2.08E+01. Sample per second: 14023\n",
      "SLIM_BPR_Recommender: Epoch 142 of 650. Elapsed time 1.32 min\n",
      "Processed 13650 (100.0%) in 1.53 sec. BPR loss is 2.16E+01. Sample per second: 8918\n",
      "SLIM_BPR_Recommender: Epoch 143 of 650. Elapsed time 1.33 min\n",
      "Processed 13650 (100.0%) in 1.10 sec. BPR loss is 2.13E+01. Sample per second: 12371\n",
      "SLIM_BPR_Recommender: Epoch 144 of 650. Elapsed time 1.34 min\n",
      "Processed 13650 (100.0%) in 0.67 sec. BPR loss is 2.10E+01. Sample per second: 20463\n",
      "SLIM_BPR_Recommender: Epoch 145 of 650. Elapsed time 1.35 min\n",
      "Processed 13650 (100.0%) in 1.26 sec. BPR loss is 2.04E+01. Sample per second: 10872\n",
      "SLIM_BPR_Recommender: Epoch 146 of 650. Elapsed time 1.36 min\n",
      "Processed 13650 (100.0%) in 0.80 sec. BPR loss is 2.12E+01. Sample per second: 17039\n",
      "SLIM_BPR_Recommender: Epoch 147 of 650. Elapsed time 1.37 min\n",
      "Processed 13650 (100.0%) in 1.34 sec. BPR loss is 2.10E+01. Sample per second: 10183\n",
      "SLIM_BPR_Recommender: Epoch 148 of 650. Elapsed time 1.38 min\n",
      "Processed 13650 (100.0%) in 0.89 sec. BPR loss is 2.09E+01. Sample per second: 15340\n",
      "SLIM_BPR_Recommender: Epoch 149 of 650. Elapsed time 1.39 min\n",
      "Processed 13650 (100.0%) in 1.46 sec. BPR loss is 2.10E+01. Sample per second: 9327\n",
      "SLIM_BPR_Recommender: Epoch 150 of 650. Elapsed time 1.40 min\n",
      "Processed 13650 (100.0%) in 1.02 sec. BPR loss is 2.14E+01. Sample per second: 13355\n",
      "SLIM_BPR_Recommender: Epoch 151 of 650. Elapsed time 1.41 min\n",
      "Processed 13650 (100.0%) in 0.58 sec. BPR loss is 2.08E+01. Sample per second: 23497\n",
      "SLIM_BPR_Recommender: Epoch 152 of 650. Elapsed time 1.42 min\n",
      "Processed 13650 (100.0%) in 1.13 sec. BPR loss is 2.19E+01. Sample per second: 12103\n",
      "SLIM_BPR_Recommender: Epoch 153 of 650. Elapsed time 1.43 min\n",
      "Processed 13650 (100.0%) in 0.69 sec. BPR loss is 2.12E+01. Sample per second: 19794\n",
      "SLIM_BPR_Recommender: Epoch 154 of 650. Elapsed time 1.44 min\n",
      "Processed 13650 (100.0%) in 1.24 sec. BPR loss is 2.12E+01. Sample per second: 10990\n",
      "SLIM_BPR_Recommender: Epoch 155 of 650. Elapsed time 1.44 min\n",
      "Processed 13650 (100.0%) in 0.81 sec. BPR loss is 2.08E+01. Sample per second: 16886\n",
      "SLIM_BPR_Recommender: Epoch 156 of 650. Elapsed time 1.45 min\n",
      "Processed 13650 (100.0%) in 1.38 sec. BPR loss is 2.13E+01. Sample per second: 9915\n",
      "SLIM_BPR_Recommender: Epoch 157 of 650. Elapsed time 1.46 min\n",
      "Processed 13650 (100.0%) in 0.93 sec. BPR loss is 2.19E+01. Sample per second: 14727\n",
      "SLIM_BPR_Recommender: Epoch 158 of 650. Elapsed time 1.47 min\n",
      "Processed 13650 (100.0%) in 1.49 sec. BPR loss is 2.23E+01. Sample per second: 9183\n",
      "SLIM_BPR_Recommender: Epoch 159 of 650. Elapsed time 1.48 min\n",
      "Processed 13650 (100.0%) in 1.06 sec. BPR loss is 2.15E+01. Sample per second: 12914\n",
      "SLIM_BPR_Recommender: Epoch 160 of 650. Elapsed time 1.49 min\n",
      "Processed 13650 (100.0%) in 0.63 sec. BPR loss is 2.15E+01. Sample per second: 21607\n",
      "SLIM_BPR_Recommender: Epoch 161 of 650. Elapsed time 1.50 min\n",
      "Processed 13650 (100.0%) in 1.21 sec. BPR loss is 2.11E+01. Sample per second: 11242\n",
      "SLIM_BPR_Recommender: Epoch 162 of 650. Elapsed time 1.51 min\n",
      "Processed 13650 (100.0%) in 0.77 sec. BPR loss is 2.20E+01. Sample per second: 17736\n",
      "SLIM_BPR_Recommender: Epoch 163 of 650. Elapsed time 1.52 min\n",
      "Processed 13650 (100.0%) in 1.32 sec. BPR loss is 2.20E+01. Sample per second: 10340\n",
      "SLIM_BPR_Recommender: Epoch 164 of 650. Elapsed time 1.53 min\n",
      "Processed 13650 (100.0%) in 0.86 sec. BPR loss is 2.15E+01. Sample per second: 15816\n",
      "SLIM_BPR_Recommender: Epoch 165 of 650. Elapsed time 1.54 min\n",
      "Processed 13650 (100.0%) in 1.45 sec. BPR loss is 2.23E+01. Sample per second: 9434\n",
      "SLIM_BPR_Recommender: Epoch 166 of 650. Elapsed time 1.55 min\n",
      "Processed 13650 (100.0%) in 1.00 sec. BPR loss is 2.17E+01. Sample per second: 13587\n",
      "SLIM_BPR_Recommender: Epoch 167 of 650. Elapsed time 1.56 min\n",
      "Processed 13650 (100.0%) in 0.54 sec. BPR loss is 2.15E+01. Sample per second: 25202\n",
      "SLIM_BPR_Recommender: Epoch 168 of 650. Elapsed time 1.57 min\n",
      "Processed 13650 (100.0%) in 1.13 sec. BPR loss is 2.24E+01. Sample per second: 12057\n",
      "SLIM_BPR_Recommender: Epoch 169 of 650. Elapsed time 1.58 min\n",
      "Processed 13650 (100.0%) in 0.69 sec. BPR loss is 2.16E+01. Sample per second: 19648\n",
      "SLIM_BPR_Recommender: Epoch 170 of 650. Elapsed time 1.59 min\n",
      "Processed 13650 (100.0%) in 1.25 sec. BPR loss is 2.12E+01. Sample per second: 10889\n",
      "SLIM_BPR_Recommender: Epoch 171 of 650. Elapsed time 1.59 min\n",
      "Processed 13650 (100.0%) in 0.83 sec. BPR loss is 2.19E+01. Sample per second: 16491\n",
      "SLIM_BPR_Recommender: Epoch 172 of 650. Elapsed time 1.60 min\n",
      "Processed 13650 (100.0%) in 1.39 sec. BPR loss is 2.21E+01. Sample per second: 9796\n",
      "SLIM_BPR_Recommender: Epoch 173 of 650. Elapsed time 1.61 min\n",
      "Processed 13650 (100.0%) in 0.95 sec. BPR loss is 2.22E+01. Sample per second: 14387\n",
      "SLIM_BPR_Recommender: Epoch 174 of 650. Elapsed time 1.62 min\n",
      "Processed 13650 (100.0%) in 1.48 sec. BPR loss is 2.22E+01. Sample per second: 9191\n",
      "SLIM_BPR_Recommender: Epoch 175 of 650. Elapsed time 1.63 min\n",
      "Processed 13650 (100.0%) in 1.04 sec. BPR loss is 2.19E+01. Sample per second: 13180\n",
      "SLIM_BPR_Recommender: Epoch 176 of 650. Elapsed time 1.64 min\n",
      "Processed 13650 (100.0%) in 0.59 sec. BPR loss is 2.19E+01. Sample per second: 23213\n",
      "SLIM_BPR_Recommender: Epoch 177 of 650. Elapsed time 1.65 min\n",
      "Processed 13650 (100.0%) in 1.14 sec. BPR loss is 2.16E+01. Sample per second: 11999\n",
      "SLIM_BPR_Recommender: Epoch 178 of 650. Elapsed time 1.66 min\n",
      "Processed 13650 (100.0%) in 0.69 sec. BPR loss is 2.17E+01. Sample per second: 19640\n",
      "SLIM_BPR_Recommender: Epoch 179 of 650. Elapsed time 1.67 min\n",
      "Processed 13650 (100.0%) in 1.26 sec. BPR loss is 2.21E+01. Sample per second: 10808\n",
      "SLIM_BPR_Recommender: Epoch 180 of 650. Elapsed time 1.68 min\n",
      "Processed 13650 (100.0%) in 0.82 sec. BPR loss is 2.15E+01. Sample per second: 16600\n",
      "SLIM_BPR_Recommender: Epoch 181 of 650. Elapsed time 1.69 min\n",
      "Processed 13650 (100.0%) in 1.37 sec. BPR loss is 2.14E+01. Sample per second: 9953\n",
      "SLIM_BPR_Recommender: Epoch 182 of 650. Elapsed time 1.70 min\n",
      "Processed 13650 (100.0%) in 0.93 sec. BPR loss is 2.18E+01. Sample per second: 14694\n",
      "SLIM_BPR_Recommender: Epoch 183 of 650. Elapsed time 1.71 min\n",
      "Processed 13650 (100.0%) in 1.49 sec. BPR loss is 2.17E+01. Sample per second: 9186\n",
      "SLIM_BPR_Recommender: Epoch 184 of 650. Elapsed time 1.71 min\n",
      "Processed 13650 (100.0%) in 1.05 sec. BPR loss is 2.22E+01. Sample per second: 12990\n",
      "SLIM_BPR_Recommender: Epoch 185 of 650. Elapsed time 1.72 min\n",
      "Processed 13650 (100.0%) in 0.63 sec. BPR loss is 2.24E+01. Sample per second: 21795\n",
      "SLIM_BPR_Recommender: Epoch 186 of 650. Elapsed time 1.73 min\n",
      "Processed 13650 (100.0%) in 1.20 sec. BPR loss is 2.19E+01. Sample per second: 11340\n",
      "SLIM_BPR_Recommender: Epoch 187 of 650. Elapsed time 1.74 min\n",
      "Processed 13650 (100.0%) in 0.78 sec. BPR loss is 2.14E+01. Sample per second: 17557\n",
      "SLIM_BPR_Recommender: Epoch 188 of 650. Elapsed time 1.75 min\n",
      "Processed 13650 (100.0%) in 1.33 sec. BPR loss is 2.22E+01. Sample per second: 10261\n",
      "SLIM_BPR_Recommender: Epoch 189 of 650. Elapsed time 1.76 min\n",
      "Processed 13650 (100.0%) in 0.90 sec. BPR loss is 2.22E+01. Sample per second: 15134\n",
      "SLIM_BPR_Recommender: Epoch 190 of 650. Elapsed time 1.77 min\n",
      "Processed 13650 (100.0%) in 1.47 sec. BPR loss is 2.16E+01. Sample per second: 9299\n",
      "SLIM_BPR_Recommender: Epoch 191 of 650. Elapsed time 1.78 min\n",
      "Processed 13650 (100.0%) in 1.07 sec. BPR loss is 2.18E+01. Sample per second: 12695\n",
      "SLIM_BPR_Recommender: Epoch 192 of 650. Elapsed time 1.79 min\n",
      "Processed 13650 (100.0%) in 0.65 sec. BPR loss is 2.26E+01. Sample per second: 21148\n",
      "SLIM_BPR_Recommender: Epoch 193 of 650. Elapsed time 1.80 min\n",
      "Processed 13650 (100.0%) in 1.21 sec. BPR loss is 2.17E+01. Sample per second: 11248\n",
      "SLIM_BPR_Recommender: Epoch 194 of 650. Elapsed time 1.81 min\n",
      "Processed 13650 (100.0%) in 0.77 sec. BPR loss is 2.29E+01. Sample per second: 17801\n",
      "SLIM_BPR_Recommender: Epoch 195 of 650. Elapsed time 1.82 min\n",
      "Processed 13650 (100.0%) in 1.32 sec. BPR loss is 2.28E+01. Sample per second: 10370\n",
      "SLIM_BPR_Recommender: Epoch 196 of 650. Elapsed time 1.83 min\n",
      "Processed 13650 (100.0%) in 0.87 sec. BPR loss is 2.28E+01. Sample per second: 15672\n",
      "SLIM_BPR_Recommender: Epoch 197 of 650. Elapsed time 1.84 min\n",
      "Processed 13650 (100.0%) in 1.42 sec. BPR loss is 2.18E+01. Sample per second: 9601\n",
      "SLIM_BPR_Recommender: Epoch 198 of 650. Elapsed time 1.85 min\n",
      "Processed 13650 (100.0%) in 0.98 sec. BPR loss is 2.30E+01. Sample per second: 13963\n",
      "SLIM_BPR_Recommender: Epoch 199 of 650. Elapsed time 1.86 min\n",
      "Processed 13650 (100.0%) in 1.52 sec. BPR loss is 2.29E+01. Sample per second: 8997\n",
      "SLIM_BPR_Recommender: Epoch 200 of 650. Elapsed time 1.87 min\n",
      "Processed 13650 (100.0%) in 1.06 sec. BPR loss is 2.28E+01. Sample per second: 12906\n",
      "SLIM_BPR_Recommender: Epoch 201 of 650. Elapsed time 1.87 min\n",
      "Processed 13650 (100.0%) in 0.63 sec. BPR loss is 2.21E+01. Sample per second: 21759\n",
      "SLIM_BPR_Recommender: Epoch 202 of 650. Elapsed time 1.88 min\n",
      "Processed 13650 (100.0%) in 1.19 sec. BPR loss is 2.29E+01. Sample per second: 11498\n",
      "SLIM_BPR_Recommender: Epoch 203 of 650. Elapsed time 1.89 min\n",
      "Processed 13650 (100.0%) in 0.74 sec. BPR loss is 2.38E+01. Sample per second: 18522\n",
      "SLIM_BPR_Recommender: Epoch 204 of 650. Elapsed time 1.90 min\n",
      "Processed 13650 (100.0%) in 1.33 sec. BPR loss is 2.33E+01. Sample per second: 10259\n",
      "SLIM_BPR_Recommender: Epoch 205 of 650. Elapsed time 1.91 min\n",
      "Processed 13650 (100.0%) in 0.90 sec. BPR loss is 2.31E+01. Sample per second: 15205\n",
      "SLIM_BPR_Recommender: Epoch 206 of 650. Elapsed time 1.92 min\n",
      "Processed 13650 (100.0%) in 1.46 sec. BPR loss is 2.34E+01. Sample per second: 9338\n",
      "SLIM_BPR_Recommender: Epoch 207 of 650. Elapsed time 1.93 min\n",
      "Processed 13650 (100.0%) in 1.06 sec. BPR loss is 2.32E+01. Sample per second: 12869\n",
      "SLIM_BPR_Recommender: Epoch 208 of 650. Elapsed time 1.94 min\n",
      "Processed 13650 (100.0%) in 0.61 sec. BPR loss is 2.20E+01. Sample per second: 22196\n",
      "SLIM_BPR_Recommender: Epoch 209 of 650. Elapsed time 1.95 min\n",
      "Processed 13650 (100.0%) in 1.17 sec. BPR loss is 2.29E+01. Sample per second: 11623\n",
      "SLIM_BPR_Recommender: Epoch 210 of 650. Elapsed time 1.96 min\n",
      "Processed 13650 (100.0%) in 0.73 sec. BPR loss is 2.28E+01. Sample per second: 18690\n",
      "SLIM_BPR_Recommender: Epoch 211 of 650. Elapsed time 1.97 min\n",
      "Processed 13650 (100.0%) in 1.29 sec. BPR loss is 2.27E+01. Sample per second: 10561\n",
      "SLIM_BPR_Recommender: Epoch 212 of 650. Elapsed time 1.98 min\n",
      "Processed 13650 (100.0%) in 0.86 sec. BPR loss is 2.25E+01. Sample per second: 15951\n",
      "SLIM_BPR_Recommender: Epoch 213 of 650. Elapsed time 1.99 min\n",
      "Processed 13650 (100.0%) in 1.40 sec. BPR loss is 2.28E+01. Sample per second: 9730\n",
      "SLIM_BPR_Recommender: Epoch 214 of 650. Elapsed time 2.00 min\n",
      "Processed 13650 (100.0%) in 0.95 sec. BPR loss is 2.29E+01. Sample per second: 14359\n",
      "SLIM_BPR_Recommender: Epoch 215 of 650. Elapsed time 2.01 min\n",
      "Processed 13650 (100.0%) in 1.50 sec. BPR loss is 2.33E+01. Sample per second: 9091\n",
      "SLIM_BPR_Recommender: Epoch 216 of 650. Elapsed time 2.02 min\n",
      "Processed 13650 (100.0%) in 1.06 sec. BPR loss is 2.28E+01. Sample per second: 12915\n",
      "SLIM_BPR_Recommender: Epoch 217 of 650. Elapsed time 2.02 min\n",
      "Processed 13650 (100.0%) in 0.61 sec. BPR loss is 2.29E+01. Sample per second: 22422\n",
      "SLIM_BPR_Recommender: Epoch 218 of 650. Elapsed time 2.03 min\n",
      "Processed 13650 (100.0%) in 1.16 sec. BPR loss is 2.23E+01. Sample per second: 11767\n",
      "SLIM_BPR_Recommender: Epoch 219 of 650. Elapsed time 2.04 min\n",
      "Processed 13650 (100.0%) in 0.72 sec. BPR loss is 2.32E+01. Sample per second: 19002\n",
      "SLIM_BPR_Recommender: Epoch 220 of 650. Elapsed time 2.05 min\n",
      "Processed 13650 (100.0%) in 1.27 sec. BPR loss is 2.28E+01. Sample per second: 10705\n",
      "SLIM_BPR_Recommender: Epoch 221 of 650. Elapsed time 2.06 min\n",
      "Processed 13650 (100.0%) in 0.83 sec. BPR loss is 2.26E+01. Sample per second: 16447\n",
      "SLIM_BPR_Recommender: Epoch 222 of 650. Elapsed time 2.07 min\n",
      "Processed 13650 (100.0%) in 1.40 sec. BPR loss is 2.34E+01. Sample per second: 9743\n",
      "SLIM_BPR_Recommender: Epoch 223 of 650. Elapsed time 2.08 min\n",
      "Processed 13650 (100.0%) in 0.97 sec. BPR loss is 2.34E+01. Sample per second: 14070\n",
      "SLIM_BPR_Recommender: Epoch 224 of 650. Elapsed time 2.09 min\n",
      "Processed 13650 (100.0%) in 1.57 sec. BPR loss is 2.34E+01. Sample per second: 8693\n",
      "SLIM_BPR_Recommender: Epoch 225 of 650. Elapsed time 2.10 min\n",
      "Processed 13650 (100.0%) in 1.12 sec. BPR loss is 2.25E+01. Sample per second: 12164\n",
      "SLIM_BPR_Recommender: Epoch 226 of 650. Elapsed time 2.11 min\n",
      "Processed 13650 (100.0%) in 0.67 sec. BPR loss is 2.31E+01. Sample per second: 20368\n",
      "SLIM_BPR_Recommender: Epoch 227 of 650. Elapsed time 2.12 min\n",
      "Processed 13650 (100.0%) in 1.21 sec. BPR loss is 2.26E+01. Sample per second: 11247\n",
      "SLIM_BPR_Recommender: Epoch 228 of 650. Elapsed time 2.13 min\n",
      "Processed 13650 (100.0%) in 0.77 sec. BPR loss is 2.36E+01. Sample per second: 17697\n",
      "SLIM_BPR_Recommender: Epoch 229 of 650. Elapsed time 2.14 min\n",
      "Processed 13650 (100.0%) in 1.32 sec. BPR loss is 2.29E+01. Sample per second: 10303\n",
      "SLIM_BPR_Recommender: Epoch 230 of 650. Elapsed time 2.15 min\n",
      "Processed 13650 (100.0%) in 0.87 sec. BPR loss is 2.25E+01. Sample per second: 15730\n",
      "SLIM_BPR_Recommender: Epoch 231 of 650. Elapsed time 2.15 min\n",
      "Processed 13650 (100.0%) in 1.41 sec. BPR loss is 2.27E+01. Sample per second: 9653\n",
      "SLIM_BPR_Recommender: Epoch 232 of 650. Elapsed time 2.16 min\n",
      "Processed 13650 (100.0%) in 0.96 sec. BPR loss is 2.31E+01. Sample per second: 14148\n",
      "SLIM_BPR_Recommender: Epoch 233 of 650. Elapsed time 2.17 min\n",
      "Processed 13650 (100.0%) in 1.51 sec. BPR loss is 2.29E+01. Sample per second: 9047\n",
      "SLIM_BPR_Recommender: Epoch 234 of 650. Elapsed time 2.18 min\n",
      "Processed 13650 (100.0%) in 1.07 sec. BPR loss is 2.24E+01. Sample per second: 12801\n",
      "SLIM_BPR_Recommender: Epoch 235 of 650. Elapsed time 2.19 min\n",
      "Processed 13650 (100.0%) in 0.63 sec. BPR loss is 2.22E+01. Sample per second: 21735\n",
      "SLIM_BPR_Recommender: Epoch 236 of 650. Elapsed time 2.20 min\n",
      "Processed 13650 (100.0%) in 1.18 sec. BPR loss is 2.24E+01. Sample per second: 11568\n",
      "SLIM_BPR_Recommender: Epoch 237 of 650. Elapsed time 2.21 min\n",
      "Processed 13650 (100.0%) in 0.79 sec. BPR loss is 2.21E+01. Sample per second: 17179\n",
      "SLIM_BPR_Recommender: Epoch 238 of 650. Elapsed time 2.22 min\n",
      "Processed 13650 (100.0%) in 1.37 sec. BPR loss is 2.29E+01. Sample per second: 9934\n",
      "SLIM_BPR_Recommender: Epoch 239 of 650. Elapsed time 2.23 min\n",
      "Processed 13650 (100.0%) in 0.94 sec. BPR loss is 2.24E+01. Sample per second: 14531\n",
      "SLIM_BPR_Recommender: Epoch 240 of 650. Elapsed time 2.24 min\n",
      "Processed 13650 (100.0%) in 1.50 sec. BPR loss is 2.29E+01. Sample per second: 9100\n",
      "SLIM_BPR_Recommender: Epoch 241 of 650. Elapsed time 2.25 min\n",
      "Processed 13650 (100.0%) in 1.04 sec. BPR loss is 2.28E+01. Sample per second: 13076\n",
      "SLIM_BPR_Recommender: Epoch 242 of 650. Elapsed time 2.26 min\n",
      "Processed 13650 (100.0%) in 0.60 sec. BPR loss is 2.25E+01. Sample per second: 22711\n",
      "SLIM_BPR_Recommender: Epoch 243 of 650. Elapsed time 2.27 min\n",
      "Processed 13650 (100.0%) in 1.15 sec. BPR loss is 2.32E+01. Sample per second: 11837\n",
      "SLIM_BPR_Recommender: Epoch 244 of 650. Elapsed time 2.28 min\n",
      "Processed 13650 (100.0%) in 0.72 sec. BPR loss is 2.36E+01. Sample per second: 18933\n",
      "SLIM_BPR_Recommender: Epoch 245 of 650. Elapsed time 2.29 min\n",
      "Processed 13650 (100.0%) in 1.26 sec. BPR loss is 2.30E+01. Sample per second: 10851\n",
      "SLIM_BPR_Recommender: Epoch 246 of 650. Elapsed time 2.29 min\n",
      "Processed 13650 (100.0%) in 0.80 sec. BPR loss is 2.34E+01. Sample per second: 16961\n",
      "SLIM_BPR_Recommender: Epoch 247 of 650. Elapsed time 2.30 min\n",
      "Processed 13650 (100.0%) in 1.35 sec. BPR loss is 2.34E+01. Sample per second: 10083\n",
      "SLIM_BPR_Recommender: Epoch 248 of 650. Elapsed time 2.31 min\n",
      "Processed 13650 (100.0%) in 0.98 sec. BPR loss is 2.32E+01. Sample per second: 13936\n",
      "SLIM_BPR_Recommender: Epoch 249 of 650. Elapsed time 2.32 min\n",
      "Processed 13650 (100.0%) in 1.52 sec. BPR loss is 2.26E+01. Sample per second: 8982\n",
      "SLIM_BPR_Recommender: Epoch 250 of 650. Elapsed time 2.33 min\n",
      "Processed 13650 (100.0%) in 1.06 sec. BPR loss is 2.34E+01. Sample per second: 12889\n",
      "SLIM_BPR_Recommender: Epoch 251 of 650. Elapsed time 2.34 min\n",
      "Processed 13650 (100.0%) in 0.60 sec. BPR loss is 2.37E+01. Sample per second: 22729\n",
      "SLIM_BPR_Recommender: Epoch 252 of 650. Elapsed time 2.35 min\n",
      "Processed 13650 (100.0%) in 1.14 sec. BPR loss is 2.34E+01. Sample per second: 11978\n",
      "SLIM_BPR_Recommender: Epoch 253 of 650. Elapsed time 2.36 min\n",
      "Processed 13650 (100.0%) in 0.70 sec. BPR loss is 2.41E+01. Sample per second: 19494\n",
      "SLIM_BPR_Recommender: Epoch 254 of 650. Elapsed time 2.37 min\n",
      "Processed 13650 (100.0%) in 1.24 sec. BPR loss is 2.35E+01. Sample per second: 11035\n",
      "SLIM_BPR_Recommender: Epoch 255 of 650. Elapsed time 2.38 min\n",
      "Processed 13650 (100.0%) in 0.79 sec. BPR loss is 2.41E+01. Sample per second: 17259\n",
      "SLIM_BPR_Recommender: Epoch 256 of 650. Elapsed time 2.39 min\n",
      "Processed 13650 (100.0%) in 1.34 sec. BPR loss is 2.30E+01. Sample per second: 10164\n",
      "SLIM_BPR_Recommender: Epoch 257 of 650. Elapsed time 2.40 min\n",
      "Processed 13650 (100.0%) in 0.89 sec. BPR loss is 2.28E+01. Sample per second: 15341\n",
      "SLIM_BPR_Recommender: Epoch 258 of 650. Elapsed time 2.41 min\n",
      "Processed 13650 (100.0%) in 1.44 sec. BPR loss is 2.31E+01. Sample per second: 9494\n",
      "SLIM_BPR_Recommender: Epoch 259 of 650. Elapsed time 2.41 min\n",
      "Processed 13650 (100.0%) in 1.00 sec. BPR loss is 2.44E+01. Sample per second: 13620\n",
      "SLIM_BPR_Recommender: Epoch 260 of 650. Elapsed time 2.42 min\n",
      "Processed 13650 (100.0%) in 0.56 sec. BPR loss is 2.48E+01. Sample per second: 24415\n",
      "SLIM_BPR_Recommender: Epoch 261 of 650. Elapsed time 2.43 min\n",
      "Processed 13650 (100.0%) in 1.13 sec. BPR loss is 2.34E+01. Sample per second: 12079\n",
      "SLIM_BPR_Recommender: Epoch 262 of 650. Elapsed time 2.44 min\n",
      "Processed 13650 (100.0%) in 0.69 sec. BPR loss is 2.35E+01. Sample per second: 19848\n",
      "SLIM_BPR_Recommender: Epoch 263 of 650. Elapsed time 2.45 min\n",
      "Processed 13650 (100.0%) in 1.27 sec. BPR loss is 2.55E+01. Sample per second: 10714\n",
      "SLIM_BPR_Recommender: Epoch 264 of 650. Elapsed time 2.46 min\n",
      "Processed 13650 (100.0%) in 0.82 sec. BPR loss is 2.41E+01. Sample per second: 16567\n",
      "SLIM_BPR_Recommender: Epoch 265 of 650. Elapsed time 2.47 min\n",
      "Processed 13650 (100.0%) in 1.37 sec. BPR loss is 2.29E+01. Sample per second: 9928\n",
      "SLIM_BPR_Recommender: Epoch 266 of 650. Elapsed time 2.48 min\n",
      "Processed 13650 (100.0%) in 0.93 sec. BPR loss is 2.30E+01. Sample per second: 14724\n",
      "SLIM_BPR_Recommender: Epoch 267 of 650. Elapsed time 2.49 min\n",
      "Processed 13650 (100.0%) in 1.48 sec. BPR loss is 2.42E+01. Sample per second: 9214\n",
      "SLIM_BPR_Recommender: Epoch 268 of 650. Elapsed time 2.50 min\n",
      "Processed 13650 (100.0%) in 1.02 sec. BPR loss is 2.33E+01. Sample per second: 13427\n",
      "SLIM_BPR_Recommender: Epoch 269 of 650. Elapsed time 2.51 min\n",
      "Processed 13650 (100.0%) in 0.54 sec. BPR loss is 2.30E+01. Sample per second: 25265\n",
      "SLIM_BPR_Recommender: Epoch 270 of 650. Elapsed time 2.52 min\n",
      "Processed 13650 (100.0%) in 1.07 sec. BPR loss is 2.40E+01. Sample per second: 12760\n",
      "SLIM_BPR_Recommender: Epoch 271 of 650. Elapsed time 2.52 min\n",
      "Processed 13650 (100.0%) in 0.62 sec. BPR loss is 2.39E+01. Sample per second: 22005\n",
      "SLIM_BPR_Recommender: Epoch 272 of 650. Elapsed time 2.53 min\n",
      "Processed 13650 (100.0%) in 1.16 sec. BPR loss is 2.32E+01. Sample per second: 11754\n",
      "SLIM_BPR_Recommender: Epoch 273 of 650. Elapsed time 2.54 min\n",
      "Processed 13650 (100.0%) in 0.72 sec. BPR loss is 2.36E+01. Sample per second: 18834\n",
      "SLIM_BPR_Recommender: Epoch 274 of 650. Elapsed time 2.55 min\n",
      "Processed 13650 (100.0%) in 1.30 sec. BPR loss is 2.42E+01. Sample per second: 10509\n",
      "SLIM_BPR_Recommender: Epoch 275 of 650. Elapsed time 2.56 min\n",
      "Processed 13650 (100.0%) in 0.84 sec. BPR loss is 2.36E+01. Sample per second: 16228\n",
      "SLIM_BPR_Recommender: Epoch 276 of 650. Elapsed time 2.57 min\n",
      "Processed 13650 (100.0%) in 1.39 sec. BPR loss is 2.33E+01. Sample per second: 9828\n",
      "SLIM_BPR_Recommender: Epoch 277 of 650. Elapsed time 2.58 min\n",
      "Processed 13650 (100.0%) in 0.93 sec. BPR loss is 2.34E+01. Sample per second: 14623\n",
      "SLIM_BPR_Recommender: Epoch 278 of 650. Elapsed time 2.59 min\n",
      "Processed 13650 (100.0%) in 1.47 sec. BPR loss is 2.38E+01. Sample per second: 9279\n",
      "SLIM_BPR_Recommender: Epoch 279 of 650. Elapsed time 2.60 min\n",
      "Processed 13650 (100.0%) in 1.02 sec. BPR loss is 2.37E+01. Sample per second: 13374\n",
      "SLIM_BPR_Recommender: Epoch 280 of 650. Elapsed time 2.61 min\n",
      "Processed 13650 (100.0%) in 0.59 sec. BPR loss is 2.42E+01. Sample per second: 23275\n",
      "SLIM_BPR_Recommender: Epoch 281 of 650. Elapsed time 2.62 min\n",
      "Processed 13650 (100.0%) in 1.14 sec. BPR loss is 2.40E+01. Sample per second: 12019\n",
      "SLIM_BPR_Recommender: Epoch 282 of 650. Elapsed time 2.63 min\n",
      "Processed 13650 (100.0%) in 0.69 sec. BPR loss is 2.40E+01. Sample per second: 19681\n",
      "SLIM_BPR_Recommender: Epoch 283 of 650. Elapsed time 2.64 min\n",
      "Processed 13650 (100.0%) in 1.27 sec. BPR loss is 2.40E+01. Sample per second: 10739\n",
      "SLIM_BPR_Recommender: Epoch 284 of 650. Elapsed time 2.64 min\n",
      "Processed 13650 (100.0%) in 0.80 sec. BPR loss is 2.41E+01. Sample per second: 17063\n",
      "SLIM_BPR_Recommender: Epoch 285 of 650. Elapsed time 2.65 min\n",
      "Processed 13650 (100.0%) in 1.33 sec. BPR loss is 2.34E+01. Sample per second: 10241\n",
      "SLIM_BPR_Recommender: Epoch 286 of 650. Elapsed time 2.66 min\n",
      "Processed 13650 (100.0%) in 0.88 sec. BPR loss is 2.40E+01. Sample per second: 15572\n",
      "SLIM_BPR_Recommender: Epoch 287 of 650. Elapsed time 2.67 min\n",
      "Processed 13650 (100.0%) in 1.42 sec. BPR loss is 2.44E+01. Sample per second: 9634\n",
      "SLIM_BPR_Recommender: Epoch 288 of 650. Elapsed time 2.68 min\n",
      "Processed 13650 (100.0%) in 0.96 sec. BPR loss is 2.40E+01. Sample per second: 14211\n",
      "SLIM_BPR_Recommender: Epoch 289 of 650. Elapsed time 2.69 min\n",
      "Processed 13650 (100.0%) in 1.49 sec. BPR loss is 2.44E+01. Sample per second: 9164\n",
      "SLIM_BPR_Recommender: Epoch 290 of 650. Elapsed time 2.70 min\n",
      "Processed 13650 (100.0%) in 1.02 sec. BPR loss is 2.45E+01. Sample per second: 13365\n",
      "SLIM_BPR_Recommender: Epoch 291 of 650. Elapsed time 2.71 min\n",
      "Processed 13650 (100.0%) in 0.56 sec. BPR loss is 2.41E+01. Sample per second: 24535\n",
      "SLIM_BPR_Recommender: Epoch 292 of 650. Elapsed time 2.72 min\n",
      "Processed 13650 (100.0%) in 1.10 sec. BPR loss is 2.44E+01. Sample per second: 12412\n",
      "SLIM_BPR_Recommender: Epoch 293 of 650. Elapsed time 2.73 min\n",
      "Processed 13650 (100.0%) in 0.65 sec. BPR loss is 2.40E+01. Sample per second: 20931\n",
      "SLIM_BPR_Recommender: Epoch 294 of 650. Elapsed time 2.73 min\n",
      "Processed 13650 (100.0%) in 1.21 sec. BPR loss is 2.40E+01. Sample per second: 11282\n",
      "SLIM_BPR_Recommender: Epoch 295 of 650. Elapsed time 2.74 min\n",
      "Processed 13650 (100.0%) in 0.76 sec. BPR loss is 2.40E+01. Sample per second: 17875\n",
      "SLIM_BPR_Recommender: Epoch 296 of 650. Elapsed time 2.75 min\n",
      "Processed 13650 (100.0%) in 1.29 sec. BPR loss is 2.38E+01. Sample per second: 10549\n",
      "SLIM_BPR_Recommender: Epoch 297 of 650. Elapsed time 2.76 min\n",
      "Processed 13650 (100.0%) in 0.85 sec. BPR loss is 2.49E+01. Sample per second: 16086\n",
      "SLIM_BPR_Recommender: Epoch 298 of 650. Elapsed time 2.77 min\n",
      "Processed 13650 (100.0%) in 1.40 sec. BPR loss is 2.47E+01. Sample per second: 9746\n",
      "SLIM_BPR_Recommender: Epoch 299 of 650. Elapsed time 2.78 min\n",
      "Processed 13650 (100.0%) in 0.95 sec. BPR loss is 2.36E+01. Sample per second: 14410\n",
      "SLIM_BPR_Recommender: Epoch 300 of 650. Elapsed time 2.79 min\n",
      "Processed 13650 (100.0%) in 1.48 sec. BPR loss is 2.39E+01. Sample per second: 9229\n",
      "SLIM_BPR_Recommender: Epoch 301 of 650. Elapsed time 2.80 min\n",
      "Processed 13650 (100.0%) in 1.03 sec. BPR loss is 2.41E+01. Sample per second: 13282\n",
      "SLIM_BPR_Recommender: Epoch 302 of 650. Elapsed time 2.81 min\n",
      "Processed 13650 (100.0%) in 0.57 sec. BPR loss is 2.47E+01. Sample per second: 23824\n",
      "SLIM_BPR_Recommender: Epoch 303 of 650. Elapsed time 2.82 min\n",
      "Processed 13650 (100.0%) in 1.12 sec. BPR loss is 2.51E+01. Sample per second: 12172\n",
      "SLIM_BPR_Recommender: Epoch 304 of 650. Elapsed time 2.83 min\n",
      "Processed 13650 (100.0%) in 0.70 sec. BPR loss is 2.47E+01. Sample per second: 19415\n",
      "SLIM_BPR_Recommender: Epoch 305 of 650. Elapsed time 2.84 min\n",
      "Processed 13650 (100.0%) in 1.27 sec. BPR loss is 2.36E+01. Sample per second: 10767\n",
      "SLIM_BPR_Recommender: Epoch 306 of 650. Elapsed time 2.84 min\n",
      "Processed 13650 (100.0%) in 0.87 sec. BPR loss is 2.43E+01. Sample per second: 15670\n",
      "SLIM_BPR_Recommender: Epoch 307 of 650. Elapsed time 2.85 min\n",
      "Processed 13650 (100.0%) in 1.46 sec. BPR loss is 2.38E+01. Sample per second: 9327\n",
      "SLIM_BPR_Recommender: Epoch 308 of 650. Elapsed time 2.86 min\n",
      "Processed 13650 (100.0%) in 1.04 sec. BPR loss is 2.39E+01. Sample per second: 13127\n",
      "SLIM_BPR_Recommender: Epoch 309 of 650. Elapsed time 2.87 min\n",
      "Processed 13650 (100.0%) in 0.62 sec. BPR loss is 2.39E+01. Sample per second: 22176\n",
      "SLIM_BPR_Recommender: Epoch 310 of 650. Elapsed time 2.88 min\n",
      "Processed 13650 (100.0%) in 1.20 sec. BPR loss is 2.42E+01. Sample per second: 11344\n",
      "SLIM_BPR_Recommender: Epoch 311 of 650. Elapsed time 2.89 min\n",
      "Processed 13650 (100.0%) in 0.79 sec. BPR loss is 2.46E+01. Sample per second: 17288\n",
      "SLIM_BPR_Recommender: Epoch 312 of 650. Elapsed time 2.90 min\n",
      "Processed 13650 (100.0%) in 1.36 sec. BPR loss is 2.47E+01. Sample per second: 9999\n",
      "SLIM_BPR_Recommender: Epoch 313 of 650. Elapsed time 2.91 min\n",
      "Processed 13650 (100.0%) in 0.91 sec. BPR loss is 2.47E+01. Sample per second: 14920\n",
      "SLIM_BPR_Recommender: Epoch 314 of 650. Elapsed time 2.92 min\n",
      "Processed 13650 (100.0%) in 1.47 sec. BPR loss is 2.50E+01. Sample per second: 9308\n",
      "SLIM_BPR_Recommender: Epoch 315 of 650. Elapsed time 2.93 min\n",
      "Processed 13650 (100.0%) in 1.04 sec. BPR loss is 2.49E+01. Sample per second: 13164\n",
      "SLIM_BPR_Recommender: Epoch 316 of 650. Elapsed time 2.94 min\n",
      "Processed 13650 (100.0%) in 0.58 sec. BPR loss is 2.41E+01. Sample per second: 23549\n",
      "SLIM_BPR_Recommender: Epoch 317 of 650. Elapsed time 2.95 min\n",
      "Processed 13650 (100.0%) in 1.13 sec. BPR loss is 2.47E+01. Sample per second: 12042\n",
      "SLIM_BPR_Recommender: Epoch 318 of 650. Elapsed time 2.96 min\n",
      "Processed 13650 (100.0%) in 0.68 sec. BPR loss is 2.41E+01. Sample per second: 20166\n",
      "SLIM_BPR_Recommender: Epoch 319 of 650. Elapsed time 2.97 min\n",
      "Processed 13650 (100.0%) in 1.22 sec. BPR loss is 2.44E+01. Sample per second: 11168\n",
      "SLIM_BPR_Recommender: Epoch 320 of 650. Elapsed time 2.98 min\n",
      "Processed 13650 (100.0%) in 0.76 sec. BPR loss is 2.49E+01. Sample per second: 17834\n",
      "SLIM_BPR_Recommender: Epoch 321 of 650. Elapsed time 2.99 min\n",
      "Processed 13650 (100.0%) in 1.31 sec. BPR loss is 2.39E+01. Sample per second: 10382\n",
      "SLIM_BPR_Recommender: Epoch 322 of 650. Elapsed time 3.00 min\n",
      "Processed 13650 (100.0%) in 0.86 sec. BPR loss is 2.50E+01. Sample per second: 15930\n",
      "SLIM_BPR_Recommender: Epoch 323 of 650. Elapsed time 3.00 min\n",
      "Processed 13650 (100.0%) in 1.44 sec. BPR loss is 2.42E+01. Sample per second: 9468\n",
      "SLIM_BPR_Recommender: Epoch 324 of 650. Elapsed time 3.01 min\n",
      "Processed 13650 (100.0%) in 0.99 sec. BPR loss is 2.44E+01. Sample per second: 13733\n",
      "SLIM_BPR_Recommender: Epoch 325 of 650. Elapsed time 3.02 min\n",
      "Processed 13650 (100.0%) in 1.54 sec. BPR loss is 2.45E+01. Sample per second: 8890\n",
      "SLIM_BPR_Recommender: Epoch 326 of 650. Elapsed time 3.03 min\n",
      "Processed 13650 (100.0%) in 1.07 sec. BPR loss is 2.43E+01. Sample per second: 12782\n",
      "SLIM_BPR_Recommender: Epoch 327 of 650. Elapsed time 3.04 min\n",
      "Processed 13650 (100.0%) in 0.62 sec. BPR loss is 2.43E+01. Sample per second: 22141\n",
      "SLIM_BPR_Recommender: Epoch 328 of 650. Elapsed time 3.05 min\n",
      "Processed 13650 (100.0%) in 1.16 sec. BPR loss is 2.53E+01. Sample per second: 11766\n",
      "SLIM_BPR_Recommender: Epoch 329 of 650. Elapsed time 3.06 min\n",
      "Processed 13650 (100.0%) in 0.70 sec. BPR loss is 2.50E+01. Sample per second: 19419\n",
      "SLIM_BPR_Recommender: Epoch 330 of 650. Elapsed time 3.07 min\n",
      "Processed 13650 (100.0%) in 1.26 sec. BPR loss is 2.46E+01. Sample per second: 10813\n",
      "SLIM_BPR_Recommender: Epoch 331 of 650. Elapsed time 3.08 min\n",
      "Processed 13650 (100.0%) in 0.82 sec. BPR loss is 2.39E+01. Sample per second: 16647\n",
      "SLIM_BPR_Recommender: Epoch 332 of 650. Elapsed time 3.09 min\n",
      "Processed 13650 (100.0%) in 1.36 sec. BPR loss is 2.50E+01. Sample per second: 10042\n",
      "SLIM_BPR_Recommender: Epoch 333 of 650. Elapsed time 3.10 min\n",
      "Processed 13650 (100.0%) in 0.92 sec. BPR loss is 2.50E+01. Sample per second: 14860\n",
      "SLIM_BPR_Recommender: Epoch 334 of 650. Elapsed time 3.11 min\n",
      "Processed 13650 (100.0%) in 1.50 sec. BPR loss is 2.48E+01. Sample per second: 9123\n",
      "SLIM_BPR_Recommender: Epoch 335 of 650. Elapsed time 3.12 min\n",
      "Processed 13650 (100.0%) in 1.05 sec. BPR loss is 2.39E+01. Sample per second: 13039\n",
      "SLIM_BPR_Recommender: Epoch 336 of 650. Elapsed time 3.12 min\n",
      "Processed 13650 (100.0%) in 0.60 sec. BPR loss is 2.59E+01. Sample per second: 22742\n",
      "SLIM_BPR_Recommender: Epoch 337 of 650. Elapsed time 3.13 min\n",
      "Processed 13650 (100.0%) in 1.15 sec. BPR loss is 2.47E+01. Sample per second: 11859\n",
      "SLIM_BPR_Recommender: Epoch 338 of 650. Elapsed time 3.14 min\n",
      "Processed 13650 (100.0%) in 0.70 sec. BPR loss is 2.51E+01. Sample per second: 19409\n",
      "SLIM_BPR_Recommender: Epoch 339 of 650. Elapsed time 3.15 min\n",
      "Processed 13650 (100.0%) in 1.25 sec. BPR loss is 2.50E+01. Sample per second: 10884\n",
      "SLIM_BPR_Recommender: Epoch 340 of 650. Elapsed time 3.16 min\n",
      "Processed 13650 (100.0%) in 0.80 sec. BPR loss is 2.54E+01. Sample per second: 17086\n",
      "SLIM_BPR_Recommender: Epoch 341 of 650. Elapsed time 3.17 min\n",
      "Processed 13650 (100.0%) in 1.35 sec. BPR loss is 2.50E+01. Sample per second: 10096\n",
      "SLIM_BPR_Recommender: Epoch 342 of 650. Elapsed time 3.18 min\n",
      "Processed 13650 (100.0%) in 0.92 sec. BPR loss is 2.48E+01. Sample per second: 14827\n",
      "SLIM_BPR_Recommender: Epoch 343 of 650. Elapsed time 3.19 min\n",
      "Processed 13650 (100.0%) in 1.48 sec. BPR loss is 2.47E+01. Sample per second: 9215\n",
      "SLIM_BPR_Recommender: Epoch 344 of 650. Elapsed time 3.20 min\n",
      "Processed 13650 (100.0%) in 1.02 sec. BPR loss is 2.66E+01. Sample per second: 13328\n",
      "SLIM_BPR_Recommender: Epoch 345 of 650. Elapsed time 3.21 min\n",
      "Processed 13650 (100.0%) in 0.57 sec. BPR loss is 2.55E+01. Sample per second: 23790\n",
      "SLIM_BPR_Recommender: Epoch 346 of 650. Elapsed time 3.22 min\n",
      "Processed 13650 (100.0%) in 1.12 sec. BPR loss is 2.53E+01. Sample per second: 12147\n",
      "SLIM_BPR_Recommender: Epoch 347 of 650. Elapsed time 3.23 min\n",
      "Processed 13650 (100.0%) in 0.67 sec. BPR loss is 2.58E+01. Sample per second: 20313\n",
      "SLIM_BPR_Recommender: Epoch 348 of 650. Elapsed time 3.23 min\n",
      "Processed 13650 (100.0%) in 1.23 sec. BPR loss is 2.57E+01. Sample per second: 11137\n",
      "SLIM_BPR_Recommender: Epoch 349 of 650. Elapsed time 3.24 min\n",
      "Processed 13650 (100.0%) in 0.79 sec. BPR loss is 2.49E+01. Sample per second: 17284\n",
      "SLIM_BPR_Recommender: Epoch 350 of 650. Elapsed time 3.25 min\n",
      "Processed 13650 (100.0%) in 1.34 sec. BPR loss is 2.58E+01. Sample per second: 10218\n",
      "SLIM_BPR_Recommender: Epoch 351 of 650. Elapsed time 3.26 min\n",
      "Processed 13650 (100.0%) in 0.90 sec. BPR loss is 2.47E+01. Sample per second: 15172\n",
      "SLIM_BPR_Recommender: Epoch 352 of 650. Elapsed time 3.27 min\n",
      "Processed 13650 (100.0%) in 1.45 sec. BPR loss is 2.54E+01. Sample per second: 9429\n",
      "SLIM_BPR_Recommender: Epoch 353 of 650. Elapsed time 3.28 min\n",
      "Processed 13650 (100.0%) in 0.99 sec. BPR loss is 2.50E+01. Sample per second: 13768\n",
      "SLIM_BPR_Recommender: Epoch 354 of 650. Elapsed time 3.29 min\n",
      "Processed 13650 (100.0%) in 1.53 sec. BPR loss is 2.67E+01. Sample per second: 8908\n",
      "SLIM_BPR_Recommender: Epoch 355 of 650. Elapsed time 3.30 min\n",
      "Processed 13650 (100.0%) in 1.07 sec. BPR loss is 2.49E+01. Sample per second: 12725\n",
      "SLIM_BPR_Recommender: Epoch 356 of 650. Elapsed time 3.31 min\n",
      "Processed 13650 (100.0%) in 0.61 sec. BPR loss is 2.52E+01. Sample per second: 22536\n",
      "SLIM_BPR_Recommender: Epoch 357 of 650. Elapsed time 3.32 min\n",
      "Processed 13650 (100.0%) in 1.16 sec. BPR loss is 2.51E+01. Sample per second: 11772\n",
      "SLIM_BPR_Recommender: Epoch 358 of 650. Elapsed time 3.33 min\n",
      "Processed 13650 (100.0%) in 0.71 sec. BPR loss is 2.60E+01. Sample per second: 19251\n",
      "SLIM_BPR_Recommender: Epoch 359 of 650. Elapsed time 3.34 min\n",
      "Processed 13650 (100.0%) in 1.27 sec. BPR loss is 2.54E+01. Sample per second: 10785\n",
      "SLIM_BPR_Recommender: Epoch 360 of 650. Elapsed time 3.34 min\n",
      "Processed 13650 (100.0%) in 0.81 sec. BPR loss is 2.62E+01. Sample per second: 16839\n",
      "SLIM_BPR_Recommender: Epoch 361 of 650. Elapsed time 3.35 min\n",
      "Processed 13650 (100.0%) in 1.36 sec. BPR loss is 2.59E+01. Sample per second: 10049\n",
      "SLIM_BPR_Recommender: Epoch 362 of 650. Elapsed time 3.36 min\n",
      "Processed 13650 (100.0%) in 0.88 sec. BPR loss is 2.51E+01. Sample per second: 15498\n",
      "SLIM_BPR_Recommender: Epoch 363 of 650. Elapsed time 3.37 min\n",
      "Processed 13650 (100.0%) in 1.53 sec. BPR loss is 2.54E+01. Sample per second: 8938\n",
      "SLIM_BPR_Recommender: Epoch 364 of 650. Elapsed time 3.38 min\n",
      "Processed 13650 (100.0%) in 1.09 sec. BPR loss is 2.49E+01. Sample per second: 12470\n",
      "SLIM_BPR_Recommender: Epoch 365 of 650. Elapsed time 3.39 min\n",
      "Processed 13650 (100.0%) in 0.67 sec. BPR loss is 2.51E+01. Sample per second: 20433\n",
      "SLIM_BPR_Recommender: Epoch 366 of 650. Elapsed time 3.40 min\n",
      "Processed 13650 (100.0%) in 1.23 sec. BPR loss is 2.58E+01. Sample per second: 11055\n",
      "SLIM_BPR_Recommender: Epoch 367 of 650. Elapsed time 3.41 min\n",
      "Processed 13650 (100.0%) in 0.79 sec. BPR loss is 2.63E+01. Sample per second: 17254\n",
      "SLIM_BPR_Recommender: Epoch 368 of 650. Elapsed time 3.42 min\n",
      "Processed 13650 (100.0%) in 1.35 sec. BPR loss is 2.57E+01. Sample per second: 10140\n",
      "SLIM_BPR_Recommender: Epoch 369 of 650. Elapsed time 3.43 min\n",
      "Processed 13650 (100.0%) in 0.91 sec. BPR loss is 2.54E+01. Sample per second: 14981\n",
      "SLIM_BPR_Recommender: Epoch 370 of 650. Elapsed time 3.44 min\n",
      "Processed 13650 (100.0%) in 1.46 sec. BPR loss is 2.64E+01. Sample per second: 9326\n",
      "SLIM_BPR_Recommender: Epoch 371 of 650. Elapsed time 3.45 min\n",
      "Processed 13650 (100.0%) in 1.01 sec. BPR loss is 2.52E+01. Sample per second: 13486\n",
      "SLIM_BPR_Recommender: Epoch 372 of 650. Elapsed time 3.46 min\n",
      "Processed 13650 (100.0%) in 0.56 sec. BPR loss is 2.52E+01. Sample per second: 24253\n",
      "SLIM_BPR_Recommender: Epoch 373 of 650. Elapsed time 3.47 min\n",
      "Processed 13650 (100.0%) in 1.11 sec. BPR loss is 2.60E+01. Sample per second: 12317\n",
      "SLIM_BPR_Recommender: Epoch 374 of 650. Elapsed time 3.48 min\n",
      "Processed 13650 (100.0%) in 0.66 sec. BPR loss is 2.62E+01. Sample per second: 20808\n",
      "SLIM_BPR_Recommender: Epoch 375 of 650. Elapsed time 3.48 min\n",
      "Processed 13650 (100.0%) in 1.21 sec. BPR loss is 2.61E+01. Sample per second: 11277\n",
      "SLIM_BPR_Recommender: Epoch 376 of 650. Elapsed time 3.49 min\n",
      "Processed 13650 (100.0%) in 0.76 sec. BPR loss is 2.59E+01. Sample per second: 17970\n",
      "SLIM_BPR_Recommender: Epoch 377 of 650. Elapsed time 3.50 min\n",
      "Processed 13650 (100.0%) in 1.29 sec. BPR loss is 2.62E+01. Sample per second: 10549\n",
      "SLIM_BPR_Recommender: Epoch 378 of 650. Elapsed time 3.51 min\n",
      "Processed 13650 (100.0%) in 0.84 sec. BPR loss is 2.63E+01. Sample per second: 16324\n",
      "SLIM_BPR_Recommender: Epoch 379 of 650. Elapsed time 3.52 min\n",
      "Processed 13650 (100.0%) in 1.38 sec. BPR loss is 2.51E+01. Sample per second: 9899\n",
      "SLIM_BPR_Recommender: Epoch 380 of 650. Elapsed time 3.53 min\n",
      "Processed 13650 (100.0%) in 0.92 sec. BPR loss is 2.69E+01. Sample per second: 14819\n",
      "SLIM_BPR_Recommender: Epoch 381 of 650. Elapsed time 3.54 min\n",
      "Processed 13650 (100.0%) in 1.47 sec. BPR loss is 2.59E+01. Sample per second: 9274\n",
      "SLIM_BPR_Recommender: Epoch 382 of 650. Elapsed time 3.55 min\n",
      "Processed 13650 (100.0%) in 1.02 sec. BPR loss is 2.54E+01. Sample per second: 13326\n",
      "SLIM_BPR_Recommender: Epoch 383 of 650. Elapsed time 3.56 min\n",
      "Processed 13650 (100.0%) in 0.61 sec. BPR loss is 2.49E+01. Sample per second: 22271\n",
      "SLIM_BPR_Recommender: Epoch 384 of 650. Elapsed time 3.57 min\n",
      "Processed 13650 (100.0%) in 1.16 sec. BPR loss is 2.52E+01. Sample per second: 11786\n",
      "SLIM_BPR_Recommender: Epoch 385 of 650. Elapsed time 3.58 min\n",
      "Processed 13650 (100.0%) in 0.70 sec. BPR loss is 2.54E+01. Sample per second: 19569\n",
      "SLIM_BPR_Recommender: Epoch 386 of 650. Elapsed time 3.59 min\n",
      "Processed 13650 (100.0%) in 1.24 sec. BPR loss is 2.55E+01. Sample per second: 10997\n",
      "SLIM_BPR_Recommender: Epoch 387 of 650. Elapsed time 3.59 min\n",
      "Processed 13650 (100.0%) in 0.80 sec. BPR loss is 2.61E+01. Sample per second: 17008\n",
      "SLIM_BPR_Recommender: Epoch 388 of 650. Elapsed time 3.60 min\n",
      "Processed 13650 (100.0%) in 1.35 sec. BPR loss is 2.58E+01. Sample per second: 10115\n",
      "SLIM_BPR_Recommender: Epoch 389 of 650. Elapsed time 3.61 min\n",
      "Processed 13650 (100.0%) in 0.89 sec. BPR loss is 2.66E+01. Sample per second: 15308\n",
      "SLIM_BPR_Recommender: Epoch 390 of 650. Elapsed time 3.62 min\n",
      "Processed 13650 (100.0%) in 1.41 sec. BPR loss is 2.50E+01. Sample per second: 9668\n",
      "SLIM_BPR_Recommender: Epoch 391 of 650. Elapsed time 3.63 min\n",
      "Processed 13650 (100.0%) in 0.96 sec. BPR loss is 2.67E+01. Sample per second: 14224\n",
      "SLIM_BPR_Recommender: Epoch 392 of 650. Elapsed time 3.64 min\n",
      "Processed 13650 (100.0%) in 1.50 sec. BPR loss is 2.60E+01. Sample per second: 9076\n",
      "SLIM_BPR_Recommender: Epoch 393 of 650. Elapsed time 3.65 min\n",
      "Processed 13650 (100.0%) in 1.06 sec. BPR loss is 2.58E+01. Sample per second: 12894\n",
      "SLIM_BPR_Recommender: Epoch 394 of 650. Elapsed time 3.66 min\n",
      "Processed 13650 (100.0%) in 0.61 sec. BPR loss is 2.56E+01. Sample per second: 22467\n",
      "SLIM_BPR_Recommender: Epoch 395 of 650. Elapsed time 3.67 min\n",
      "Processed 13650 (100.0%) in 1.17 sec. BPR loss is 2.61E+01. Sample per second: 11633\n",
      "SLIM_BPR_Recommender: Epoch 396 of 650. Elapsed time 3.68 min\n",
      "Processed 13650 (100.0%) in 0.72 sec. BPR loss is 2.56E+01. Sample per second: 18915\n",
      "SLIM_BPR_Recommender: Epoch 397 of 650. Elapsed time 3.69 min\n",
      "Processed 13650 (100.0%) in 1.26 sec. BPR loss is 2.57E+01. Sample per second: 10814\n",
      "SLIM_BPR_Recommender: Epoch 398 of 650. Elapsed time 3.69 min\n",
      "Processed 13650 (100.0%) in 0.81 sec. BPR loss is 2.58E+01. Sample per second: 16776\n",
      "SLIM_BPR_Recommender: Epoch 399 of 650. Elapsed time 3.70 min\n",
      "Processed 13650 (100.0%) in 1.36 sec. BPR loss is 2.59E+01. Sample per second: 10048\n",
      "SLIM_BPR_Recommender: Epoch 400 of 650. Elapsed time 3.71 min\n",
      "Processed 13650 (100.0%) in 0.92 sec. BPR loss is 2.56E+01. Sample per second: 14855\n",
      "SLIM_BPR_Recommender: Epoch 401 of 650. Elapsed time 3.72 min\n",
      "Processed 13650 (100.0%) in 1.46 sec. BPR loss is 2.61E+01. Sample per second: 9323\n",
      "SLIM_BPR_Recommender: Epoch 402 of 650. Elapsed time 3.73 min\n",
      "Processed 13650 (100.0%) in 1.01 sec. BPR loss is 2.60E+01. Sample per second: 13499\n",
      "SLIM_BPR_Recommender: Epoch 403 of 650. Elapsed time 3.74 min\n",
      "Processed 13650 (100.0%) in 0.60 sec. BPR loss is 2.63E+01. Sample per second: 22931\n",
      "SLIM_BPR_Recommender: Epoch 404 of 650. Elapsed time 3.75 min\n",
      "Processed 13650 (100.0%) in 1.14 sec. BPR loss is 2.54E+01. Sample per second: 11960\n",
      "SLIM_BPR_Recommender: Epoch 405 of 650. Elapsed time 3.76 min\n",
      "Processed 13650 (100.0%) in 0.69 sec. BPR loss is 2.64E+01. Sample per second: 19792\n",
      "SLIM_BPR_Recommender: Epoch 406 of 650. Elapsed time 3.77 min\n",
      "Processed 13650 (100.0%) in 1.23 sec. BPR loss is 2.64E+01. Sample per second: 11074\n",
      "SLIM_BPR_Recommender: Epoch 407 of 650. Elapsed time 3.78 min\n",
      "Processed 13650 (100.0%) in 0.79 sec. BPR loss is 2.67E+01. Sample per second: 17335\n",
      "SLIM_BPR_Recommender: Epoch 408 of 650. Elapsed time 3.79 min\n",
      "Processed 13650 (100.0%) in 1.33 sec. BPR loss is 2.53E+01. Sample per second: 10281\n",
      "SLIM_BPR_Recommender: Epoch 409 of 650. Elapsed time 3.80 min\n",
      "Processed 13650 (100.0%) in 0.89 sec. BPR loss is 2.57E+01. Sample per second: 15312\n",
      "SLIM_BPR_Recommender: Epoch 410 of 650. Elapsed time 3.81 min\n",
      "Processed 13650 (100.0%) in 1.44 sec. BPR loss is 2.59E+01. Sample per second: 9453\n",
      "SLIM_BPR_Recommender: Epoch 411 of 650. Elapsed time 3.81 min\n",
      "Processed 13650 (100.0%) in 0.99 sec. BPR loss is 2.53E+01. Sample per second: 13800\n",
      "SLIM_BPR_Recommender: Epoch 412 of 650. Elapsed time 3.82 min\n",
      "Processed 13650 (100.0%) in 1.53 sec. BPR loss is 2.57E+01. Sample per second: 8928\n",
      "SLIM_BPR_Recommender: Epoch 413 of 650. Elapsed time 3.83 min\n",
      "Processed 13650 (100.0%) in 1.08 sec. BPR loss is 2.48E+01. Sample per second: 12619\n",
      "SLIM_BPR_Recommender: Epoch 414 of 650. Elapsed time 3.84 min\n",
      "Processed 13650 (100.0%) in 0.62 sec. BPR loss is 2.59E+01. Sample per second: 21840\n",
      "SLIM_BPR_Recommender: Epoch 415 of 650. Elapsed time 3.85 min\n",
      "Processed 13650 (100.0%) in 1.17 sec. BPR loss is 2.63E+01. Sample per second: 11673\n",
      "SLIM_BPR_Recommender: Epoch 416 of 650. Elapsed time 3.86 min\n",
      "Processed 13650 (100.0%) in 0.69 sec. BPR loss is 2.62E+01. Sample per second: 19681\n",
      "SLIM_BPR_Recommender: Epoch 417 of 650. Elapsed time 3.87 min\n",
      "Processed 13650 (100.0%) in 1.23 sec. BPR loss is 2.72E+01. Sample per second: 11065\n",
      "SLIM_BPR_Recommender: Epoch 418 of 650. Elapsed time 3.88 min\n",
      "Processed 13650 (100.0%) in 0.78 sec. BPR loss is 2.68E+01. Sample per second: 17399\n",
      "SLIM_BPR_Recommender: Epoch 419 of 650. Elapsed time 3.89 min\n",
      "Processed 13650 (100.0%) in 1.31 sec. BPR loss is 2.60E+01. Sample per second: 10392\n",
      "SLIM_BPR_Recommender: Epoch 420 of 650. Elapsed time 3.90 min\n",
      "Processed 13650 (100.0%) in 0.87 sec. BPR loss is 2.65E+01. Sample per second: 15741\n",
      "SLIM_BPR_Recommender: Epoch 421 of 650. Elapsed time 3.90 min\n",
      "Processed 13650 (100.0%) in 1.43 sec. BPR loss is 2.61E+01. Sample per second: 9547\n",
      "SLIM_BPR_Recommender: Epoch 422 of 650. Elapsed time 3.91 min\n",
      "Processed 13650 (100.0%) in 1.04 sec. BPR loss is 2.61E+01. Sample per second: 13173\n",
      "SLIM_BPR_Recommender: Epoch 423 of 650. Elapsed time 3.92 min\n",
      "Processed 13650 (100.0%) in 0.71 sec. BPR loss is 2.64E+01. Sample per second: 19139\n",
      "SLIM_BPR_Recommender: Epoch 424 of 650. Elapsed time 3.94 min\n",
      "Processed 13650 (100.0%) in 1.28 sec. BPR loss is 2.64E+01. Sample per second: 10668\n",
      "SLIM_BPR_Recommender: Epoch 425 of 650. Elapsed time 3.94 min\n",
      "Processed 13650 (100.0%) in 0.82 sec. BPR loss is 2.61E+01. Sample per second: 16665\n",
      "SLIM_BPR_Recommender: Epoch 426 of 650. Elapsed time 3.95 min\n",
      "Processed 13650 (100.0%) in 1.35 sec. BPR loss is 2.60E+01. Sample per second: 10122\n",
      "SLIM_BPR_Recommender: Epoch 427 of 650. Elapsed time 3.96 min\n",
      "Processed 13650 (100.0%) in 0.89 sec. BPR loss is 2.55E+01. Sample per second: 15375\n",
      "SLIM_BPR_Recommender: Epoch 428 of 650. Elapsed time 3.97 min\n",
      "Processed 13650 (100.0%) in 1.43 sec. BPR loss is 2.64E+01. Sample per second: 9548\n",
      "SLIM_BPR_Recommender: Epoch 429 of 650. Elapsed time 3.98 min\n",
      "Processed 13650 (100.0%) in 0.98 sec. BPR loss is 2.60E+01. Sample per second: 13894\n",
      "SLIM_BPR_Recommender: Epoch 430 of 650. Elapsed time 3.99 min\n",
      "Processed 13650 (100.0%) in 1.54 sec. BPR loss is 2.58E+01. Sample per second: 8890\n",
      "SLIM_BPR_Recommender: Epoch 431 of 650. Elapsed time 4.00 min\n",
      "Processed 13650 (100.0%) in 1.07 sec. BPR loss is 2.62E+01. Sample per second: 12703\n",
      "SLIM_BPR_Recommender: Epoch 432 of 650. Elapsed time 4.01 min\n",
      "Processed 13650 (100.0%) in 0.61 sec. BPR loss is 2.52E+01. Sample per second: 22541\n",
      "SLIM_BPR_Recommender: Epoch 433 of 650. Elapsed time 4.02 min\n",
      "Processed 13650 (100.0%) in 1.14 sec. BPR loss is 2.58E+01. Sample per second: 12000\n",
      "SLIM_BPR_Recommender: Epoch 434 of 650. Elapsed time 4.03 min\n",
      "Processed 13650 (100.0%) in 0.69 sec. BPR loss is 2.54E+01. Sample per second: 19829\n",
      "SLIM_BPR_Recommender: Epoch 435 of 650. Elapsed time 4.04 min\n",
      "Processed 13650 (100.0%) in 1.24 sec. BPR loss is 2.69E+01. Sample per second: 10967\n",
      "SLIM_BPR_Recommender: Epoch 436 of 650. Elapsed time 4.04 min\n",
      "Processed 13650 (100.0%) in 0.80 sec. BPR loss is 2.55E+01. Sample per second: 17089\n",
      "SLIM_BPR_Recommender: Epoch 437 of 650. Elapsed time 4.05 min\n",
      "Processed 13650 (100.0%) in 1.34 sec. BPR loss is 2.54E+01. Sample per second: 10176\n",
      "SLIM_BPR_Recommender: Epoch 438 of 650. Elapsed time 4.06 min\n",
      "Processed 13650 (100.0%) in 0.88 sec. BPR loss is 2.51E+01. Sample per second: 15460\n",
      "SLIM_BPR_Recommender: Epoch 439 of 650. Elapsed time 4.07 min\n",
      "Processed 13650 (100.0%) in 1.44 sec. BPR loss is 2.62E+01. Sample per second: 9506\n",
      "SLIM_BPR_Recommender: Epoch 440 of 650. Elapsed time 4.08 min\n",
      "Processed 13650 (100.0%) in 0.99 sec. BPR loss is 2.60E+01. Sample per second: 13839\n",
      "SLIM_BPR_Recommender: Epoch 441 of 650. Elapsed time 4.09 min\n",
      "Processed 13650 (100.0%) in 1.54 sec. BPR loss is 2.56E+01. Sample per second: 8863\n",
      "SLIM_BPR_Recommender: Epoch 442 of 650. Elapsed time 4.10 min\n",
      "Processed 13650 (100.0%) in 1.11 sec. BPR loss is 2.64E+01. Sample per second: 12304\n",
      "SLIM_BPR_Recommender: Epoch 443 of 650. Elapsed time 4.11 min\n",
      "Processed 13650 (100.0%) in 0.70 sec. BPR loss is 2.60E+01. Sample per second: 19612\n",
      "SLIM_BPR_Recommender: Epoch 444 of 650. Elapsed time 4.12 min\n",
      "Processed 13650 (100.0%) in 1.25 sec. BPR loss is 2.63E+01. Sample per second: 10961\n",
      "SLIM_BPR_Recommender: Epoch 445 of 650. Elapsed time 4.13 min\n",
      "Processed 13650 (100.0%) in 0.78 sec. BPR loss is 2.65E+01. Sample per second: 17406\n",
      "SLIM_BPR_Recommender: Epoch 446 of 650. Elapsed time 4.14 min\n",
      "Processed 13650 (100.0%) in 1.32 sec. BPR loss is 2.64E+01. Sample per second: 10318\n",
      "SLIM_BPR_Recommender: Epoch 447 of 650. Elapsed time 4.15 min\n",
      "Processed 13650 (100.0%) in 0.87 sec. BPR loss is 2.64E+01. Sample per second: 15748\n",
      "SLIM_BPR_Recommender: Epoch 448 of 650. Elapsed time 4.15 min\n",
      "Processed 13650 (100.0%) in 1.41 sec. BPR loss is 2.60E+01. Sample per second: 9648\n",
      "SLIM_BPR_Recommender: Epoch 449 of 650. Elapsed time 4.16 min\n",
      "Processed 13650 (100.0%) in 0.96 sec. BPR loss is 2.61E+01. Sample per second: 14173\n",
      "SLIM_BPR_Recommender: Epoch 450 of 650. Elapsed time 4.17 min\n",
      "Processed 13650 (100.0%) in 1.51 sec. BPR loss is 2.69E+01. Sample per second: 9056\n",
      "SLIM_BPR_Recommender: Epoch 451 of 650. Elapsed time 4.18 min\n",
      "Processed 13650 (100.0%) in 1.06 sec. BPR loss is 2.69E+01. Sample per second: 12828\n",
      "SLIM_BPR_Recommender: Epoch 452 of 650. Elapsed time 4.19 min\n",
      "Processed 13650 (100.0%) in 0.62 sec. BPR loss is 2.62E+01. Sample per second: 22111\n",
      "SLIM_BPR_Recommender: Epoch 453 of 650. Elapsed time 4.20 min\n",
      "Processed 13650 (100.0%) in 1.17 sec. BPR loss is 2.61E+01. Sample per second: 11662\n",
      "SLIM_BPR_Recommender: Epoch 454 of 650. Elapsed time 4.21 min\n",
      "Processed 13650 (100.0%) in 0.72 sec. BPR loss is 2.63E+01. Sample per second: 18898\n",
      "SLIM_BPR_Recommender: Epoch 455 of 650. Elapsed time 4.22 min\n",
      "Processed 13650 (100.0%) in 1.28 sec. BPR loss is 2.60E+01. Sample per second: 10624\n",
      "SLIM_BPR_Recommender: Epoch 456 of 650. Elapsed time 4.23 min\n",
      "Processed 13650 (100.0%) in 0.83 sec. BPR loss is 2.76E+01. Sample per second: 16442\n",
      "SLIM_BPR_Recommender: Epoch 457 of 650. Elapsed time 4.24 min\n",
      "Processed 13650 (100.0%) in 1.38 sec. BPR loss is 2.72E+01. Sample per second: 9883\n",
      "SLIM_BPR_Recommender: Epoch 458 of 650. Elapsed time 4.25 min\n",
      "Processed 13650 (100.0%) in 0.93 sec. BPR loss is 2.66E+01. Sample per second: 14615\n",
      "SLIM_BPR_Recommender: Epoch 459 of 650. Elapsed time 4.26 min\n",
      "Processed 13650 (100.0%) in 1.48 sec. BPR loss is 2.67E+01. Sample per second: 9195\n",
      "SLIM_BPR_Recommender: Epoch 460 of 650. Elapsed time 4.26 min\n",
      "Processed 13650 (100.0%) in 1.03 sec. BPR loss is 2.70E+01. Sample per second: 13237\n",
      "SLIM_BPR_Recommender: Epoch 461 of 650. Elapsed time 4.27 min\n",
      "Processed 13650 (100.0%) in 0.57 sec. BPR loss is 2.52E+01. Sample per second: 24008\n",
      "SLIM_BPR_Recommender: Epoch 462 of 650. Elapsed time 4.28 min\n",
      "Processed 13650 (100.0%) in 1.11 sec. BPR loss is 2.58E+01. Sample per second: 12276\n",
      "SLIM_BPR_Recommender: Epoch 463 of 650. Elapsed time 4.29 min\n",
      "Processed 13650 (100.0%) in 0.69 sec. BPR loss is 2.59E+01. Sample per second: 19696\n",
      "SLIM_BPR_Recommender: Epoch 464 of 650. Elapsed time 4.30 min\n",
      "Processed 13650 (100.0%) in 1.24 sec. BPR loss is 2.62E+01. Sample per second: 10982\n",
      "SLIM_BPR_Recommender: Epoch 465 of 650. Elapsed time 4.31 min\n",
      "Processed 13650 (100.0%) in 0.78 sec. BPR loss is 2.71E+01. Sample per second: 17553\n",
      "SLIM_BPR_Recommender: Epoch 466 of 650. Elapsed time 4.32 min\n",
      "Processed 13650 (100.0%) in 1.32 sec. BPR loss is 2.62E+01. Sample per second: 10309\n",
      "SLIM_BPR_Recommender: Epoch 467 of 650. Elapsed time 4.33 min\n",
      "Processed 13650 (100.0%) in 0.87 sec. BPR loss is 2.67E+01. Sample per second: 15597\n",
      "SLIM_BPR_Recommender: Epoch 468 of 650. Elapsed time 4.34 min\n",
      "Processed 13650 (100.0%) in 1.42 sec. BPR loss is 2.56E+01. Sample per second: 9645\n",
      "SLIM_BPR_Recommender: Epoch 469 of 650. Elapsed time 4.35 min\n",
      "Processed 13650 (100.0%) in 0.96 sec. BPR loss is 2.66E+01. Sample per second: 14143\n",
      "SLIM_BPR_Recommender: Epoch 470 of 650. Elapsed time 4.36 min\n",
      "Processed 13650 (100.0%) in 1.51 sec. BPR loss is 2.69E+01. Sample per second: 9068\n",
      "SLIM_BPR_Recommender: Epoch 471 of 650. Elapsed time 4.37 min\n",
      "Processed 13650 (100.0%) in 1.04 sec. BPR loss is 2.58E+01. Sample per second: 13144\n",
      "SLIM_BPR_Recommender: Epoch 472 of 650. Elapsed time 4.37 min\n",
      "Processed 13650 (100.0%) in 0.58 sec. BPR loss is 2.68E+01. Sample per second: 23431\n",
      "SLIM_BPR_Recommender: Epoch 473 of 650. Elapsed time 4.38 min\n",
      "Processed 13650 (100.0%) in 1.13 sec. BPR loss is 2.66E+01. Sample per second: 12060\n",
      "SLIM_BPR_Recommender: Epoch 474 of 650. Elapsed time 4.39 min\n",
      "Processed 13650 (100.0%) in 0.67 sec. BPR loss is 2.69E+01. Sample per second: 20336\n",
      "SLIM_BPR_Recommender: Epoch 475 of 650. Elapsed time 4.40 min\n",
      "Processed 13650 (100.0%) in 1.21 sec. BPR loss is 2.60E+01. Sample per second: 11289\n",
      "SLIM_BPR_Recommender: Epoch 476 of 650. Elapsed time 4.41 min\n",
      "Processed 13650 (100.0%) in 0.75 sec. BPR loss is 2.55E+01. Sample per second: 18212\n",
      "SLIM_BPR_Recommender: Epoch 477 of 650. Elapsed time 4.42 min\n",
      "Processed 13650 (100.0%) in 1.30 sec. BPR loss is 2.62E+01. Sample per second: 10478\n",
      "SLIM_BPR_Recommender: Epoch 478 of 650. Elapsed time 4.43 min\n",
      "Processed 13650 (100.0%) in 0.86 sec. BPR loss is 2.66E+01. Sample per second: 15839\n",
      "SLIM_BPR_Recommender: Epoch 479 of 650. Elapsed time 4.44 min\n",
      "Processed 13650 (100.0%) in 1.39 sec. BPR loss is 2.65E+01. Sample per second: 9818\n",
      "SLIM_BPR_Recommender: Epoch 480 of 650. Elapsed time 4.45 min\n",
      "Processed 13650 (100.0%) in 0.93 sec. BPR loss is 2.64E+01. Sample per second: 14730\n",
      "SLIM_BPR_Recommender: Epoch 481 of 650. Elapsed time 4.46 min\n",
      "Processed 13650 (100.0%) in 1.47 sec. BPR loss is 2.62E+01. Sample per second: 9297\n",
      "SLIM_BPR_Recommender: Epoch 482 of 650. Elapsed time 4.46 min\n",
      "Processed 13650 (100.0%) in 1.00 sec. BPR loss is 2.66E+01. Sample per second: 13586\n",
      "SLIM_BPR_Recommender: Epoch 483 of 650. Elapsed time 4.47 min\n",
      "Processed 13650 (100.0%) in 0.57 sec. BPR loss is 2.65E+01. Sample per second: 23741\n",
      "SLIM_BPR_Recommender: Epoch 484 of 650. Elapsed time 4.48 min\n",
      "Processed 13650 (100.0%) in 1.18 sec. BPR loss is 2.73E+01. Sample per second: 11556\n",
      "SLIM_BPR_Recommender: Epoch 485 of 650. Elapsed time 4.49 min\n",
      "Processed 13650 (100.0%) in 0.77 sec. BPR loss is 2.70E+01. Sample per second: 17743\n",
      "SLIM_BPR_Recommender: Epoch 486 of 650. Elapsed time 4.50 min\n",
      "Processed 13650 (100.0%) in 1.31 sec. BPR loss is 2.60E+01. Sample per second: 10382\n",
      "SLIM_BPR_Recommender: Epoch 487 of 650. Elapsed time 4.51 min\n",
      "Processed 13650 (100.0%) in 0.87 sec. BPR loss is 2.74E+01. Sample per second: 15671\n",
      "SLIM_BPR_Recommender: Epoch 488 of 650. Elapsed time 4.52 min\n",
      "Processed 13650 (100.0%) in 1.41 sec. BPR loss is 2.65E+01. Sample per second: 9680\n",
      "SLIM_BPR_Recommender: Epoch 489 of 650. Elapsed time 4.53 min\n",
      "Processed 13650 (100.0%) in 0.94 sec. BPR loss is 2.59E+01. Sample per second: 14479\n",
      "SLIM_BPR_Recommender: Epoch 490 of 650. Elapsed time 4.54 min\n",
      "Processed 13650 (100.0%) in 1.47 sec. BPR loss is 2.61E+01. Sample per second: 9286\n",
      "SLIM_BPR_Recommender: Epoch 491 of 650. Elapsed time 4.55 min\n",
      "Processed 13650 (100.0%) in 1.02 sec. BPR loss is 2.68E+01. Sample per second: 13358\n",
      "SLIM_BPR_Recommender: Epoch 492 of 650. Elapsed time 4.56 min\n",
      "Processed 13650 (100.0%) in 0.56 sec. BPR loss is 2.61E+01. Sample per second: 24179\n",
      "SLIM_BPR_Recommender: Epoch 493 of 650. Elapsed time 4.57 min\n",
      "Processed 13650 (100.0%) in 1.11 sec. BPR loss is 2.67E+01. Sample per second: 12270\n",
      "SLIM_BPR_Recommender: Epoch 494 of 650. Elapsed time 4.58 min\n",
      "Processed 13650 (100.0%) in 0.65 sec. BPR loss is 2.66E+01. Sample per second: 20883\n",
      "SLIM_BPR_Recommender: Epoch 495 of 650. Elapsed time 4.58 min\n",
      "Processed 13650 (100.0%) in 1.21 sec. BPR loss is 2.56E+01. Sample per second: 11313\n",
      "SLIM_BPR_Recommender: Epoch 496 of 650. Elapsed time 4.59 min\n",
      "Processed 13650 (100.0%) in 0.76 sec. BPR loss is 2.70E+01. Sample per second: 18067\n",
      "SLIM_BPR_Recommender: Epoch 497 of 650. Elapsed time 4.60 min\n",
      "Processed 13650 (100.0%) in 1.30 sec. BPR loss is 2.70E+01. Sample per second: 10522\n",
      "SLIM_BPR_Recommender: Epoch 498 of 650. Elapsed time 4.61 min\n",
      "Processed 13650 (100.0%) in 0.83 sec. BPR loss is 2.61E+01. Sample per second: 16449\n",
      "SLIM_BPR_Recommender: Epoch 499 of 650. Elapsed time 4.62 min\n",
      "Processed 13650 (100.0%) in 1.36 sec. BPR loss is 2.65E+01. Sample per second: 10005\n",
      "SLIM_BPR_Recommender: Epoch 500 of 650. Elapsed time 4.63 min\n",
      "Processed 13650 (100.0%) in 0.91 sec. BPR loss is 2.62E+01. Sample per second: 15043\n",
      "SLIM_BPR_Recommender: Epoch 501 of 650. Elapsed time 4.64 min\n",
      "Processed 13650 (100.0%) in 1.45 sec. BPR loss is 2.60E+01. Sample per second: 9421\n",
      "SLIM_BPR_Recommender: Epoch 502 of 650. Elapsed time 4.65 min\n",
      "Processed 13650 (100.0%) in 0.99 sec. BPR loss is 2.67E+01. Sample per second: 13716\n",
      "SLIM_BPR_Recommender: Epoch 503 of 650. Elapsed time 4.66 min\n",
      "Processed 13650 (100.0%) in 1.59 sec. BPR loss is 2.63E+01. Sample per second: 8560\n",
      "SLIM_BPR_Recommender: Epoch 504 of 650. Elapsed time 4.67 min\n",
      "Processed 13650 (100.0%) in 1.16 sec. BPR loss is 2.68E+01. Sample per second: 11805\n",
      "SLIM_BPR_Recommender: Epoch 505 of 650. Elapsed time 4.68 min\n",
      "Processed 13650 (100.0%) in 0.74 sec. BPR loss is 2.59E+01. Sample per second: 18535\n",
      "SLIM_BPR_Recommender: Epoch 506 of 650. Elapsed time 4.69 min\n",
      "Processed 13650 (100.0%) in 1.31 sec. BPR loss is 2.73E+01. Sample per second: 10427\n",
      "SLIM_BPR_Recommender: Epoch 507 of 650. Elapsed time 4.70 min\n",
      "Processed 13650 (100.0%) in 0.87 sec. BPR loss is 2.67E+01. Sample per second: 15653\n",
      "SLIM_BPR_Recommender: Epoch 508 of 650. Elapsed time 4.70 min\n",
      "Processed 13650 (100.0%) in 1.41 sec. BPR loss is 2.68E+01. Sample per second: 9674\n",
      "SLIM_BPR_Recommender: Epoch 509 of 650. Elapsed time 4.71 min\n",
      "Processed 13650 (100.0%) in 0.97 sec. BPR loss is 2.57E+01. Sample per second: 14036\n",
      "SLIM_BPR_Recommender: Epoch 510 of 650. Elapsed time 4.72 min\n",
      "Processed 13650 (100.0%) in 1.53 sec. BPR loss is 2.66E+01. Sample per second: 8929\n",
      "SLIM_BPR_Recommender: Epoch 511 of 650. Elapsed time 4.73 min\n",
      "Processed 13650 (100.0%) in 1.08 sec. BPR loss is 2.64E+01. Sample per second: 12650\n",
      "SLIM_BPR_Recommender: Epoch 512 of 650. Elapsed time 4.74 min\n",
      "Processed 13650 (100.0%) in 0.63 sec. BPR loss is 2.84E+01. Sample per second: 21784\n",
      "SLIM_BPR_Recommender: Epoch 513 of 650. Elapsed time 4.75 min\n",
      "Processed 13650 (100.0%) in 1.18 sec. BPR loss is 2.67E+01. Sample per second: 11566\n",
      "SLIM_BPR_Recommender: Epoch 514 of 650. Elapsed time 4.76 min\n",
      "Processed 13650 (100.0%) in 0.74 sec. BPR loss is 2.70E+01. Sample per second: 18512\n",
      "SLIM_BPR_Recommender: Epoch 515 of 650. Elapsed time 4.77 min\n",
      "Processed 13650 (100.0%) in 1.29 sec. BPR loss is 2.68E+01. Sample per second: 10570\n",
      "SLIM_BPR_Recommender: Epoch 516 of 650. Elapsed time 4.78 min\n",
      "Processed 13650 (100.0%) in 0.83 sec. BPR loss is 2.67E+01. Sample per second: 16452\n",
      "SLIM_BPR_Recommender: Epoch 517 of 650. Elapsed time 4.79 min\n",
      "Processed 13650 (100.0%) in 1.37 sec. BPR loss is 2.64E+01. Sample per second: 9969\n",
      "SLIM_BPR_Recommender: Epoch 518 of 650. Elapsed time 4.80 min\n",
      "Processed 13650 (100.0%) in 0.91 sec. BPR loss is 2.78E+01. Sample per second: 15047\n",
      "SLIM_BPR_Recommender: Epoch 519 of 650. Elapsed time 4.81 min\n",
      "Processed 13650 (100.0%) in 1.44 sec. BPR loss is 2.68E+01. Sample per second: 9475\n",
      "SLIM_BPR_Recommender: Epoch 520 of 650. Elapsed time 4.81 min\n",
      "Processed 13650 (100.0%) in 0.98 sec. BPR loss is 2.67E+01. Sample per second: 13981\n",
      "SLIM_BPR_Recommender: Epoch 521 of 650. Elapsed time 4.82 min\n",
      "Processed 13650 (100.0%) in 1.52 sec. BPR loss is 2.73E+01. Sample per second: 8991\n",
      "SLIM_BPR_Recommender: Epoch 522 of 650. Elapsed time 4.83 min\n",
      "Processed 13650 (100.0%) in 1.06 sec. BPR loss is 2.63E+01. Sample per second: 12934\n",
      "SLIM_BPR_Recommender: Epoch 523 of 650. Elapsed time 4.84 min\n",
      "Processed 13650 (100.0%) in 0.62 sec. BPR loss is 2.71E+01. Sample per second: 21882\n",
      "SLIM_BPR_Recommender: Epoch 524 of 650. Elapsed time 4.85 min\n",
      "Processed 13650 (100.0%) in 1.17 sec. BPR loss is 2.76E+01. Sample per second: 11671\n",
      "SLIM_BPR_Recommender: Epoch 525 of 650. Elapsed time 4.86 min\n",
      "Processed 13650 (100.0%) in 0.71 sec. BPR loss is 2.72E+01. Sample per second: 19126\n",
      "SLIM_BPR_Recommender: Epoch 526 of 650. Elapsed time 4.87 min\n",
      "Processed 13650 (100.0%) in 1.26 sec. BPR loss is 2.68E+01. Sample per second: 10872\n",
      "SLIM_BPR_Recommender: Epoch 527 of 650. Elapsed time 4.88 min\n",
      "Processed 13650 (100.0%) in 0.81 sec. BPR loss is 2.67E+01. Sample per second: 16874\n",
      "SLIM_BPR_Recommender: Epoch 528 of 650. Elapsed time 4.89 min\n",
      "Processed 13650 (100.0%) in 1.37 sec. BPR loss is 2.64E+01. Sample per second: 9998\n",
      "SLIM_BPR_Recommender: Epoch 529 of 650. Elapsed time 4.90 min\n",
      "Processed 13650 (100.0%) in 0.91 sec. BPR loss is 2.67E+01. Sample per second: 14991\n",
      "SLIM_BPR_Recommender: Epoch 530 of 650. Elapsed time 4.91 min\n",
      "Processed 13650 (100.0%) in 1.46 sec. BPR loss is 2.65E+01. Sample per second: 9333\n",
      "SLIM_BPR_Recommender: Epoch 531 of 650. Elapsed time 4.91 min\n",
      "Processed 13650 (100.0%) in 1.02 sec. BPR loss is 2.70E+01. Sample per second: 13322\n",
      "SLIM_BPR_Recommender: Epoch 532 of 650. Elapsed time 4.92 min\n",
      "Processed 13650 (100.0%) in 0.58 sec. BPR loss is 2.69E+01. Sample per second: 23661\n",
      "SLIM_BPR_Recommender: Epoch 533 of 650. Elapsed time 4.93 min\n",
      "Processed 13650 (100.0%) in 1.12 sec. BPR loss is 2.70E+01. Sample per second: 12216\n",
      "SLIM_BPR_Recommender: Epoch 534 of 650. Elapsed time 4.94 min\n",
      "Processed 13650 (100.0%) in 0.65 sec. BPR loss is 2.63E+01. Sample per second: 21024\n",
      "SLIM_BPR_Recommender: Epoch 535 of 650. Elapsed time 4.95 min\n",
      "Processed 13650 (100.0%) in 1.19 sec. BPR loss is 2.69E+01. Sample per second: 11457\n",
      "SLIM_BPR_Recommender: Epoch 536 of 650. Elapsed time 4.96 min\n",
      "Processed 13650 (100.0%) in 0.74 sec. BPR loss is 2.61E+01. Sample per second: 18528\n",
      "SLIM_BPR_Recommender: Epoch 537 of 650. Elapsed time 4.97 min\n",
      "Processed 13650 (100.0%) in 1.27 sec. BPR loss is 2.63E+01. Sample per second: 10731\n",
      "SLIM_BPR_Recommender: Epoch 538 of 650. Elapsed time 4.98 min\n",
      "Processed 13650 (100.0%) in 0.82 sec. BPR loss is 2.69E+01. Sample per second: 16696\n",
      "SLIM_BPR_Recommender: Epoch 539 of 650. Elapsed time 4.99 min\n",
      "Processed 13650 (100.0%) in 1.36 sec. BPR loss is 2.68E+01. Sample per second: 10015\n",
      "SLIM_BPR_Recommender: Epoch 540 of 650. Elapsed time 5.00 min\n",
      "Processed 13650 (100.0%) in 0.90 sec. BPR loss is 2.69E+01. Sample per second: 15125\n",
      "SLIM_BPR_Recommender: Epoch 541 of 650. Elapsed time 5.01 min\n",
      "Processed 13650 (100.0%) in 1.44 sec. BPR loss is 2.73E+01. Sample per second: 9510\n",
      "SLIM_BPR_Recommender: Epoch 542 of 650. Elapsed time 5.01 min\n",
      "Processed 13650 (100.0%) in 1.02 sec. BPR loss is 2.71E+01. Sample per second: 13346\n",
      "SLIM_BPR_Recommender: Epoch 543 of 650. Elapsed time 5.02 min\n",
      "Processed 13650 (100.0%) in 0.62 sec. BPR loss is 2.70E+01. Sample per second: 22029\n",
      "SLIM_BPR_Recommender: Epoch 544 of 650. Elapsed time 5.03 min\n",
      "Processed 13650 (100.0%) in 1.16 sec. BPR loss is 2.66E+01. Sample per second: 11812\n",
      "SLIM_BPR_Recommender: Epoch 545 of 650. Elapsed time 5.04 min\n",
      "Processed 13650 (100.0%) in 0.70 sec. BPR loss is 2.69E+01. Sample per second: 19633\n",
      "SLIM_BPR_Recommender: Epoch 546 of 650. Elapsed time 5.05 min\n",
      "Processed 13650 (100.0%) in 1.22 sec. BPR loss is 2.61E+01. Sample per second: 11193\n",
      "SLIM_BPR_Recommender: Epoch 547 of 650. Elapsed time 5.06 min\n",
      "Processed 13650 (100.0%) in 0.75 sec. BPR loss is 2.59E+01. Sample per second: 18204\n",
      "SLIM_BPR_Recommender: Epoch 548 of 650. Elapsed time 5.07 min\n",
      "Processed 13650 (100.0%) in 1.30 sec. BPR loss is 2.63E+01. Sample per second: 10494\n",
      "SLIM_BPR_Recommender: Epoch 549 of 650. Elapsed time 5.08 min\n",
      "Processed 13650 (100.0%) in 0.85 sec. BPR loss is 2.70E+01. Sample per second: 16114\n",
      "SLIM_BPR_Recommender: Epoch 550 of 650. Elapsed time 5.09 min\n",
      "Processed 13650 (100.0%) in 1.38 sec. BPR loss is 2.58E+01. Sample per second: 9915\n",
      "SLIM_BPR_Recommender: Epoch 551 of 650. Elapsed time 5.10 min\n",
      "Processed 13650 (100.0%) in 0.91 sec. BPR loss is 2.73E+01. Sample per second: 15060\n",
      "SLIM_BPR_Recommender: Epoch 552 of 650. Elapsed time 5.11 min\n",
      "Processed 13650 (100.0%) in 1.44 sec. BPR loss is 2.70E+01. Sample per second: 9483\n",
      "SLIM_BPR_Recommender: Epoch 553 of 650. Elapsed time 5.11 min\n",
      "Processed 13650 (100.0%) in 0.98 sec. BPR loss is 2.66E+01. Sample per second: 13983\n",
      "SLIM_BPR_Recommender: Epoch 554 of 650. Elapsed time 5.12 min\n",
      "Processed 13650 (100.0%) in 1.51 sec. BPR loss is 2.62E+01. Sample per second: 9053\n",
      "SLIM_BPR_Recommender: Epoch 555 of 650. Elapsed time 5.13 min\n",
      "Processed 13650 (100.0%) in 1.05 sec. BPR loss is 2.61E+01. Sample per second: 12968\n",
      "SLIM_BPR_Recommender: Epoch 556 of 650. Elapsed time 5.14 min\n",
      "Processed 13650 (100.0%) in 0.59 sec. BPR loss is 2.75E+01. Sample per second: 23007\n",
      "SLIM_BPR_Recommender: Epoch 557 of 650. Elapsed time 5.15 min\n",
      "Processed 13650 (100.0%) in 1.13 sec. BPR loss is 2.65E+01. Sample per second: 12060\n",
      "SLIM_BPR_Recommender: Epoch 558 of 650. Elapsed time 5.16 min\n",
      "Processed 13650 (100.0%) in 0.68 sec. BPR loss is 2.71E+01. Sample per second: 19990\n",
      "SLIM_BPR_Recommender: Epoch 559 of 650. Elapsed time 5.17 min\n",
      "Processed 13650 (100.0%) in 1.22 sec. BPR loss is 2.65E+01. Sample per second: 11178\n",
      "SLIM_BPR_Recommender: Epoch 560 of 650. Elapsed time 5.18 min\n",
      "Processed 13650 (100.0%) in 0.76 sec. BPR loss is 2.69E+01. Sample per second: 17871\n",
      "SLIM_BPR_Recommender: Epoch 561 of 650. Elapsed time 5.19 min\n",
      "Processed 13650 (100.0%) in 1.29 sec. BPR loss is 2.75E+01. Sample per second: 10549\n",
      "SLIM_BPR_Recommender: Epoch 562 of 650. Elapsed time 5.20 min\n",
      "Processed 13650 (100.0%) in 0.83 sec. BPR loss is 2.64E+01. Sample per second: 16377\n",
      "SLIM_BPR_Recommender: Epoch 563 of 650. Elapsed time 5.20 min\n",
      "Processed 13650 (100.0%) in 1.41 sec. BPR loss is 2.69E+01. Sample per second: 9711\n",
      "SLIM_BPR_Recommender: Epoch 564 of 650. Elapsed time 5.21 min\n",
      "Processed 13650 (100.0%) in 0.95 sec. BPR loss is 2.76E+01. Sample per second: 14379\n",
      "SLIM_BPR_Recommender: Epoch 565 of 650. Elapsed time 5.22 min\n",
      "Processed 13650 (100.0%) in 1.49 sec. BPR loss is 2.82E+01. Sample per second: 9175\n",
      "SLIM_BPR_Recommender: Epoch 566 of 650. Elapsed time 5.23 min\n",
      "Processed 13650 (100.0%) in 1.04 sec. BPR loss is 2.69E+01. Sample per second: 13093\n",
      "SLIM_BPR_Recommender: Epoch 567 of 650. Elapsed time 5.24 min\n",
      "Processed 13650 (100.0%) in 0.59 sec. BPR loss is 2.85E+01. Sample per second: 22960\n",
      "SLIM_BPR_Recommender: Epoch 568 of 650. Elapsed time 5.25 min\n",
      "Processed 13650 (100.0%) in 1.14 sec. BPR loss is 2.75E+01. Sample per second: 11978\n",
      "SLIM_BPR_Recommender: Epoch 569 of 650. Elapsed time 5.26 min\n",
      "Processed 13650 (100.0%) in 0.70 sec. BPR loss is 2.69E+01. Sample per second: 19547\n",
      "SLIM_BPR_Recommender: Epoch 570 of 650. Elapsed time 5.27 min\n",
      "Processed 13650 (100.0%) in 1.25 sec. BPR loss is 2.68E+01. Sample per second: 10884\n",
      "SLIM_BPR_Recommender: Epoch 571 of 650. Elapsed time 5.28 min\n",
      "Processed 13650 (100.0%) in 0.80 sec. BPR loss is 2.77E+01. Sample per second: 17058\n",
      "SLIM_BPR_Recommender: Epoch 572 of 650. Elapsed time 5.29 min\n",
      "Processed 13650 (100.0%) in 1.34 sec. BPR loss is 2.75E+01. Sample per second: 10168\n",
      "SLIM_BPR_Recommender: Epoch 573 of 650. Elapsed time 5.30 min\n",
      "Processed 13650 (100.0%) in 0.89 sec. BPR loss is 2.64E+01. Sample per second: 15281\n",
      "SLIM_BPR_Recommender: Epoch 574 of 650. Elapsed time 5.31 min\n",
      "Processed 13650 (100.0%) in 1.44 sec. BPR loss is 2.74E+01. Sample per second: 9497\n",
      "SLIM_BPR_Recommender: Epoch 575 of 650. Elapsed time 5.31 min\n",
      "Processed 13650 (100.0%) in 0.98 sec. BPR loss is 2.83E+01. Sample per second: 13959\n",
      "SLIM_BPR_Recommender: Epoch 576 of 650. Elapsed time 5.32 min\n",
      "Processed 13650 (100.0%) in 1.51 sec. BPR loss is 2.74E+01. Sample per second: 9017\n",
      "SLIM_BPR_Recommender: Epoch 577 of 650. Elapsed time 5.33 min\n",
      "Processed 13650 (100.0%) in 1.07 sec. BPR loss is 2.71E+01. Sample per second: 12792\n",
      "SLIM_BPR_Recommender: Epoch 578 of 650. Elapsed time 5.34 min\n",
      "Processed 13650 (100.0%) in 0.61 sec. BPR loss is 2.65E+01. Sample per second: 22478\n",
      "SLIM_BPR_Recommender: Epoch 579 of 650. Elapsed time 5.35 min\n",
      "Processed 13650 (100.0%) in 1.13 sec. BPR loss is 2.62E+01. Sample per second: 12041\n",
      "SLIM_BPR_Recommender: Epoch 580 of 650. Elapsed time 5.36 min\n",
      "Processed 13650 (100.0%) in 0.66 sec. BPR loss is 2.70E+01. Sample per second: 20518\n",
      "SLIM_BPR_Recommender: Epoch 581 of 650. Elapsed time 5.37 min\n",
      "Processed 13650 (100.0%) in 1.20 sec. BPR loss is 2.66E+01. Sample per second: 11374\n",
      "SLIM_BPR_Recommender: Epoch 582 of 650. Elapsed time 5.38 min\n",
      "Processed 13650 (100.0%) in 0.74 sec. BPR loss is 2.68E+01. Sample per second: 18374\n",
      "SLIM_BPR_Recommender: Epoch 583 of 650. Elapsed time 5.39 min\n",
      "Processed 13650 (100.0%) in 1.30 sec. BPR loss is 2.78E+01. Sample per second: 10472\n",
      "SLIM_BPR_Recommender: Epoch 584 of 650. Elapsed time 5.40 min\n",
      "Processed 13650 (100.0%) in 0.85 sec. BPR loss is 2.67E+01. Sample per second: 16123\n",
      "SLIM_BPR_Recommender: Epoch 585 of 650. Elapsed time 5.40 min\n",
      "Processed 13650 (100.0%) in 1.40 sec. BPR loss is 2.72E+01. Sample per second: 9776\n",
      "SLIM_BPR_Recommender: Epoch 586 of 650. Elapsed time 5.41 min\n",
      "Processed 13650 (100.0%) in 0.94 sec. BPR loss is 2.66E+01. Sample per second: 14577\n",
      "SLIM_BPR_Recommender: Epoch 587 of 650. Elapsed time 5.42 min\n",
      "Processed 13650 (100.0%) in 1.48 sec. BPR loss is 2.72E+01. Sample per second: 9237\n",
      "SLIM_BPR_Recommender: Epoch 588 of 650. Elapsed time 5.43 min\n",
      "Processed 13650 (100.0%) in 1.03 sec. BPR loss is 2.73E+01. Sample per second: 13186\n",
      "SLIM_BPR_Recommender: Epoch 589 of 650. Elapsed time 5.44 min\n",
      "Processed 13650 (100.0%) in 0.57 sec. BPR loss is 2.84E+01. Sample per second: 23871\n",
      "SLIM_BPR_Recommender: Epoch 590 of 650. Elapsed time 5.45 min\n",
      "Processed 13650 (100.0%) in 1.10 sec. BPR loss is 2.64E+01. Sample per second: 12437\n",
      "SLIM_BPR_Recommender: Epoch 591 of 650. Elapsed time 5.46 min\n",
      "Processed 13650 (100.0%) in 0.64 sec. BPR loss is 2.77E+01. Sample per second: 21450\n",
      "SLIM_BPR_Recommender: Epoch 592 of 650. Elapsed time 5.47 min\n",
      "Processed 13650 (100.0%) in 1.18 sec. BPR loss is 2.68E+01. Sample per second: 11542\n",
      "SLIM_BPR_Recommender: Epoch 593 of 650. Elapsed time 5.48 min\n",
      "Processed 13650 (100.0%) in 0.73 sec. BPR loss is 2.64E+01. Sample per second: 18667\n",
      "SLIM_BPR_Recommender: Epoch 594 of 650. Elapsed time 5.49 min\n",
      "Processed 13650 (100.0%) in 1.27 sec. BPR loss is 2.73E+01. Sample per second: 10729\n",
      "SLIM_BPR_Recommender: Epoch 595 of 650. Elapsed time 5.49 min\n",
      "Processed 13650 (100.0%) in 0.80 sec. BPR loss is 2.71E+01. Sample per second: 17084\n",
      "SLIM_BPR_Recommender: Epoch 596 of 650. Elapsed time 5.50 min\n",
      "Processed 13650 (100.0%) in 1.34 sec. BPR loss is 2.74E+01. Sample per second: 10187\n",
      "SLIM_BPR_Recommender: Epoch 597 of 650. Elapsed time 5.51 min\n",
      "Processed 13650 (100.0%) in 0.88 sec. BPR loss is 2.76E+01. Sample per second: 15577\n",
      "SLIM_BPR_Recommender: Epoch 598 of 650. Elapsed time 5.52 min\n",
      "Processed 13650 (100.0%) in 1.41 sec. BPR loss is 2.64E+01. Sample per second: 9691\n",
      "SLIM_BPR_Recommender: Epoch 599 of 650. Elapsed time 5.53 min\n",
      "Processed 13650 (100.0%) in 0.95 sec. BPR loss is 2.76E+01. Sample per second: 14400\n",
      "SLIM_BPR_Recommender: Epoch 600 of 650. Elapsed time 5.54 min\n",
      "Processed 13650 (100.0%) in 1.50 sec. BPR loss is 2.79E+01. Sample per second: 9120\n",
      "SLIM_BPR_Recommender: Epoch 601 of 650. Elapsed time 5.55 min\n",
      "Processed 13650 (100.0%) in 1.10 sec. BPR loss is 2.69E+01. Sample per second: 12435\n",
      "SLIM_BPR_Recommender: Epoch 602 of 650. Elapsed time 5.56 min\n",
      "Processed 13650 (100.0%) in 0.64 sec. BPR loss is 2.62E+01. Sample per second: 21456\n",
      "SLIM_BPR_Recommender: Epoch 603 of 650. Elapsed time 5.57 min\n",
      "Processed 13650 (100.0%) in 1.19 sec. BPR loss is 2.74E+01. Sample per second: 11489\n",
      "SLIM_BPR_Recommender: Epoch 604 of 650. Elapsed time 5.58 min\n",
      "Processed 13650 (100.0%) in 0.75 sec. BPR loss is 2.73E+01. Sample per second: 18081\n",
      "SLIM_BPR_Recommender: Epoch 605 of 650. Elapsed time 5.59 min\n",
      "Processed 13650 (100.0%) in 1.29 sec. BPR loss is 2.70E+01. Sample per second: 10592\n",
      "SLIM_BPR_Recommender: Epoch 606 of 650. Elapsed time 5.60 min\n",
      "Processed 13650 (100.0%) in 0.84 sec. BPR loss is 2.67E+01. Sample per second: 16212\n",
      "SLIM_BPR_Recommender: Epoch 607 of 650. Elapsed time 5.60 min\n",
      "Processed 13650 (100.0%) in 1.39 sec. BPR loss is 2.72E+01. Sample per second: 9831\n",
      "SLIM_BPR_Recommender: Epoch 608 of 650. Elapsed time 5.61 min\n",
      "Processed 13650 (100.0%) in 0.94 sec. BPR loss is 2.74E+01. Sample per second: 14566\n",
      "SLIM_BPR_Recommender: Epoch 609 of 650. Elapsed time 5.62 min\n",
      "Processed 13650 (100.0%) in 1.48 sec. BPR loss is 2.73E+01. Sample per second: 9237\n",
      "SLIM_BPR_Recommender: Epoch 610 of 650. Elapsed time 5.63 min\n",
      "Processed 13650 (100.0%) in 1.02 sec. BPR loss is 2.70E+01. Sample per second: 13380\n",
      "SLIM_BPR_Recommender: Epoch 611 of 650. Elapsed time 5.64 min\n",
      "Processed 13650 (100.0%) in 0.56 sec. BPR loss is 2.72E+01. Sample per second: 24571\n",
      "SLIM_BPR_Recommender: Epoch 612 of 650. Elapsed time 5.65 min\n",
      "Processed 13650 (100.0%) in 1.08 sec. BPR loss is 2.77E+01. Sample per second: 12598\n",
      "SLIM_BPR_Recommender: Epoch 613 of 650. Elapsed time 5.66 min\n",
      "Processed 13650 (100.0%) in 0.62 sec. BPR loss is 2.85E+01. Sample per second: 21945\n",
      "SLIM_BPR_Recommender: Epoch 614 of 650. Elapsed time 5.67 min\n",
      "Processed 13650 (100.0%) in 1.17 sec. BPR loss is 2.74E+01. Sample per second: 11645\n",
      "SLIM_BPR_Recommender: Epoch 615 of 650. Elapsed time 5.68 min\n",
      "Processed 13650 (100.0%) in 0.71 sec. BPR loss is 2.68E+01. Sample per second: 19344\n",
      "SLIM_BPR_Recommender: Epoch 616 of 650. Elapsed time 5.69 min\n",
      "Processed 13650 (100.0%) in 1.24 sec. BPR loss is 2.77E+01. Sample per second: 10972\n",
      "SLIM_BPR_Recommender: Epoch 617 of 650. Elapsed time 5.69 min\n",
      "Processed 13650 (100.0%) in 0.79 sec. BPR loss is 2.83E+01. Sample per second: 17300\n",
      "SLIM_BPR_Recommender: Epoch 618 of 650. Elapsed time 5.70 min\n",
      "Processed 13650 (100.0%) in 1.33 sec. BPR loss is 2.73E+01. Sample per second: 10298\n",
      "SLIM_BPR_Recommender: Epoch 619 of 650. Elapsed time 5.71 min\n",
      "Processed 13650 (100.0%) in 0.87 sec. BPR loss is 2.84E+01. Sample per second: 15709\n",
      "SLIM_BPR_Recommender: Epoch 620 of 650. Elapsed time 5.72 min\n",
      "Processed 13650 (100.0%) in 1.41 sec. BPR loss is 2.65E+01. Sample per second: 9658\n",
      "SLIM_BPR_Recommender: Epoch 621 of 650. Elapsed time 5.73 min\n",
      "Processed 13650 (100.0%) in 0.95 sec. BPR loss is 2.71E+01. Sample per second: 14372\n",
      "SLIM_BPR_Recommender: Epoch 622 of 650. Elapsed time 5.74 min\n",
      "Processed 13650 (100.0%) in 1.51 sec. BPR loss is 2.81E+01. Sample per second: 9061\n",
      "SLIM_BPR_Recommender: Epoch 623 of 650. Elapsed time 5.75 min\n",
      "Processed 13650 (100.0%) in 1.06 sec. BPR loss is 2.75E+01. Sample per second: 12912\n",
      "SLIM_BPR_Recommender: Epoch 624 of 650. Elapsed time 5.76 min\n",
      "Processed 13650 (100.0%) in 0.64 sec. BPR loss is 2.74E+01. Sample per second: 21363\n",
      "SLIM_BPR_Recommender: Epoch 625 of 650. Elapsed time 5.77 min\n",
      "Processed 13650 (100.0%) in 1.18 sec. BPR loss is 2.79E+01. Sample per second: 11573\n",
      "SLIM_BPR_Recommender: Epoch 626 of 650. Elapsed time 5.78 min\n",
      "Processed 13650 (100.0%) in 0.74 sec. BPR loss is 2.69E+01. Sample per second: 18521\n",
      "SLIM_BPR_Recommender: Epoch 627 of 650. Elapsed time 5.79 min\n",
      "Processed 13650 (100.0%) in 1.28 sec. BPR loss is 2.80E+01. Sample per second: 10651\n",
      "SLIM_BPR_Recommender: Epoch 628 of 650. Elapsed time 5.79 min\n",
      "Processed 13650 (100.0%) in 0.82 sec. BPR loss is 2.81E+01. Sample per second: 16741\n",
      "SLIM_BPR_Recommender: Epoch 629 of 650. Elapsed time 5.80 min\n",
      "Processed 13650 (100.0%) in 1.36 sec. BPR loss is 2.73E+01. Sample per second: 9998\n",
      "SLIM_BPR_Recommender: Epoch 630 of 650. Elapsed time 5.81 min\n",
      "Processed 13650 (100.0%) in 0.90 sec. BPR loss is 2.68E+01. Sample per second: 15083\n",
      "SLIM_BPR_Recommender: Epoch 631 of 650. Elapsed time 5.82 min\n",
      "Processed 13650 (100.0%) in 1.45 sec. BPR loss is 2.77E+01. Sample per second: 9439\n",
      "SLIM_BPR_Recommender: Epoch 632 of 650. Elapsed time 5.83 min\n",
      "Processed 13650 (100.0%) in 1.00 sec. BPR loss is 2.76E+01. Sample per second: 13646\n",
      "SLIM_BPR_Recommender: Epoch 633 of 650. Elapsed time 5.84 min\n",
      "Processed 13650 (100.0%) in 0.54 sec. BPR loss is 2.85E+01. Sample per second: 25082\n",
      "SLIM_BPR_Recommender: Epoch 634 of 650. Elapsed time 5.85 min\n",
      "Processed 13650 (100.0%) in 1.08 sec. BPR loss is 2.76E+01. Sample per second: 12670\n",
      "SLIM_BPR_Recommender: Epoch 635 of 650. Elapsed time 5.86 min\n",
      "Processed 13650 (100.0%) in 0.62 sec. BPR loss is 2.78E+01. Sample per second: 22069\n",
      "SLIM_BPR_Recommender: Epoch 636 of 650. Elapsed time 5.87 min\n",
      "Processed 13650 (100.0%) in 1.16 sec. BPR loss is 2.68E+01. Sample per second: 11740\n",
      "SLIM_BPR_Recommender: Epoch 637 of 650. Elapsed time 5.88 min\n",
      "Processed 13650 (100.0%) in 0.71 sec. BPR loss is 2.80E+01. Sample per second: 19114\n",
      "SLIM_BPR_Recommender: Epoch 638 of 650. Elapsed time 5.89 min\n",
      "Processed 13650 (100.0%) in 1.26 sec. BPR loss is 2.71E+01. Sample per second: 10838\n",
      "SLIM_BPR_Recommender: Epoch 639 of 650. Elapsed time 5.89 min\n",
      "Processed 13650 (100.0%) in 0.79 sec. BPR loss is 2.70E+01. Sample per second: 17249\n",
      "SLIM_BPR_Recommender: Epoch 640 of 650. Elapsed time 5.90 min\n",
      "Processed 13650 (100.0%) in 1.35 sec. BPR loss is 2.70E+01. Sample per second: 10081\n",
      "SLIM_BPR_Recommender: Epoch 641 of 650. Elapsed time 5.91 min\n",
      "Processed 13650 (100.0%) in 0.92 sec. BPR loss is 2.73E+01. Sample per second: 14911\n",
      "SLIM_BPR_Recommender: Epoch 642 of 650. Elapsed time 5.92 min\n",
      "Processed 13650 (100.0%) in 1.49 sec. BPR loss is 2.81E+01. Sample per second: 9188\n",
      "SLIM_BPR_Recommender: Epoch 643 of 650. Elapsed time 5.93 min\n",
      "Processed 13650 (100.0%) in 1.05 sec. BPR loss is 2.79E+01. Sample per second: 13041\n",
      "SLIM_BPR_Recommender: Epoch 644 of 650. Elapsed time 5.94 min\n",
      "Processed 13650 (100.0%) in 0.64 sec. BPR loss is 2.95E+01. Sample per second: 21251\n",
      "SLIM_BPR_Recommender: Epoch 645 of 650. Elapsed time 5.95 min\n",
      "Processed 13650 (100.0%) in 1.18 sec. BPR loss is 2.74E+01. Sample per second: 11569\n",
      "SLIM_BPR_Recommender: Epoch 646 of 650. Elapsed time 5.96 min\n",
      "Processed 13650 (100.0%) in 0.72 sec. BPR loss is 2.78E+01. Sample per second: 18934\n",
      "SLIM_BPR_Recommender: Epoch 647 of 650. Elapsed time 5.97 min\n",
      "Processed 13650 (100.0%) in 1.27 sec. BPR loss is 2.80E+01. Sample per second: 10780\n",
      "SLIM_BPR_Recommender: Epoch 648 of 650. Elapsed time 5.98 min\n",
      "Processed 13650 (100.0%) in 0.81 sec. BPR loss is 2.84E+01. Sample per second: 16867\n",
      "SLIM_BPR_Recommender: Epoch 649 of 650. Elapsed time 5.99 min\n",
      "Processed 13650 (100.0%) in 1.36 sec. BPR loss is 2.77E+01. Sample per second: 10010\n",
      "SLIM_BPR_Recommender: Epoch 650 of 650. Elapsed time 6.00 min\n",
      "SLIM_BPR_Recommender: Terminating at epoch 650. Elapsed time 6.40 min\n",
      "Deallocating Cython objects\n"
     ]
    }
   ],
   "source": [
    "from Recommenders.SLIM.Cython.SLIM_BPR_Cython import SLIM_BPR_Cython\n",
    "recommender_SLIM_BPR_Cython = SLIM_BPR_Cython(URM_train)\n",
    "recommender_SLIM_BPR_Cython.fit(epochs=650, sgd_mode = \"sgd\", topK = 483, lambda_i = 0.0006712905081189398, \n",
    "                lambda_j = 0.06584150350451998, learning_rate = 0.0036482363905043207)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72dc2219",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-10T18:13:48.730169Z",
     "iopub.status.busy": "2021-12-10T18:13:48.729345Z",
     "iopub.status.idle": "2021-12-10T18:13:51.601792Z",
     "shell.execute_reply": "2021-12-10T18:13:51.602680Z",
     "shell.execute_reply.started": "2021-12-09T16:39:52.930249Z"
    },
    "papermill": {
     "duration": 3.300899,
     "end_time": "2021-12-10T18:13:51.603012",
     "exception": false,
     "start_time": "2021-12-10T18:13:48.302113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PureSVDRecommender: Computing SVD decomposition...\n",
      "PureSVDRecommender: Computing SVD decomposition... done in 2.76 sec\n"
     ]
    }
   ],
   "source": [
    "from Recommenders.MatrixFactorization.PureSVDRecommender import PureSVDRecommender\n",
    "\n",
    "#try a simple PureSVD recommender\n",
    "recommender_pureSVD = PureSVDRecommender(URM_train)\n",
    "recommender_pureSVD.fit(num_factors=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52b78f19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-10T18:13:52.625029Z",
     "iopub.status.busy": "2021-12-10T18:13:52.624307Z",
     "iopub.status.idle": "2021-12-10T18:14:55.439779Z",
     "shell.execute_reply": "2021-12-10T18:14:55.440330Z",
     "shell.execute_reply.started": "2021-12-09T16:45:56.493857Z"
    },
    "papermill": {
     "duration": 63.363525,
     "end_time": "2021-12-10T18:14:55.440557",
     "exception": false,
     "start_time": "2021-12-10T18:13:52.077032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP of the starting models\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 25.26 sec. Users per second: 540\n",
      "SLIM ElasticNet - MAP: 0.24585284309141175\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 23.98 sec. Users per second: 569\n",
      "SLIM BPR - MAP: 0.23818227156513022\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 13.53 sec. Users per second: 1009\n",
      "PURE SVD - MAP: 0.22963454317678955\n"
     ]
    }
   ],
   "source": [
    "print(\"MAP of the starting models\")\n",
    "\n",
    "result_df, _ = evaluator_valid.evaluateRecommender(recommender_SLIMElasticNet)\n",
    "print(\"SLIM ElasticNet - MAP: {}\".format(result_df.loc[10][\"MAP\"]))\n",
    "\n",
    "result_df, _ = evaluator_valid.evaluateRecommender(recommender_SLIM_BPR_Cython)\n",
    "print(\"SLIM BPR - MAP: {}\".format(result_df.loc[10][\"MAP\"]))\n",
    "\n",
    "result_df, _ = evaluator_valid.evaluateRecommender(recommender_pureSVD)\n",
    "print(\"PURE SVD - MAP: {}\".format(result_df.loc[10][\"MAP\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f906dd00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-10T18:14:56.306677Z",
     "iopub.status.busy": "2021-12-10T18:14:56.303573Z",
     "iopub.status.idle": "2021-12-10T18:14:56.309947Z",
     "shell.execute_reply": "2021-12-10T18:14:56.309343Z",
     "shell.execute_reply.started": "2021-12-09T16:47:49.914135Z"
    },
    "papermill": {
     "duration": 0.445043,
     "end_time": "2021-12-10T18:14:56.310098",
     "exception": false,
     "start_time": "2021-12-10T18:14:55.865055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "from Recommenders.BaseRecommender import BaseRecommender\n",
    "\n",
    "class DifferentLossScoresHybridRecommender(BaseRecommender):\n",
    "    \"\"\" ScoresHybridRecommender\n",
    "    Hybrid of three predictions scores\n",
    "    R = R1*alpha + R2*beta + R3*(1-alpha-beta)\n",
    "    \n",
    "    Class from Dacrema exercise modified by Antonio Ercolani\n",
    "    The original took as input 2 recommender\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    RECOMMENDER_NAME = \"DifferentLossScoresHybridRecommender\"\n",
    "\n",
    "\n",
    "    def __init__(self, URM_train, recommender_1, recommender_2, recommender_3):\n",
    "        super(DifferentLossScoresHybridRecommender, self).__init__(URM_train)\n",
    "\n",
    "        self.URM_train = sps.csr_matrix(URM_train)\n",
    "        self.recommender_1 = recommender_1\n",
    "        self.recommender_2 = recommender_2\n",
    "        self.recommender_3 = recommender_3\n",
    "        \n",
    "        \n",
    "        \n",
    "    def fit(self, norm, alpha = 0.5, beta = 0.5):\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.norm = norm\n",
    "\n",
    "\n",
    "    def _compute_item_score(self, user_id_array, items_to_compute):\n",
    "        \n",
    "        item_weights_1 = self.recommender_1._compute_item_score(user_id_array)\n",
    "        item_weights_2 = self.recommender_2._compute_item_score(user_id_array)\n",
    "        item_weights_3 = self.recommender_3._compute_item_score(user_id_array)\n",
    "\n",
    "        norm_item_weights_1 = LA.norm(item_weights_1, self.norm)\n",
    "        norm_item_weights_2 = LA.norm(item_weights_2, self.norm)\n",
    "        norm_item_weights_3 = LA.norm(item_weights_3, self.norm)\n",
    "        \n",
    "        \n",
    "        if norm_item_weights_1 == 0:\n",
    "            raise ValueError(\"Norm {} of item weights for recommender 1 is zero. Avoiding division by zero\".format(self.norm))\n",
    "        \n",
    "        if norm_item_weights_2 == 0:\n",
    "            raise ValueError(\"Norm {} of item weights for recommender 2 is zero. Avoiding division by zero\".format(self.norm))\n",
    "            \n",
    "        if norm_item_weights_3 == 0:\n",
    "            raise ValueError(\"Norm {} of item weights for recommender 3 is zero. Avoiding division by zero\".format(self.norm))\n",
    "        \n",
    "        item_weights = item_weights_1 / norm_item_weights_1 * self.alpha + item_weights_2 / norm_item_weights_2 * self.beta + item_weights_3 / norm_item_weights_3 * (1-self.alpha-self.beta)\n",
    "\n",
    "        return item_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68137890",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-10T18:14:57.179292Z",
     "iopub.status.busy": "2021-12-10T18:14:57.174010Z",
     "iopub.status.idle": "2021-12-10T21:51:34.768314Z",
     "shell.execute_reply": "2021-12-10T21:51:34.767672Z",
     "shell.execute_reply.started": "2021-12-09T16:47:56.757308Z"
    },
    "papermill": {
     "duration": 12998.032064,
     "end_time": "2021-12-10T21:51:34.768658",
     "exception": false,
     "start_time": "2021-12-10T18:14:56.736594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.78 sec. Users per second: 343\n",
      "Norm: 1, Alpha: 0.0, Beta: 0.0, Theta: 1.0, Result: 0.22963454317678955\n",
      "*** New best model found! \n",
      "New best model has MAP: 0.22963454317678955 with alpha: 0.0, beta: 0, theta: 1.0, norm: 1\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.52 sec. Users per second: 345\n",
      "Norm: 1, Alpha: 0.0, Beta: 0.1, Theta: 0.9, Result: 0.2310726441145623\n",
      "*** New best model found! \n",
      "New best model has MAP: 0.2310726441145623 with alpha: 0.0, beta: 0, theta: 1.0, norm: 1\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.89 sec. Users per second: 342\n",
      "Norm: 1, Alpha: 0.0, Beta: 0.2, Theta: 0.8, Result: 0.23240333233298366\n",
      "*** New best model found! \n",
      "New best model has MAP: 0.23240333233298366 with alpha: 0.0, beta: 0, theta: 1.0, norm: 1\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.62 sec. Users per second: 344\n",
      "Norm: 1, Alpha: 0.0, Beta: 0.3, Theta: 0.7, Result: 0.2343548054084112\n",
      "*** New best model found! \n",
      "New best model has MAP: 0.2343548054084112 with alpha: 0.0, beta: 0, theta: 1.0, norm: 1\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.61 sec. Users per second: 345\n",
      "Norm: 1, Alpha: 0.0, Beta: 0.4, Theta: 0.6, Result: 0.23621195466315018\n",
      "*** New best model found! \n",
      "New best model has MAP: 0.23621195466315018 with alpha: 0.0, beta: 0, theta: 1.0, norm: 1\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.68 sec. Users per second: 344\n",
      "Norm: 1, Alpha: 0.0, Beta: 0.5, Theta: 0.5, Result: 0.23840348005927736\n",
      "*** New best model found! \n",
      "New best model has MAP: 0.23840348005927736 with alpha: 0.0, beta: 0, theta: 1.0, norm: 1\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.96 sec. Users per second: 341\n",
      "Norm: 1, Alpha: 0.0, Beta: 0.6, Theta: 0.4, Result: 0.2410411301410477\n",
      "*** New best model found! \n",
      "New best model has MAP: 0.2410411301410477 with alpha: 0.0, beta: 0, theta: 1.0, norm: 1\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.74 sec. Users per second: 343\n",
      "Norm: 1, Alpha: 0.0, Beta: 0.7, Theta: 0.30000000000000004, Result: 0.24300950159241863\n",
      "*** New best model found! \n",
      "New best model has MAP: 0.24300950159241863 with alpha: 0.0, beta: 0, theta: 1.0, norm: 1\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.95 sec. Users per second: 342\n",
      "Norm: 1, Alpha: 0.0, Beta: 0.8, Theta: 0.19999999999999996, Result: 0.2438786207482158\n",
      "*** New best model found! \n",
      "New best model has MAP: 0.2438786207482158 with alpha: 0.0, beta: 0, theta: 1.0, norm: 1\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.64 sec. Users per second: 344\n",
      "Norm: 1, Alpha: 0.0, Beta: 0.9, Theta: 0.09999999999999998, Result: 0.2430734891787585\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.68 sec. Users per second: 344\n",
      "Norm: 1, Alpha: 0.0, Beta: 1.0, Theta: 0.0, Result: 0.23818227156513022\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.50 sec. Users per second: 345\n",
      "Norm: 1, Alpha: 0.1, Beta: 0.0, Theta: 0.9, Result: 0.23263481187579868\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.64 sec. Users per second: 344\n",
      "Norm: 1, Alpha: 0.1, Beta: 0.1, Theta: 0.8, Result: 0.23419546457011686\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 41.91 sec. Users per second: 326\n",
      "Norm: 1, Alpha: 0.1, Beta: 0.2, Theta: 0.7, Result: 0.23569507547999446\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.74 sec. Users per second: 343\n",
      "Norm: 1, Alpha: 0.1, Beta: 0.3, Theta: 0.6000000000000001, Result: 0.23763840034523803\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.93 sec. Users per second: 342\n",
      "Norm: 1, Alpha: 0.1, Beta: 0.4, Theta: 0.5, Result: 0.24012859166823727\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.70 sec. Users per second: 344\n",
      "Norm: 1, Alpha: 0.1, Beta: 0.5, Theta: 0.4, Result: 0.24274172151150702\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.92 sec. Users per second: 342\n",
      "Norm: 1, Alpha: 0.1, Beta: 0.6, Theta: 0.30000000000000004, Result: 0.244838713711095\n",
      "*** New best model found! \n",
      "New best model has MAP: 0.244838713711095 with alpha: 0.1, beta: 0, theta: 0.9, norm: 1\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.80 sec. Users per second: 343\n",
      "Norm: 1, Alpha: 0.1, Beta: 0.7, Theta: 0.20000000000000007, Result: 0.24627768414024498\n",
      "*** New best model found! \n",
      "New best model has MAP: 0.24627768414024498 with alpha: 0.1, beta: 0, theta: 0.9, norm: 1\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.87 sec. Users per second: 342\n",
      "Norm: 1, Alpha: 0.1, Beta: 0.8, Theta: 0.09999999999999998, Result: 0.24657500657207462\n",
      "*** New best model found! \n",
      "New best model has MAP: 0.24657500657207462 with alpha: 0.1, beta: 0, theta: 0.9, norm: 1\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.66 sec. Users per second: 344\n",
      "Norm: 1, Alpha: 0.1, Beta: 0.9, Theta: 0.0, Result: 0.2446864015037838\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.68 sec. Users per second: 344\n",
      "Norm: 1, Alpha: 0.2, Beta: 0.0, Theta: 0.8, Result: 0.23494100253810063\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.70 sec. Users per second: 344\n",
      "Norm: 1, Alpha: 0.2, Beta: 0.1, Theta: 0.7000000000000001, Result: 0.23669290843994145\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.91 sec. Users per second: 342\n",
      "Norm: 1, Alpha: 0.2, Beta: 0.2, Theta: 0.6000000000000001, Result: 0.23856305062940686\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.96 sec. Users per second: 342\n",
      "Norm: 1, Alpha: 0.2, Beta: 0.3, Theta: 0.5, Result: 0.2409766511030626\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.94 sec. Users per second: 342\n",
      "Norm: 1, Alpha: 0.2, Beta: 0.4, Theta: 0.4, Result: 0.24352727062294013\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.66 sec. Users per second: 344\n",
      "Norm: 1, Alpha: 0.2, Beta: 0.5, Theta: 0.30000000000000004, Result: 0.2457484750458892\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.86 sec. Users per second: 342\n",
      "Norm: 1, Alpha: 0.2, Beta: 0.6, Theta: 0.20000000000000007, Result: 0.24756092837252197\n",
      "*** New best model found! \n",
      "New best model has MAP: 0.24756092837252197 with alpha: 0.2, beta: 0, theta: 0.8, norm: 1\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.86 sec. Users per second: 342\n",
      "Norm: 1, Alpha: 0.2, Beta: 0.7, Theta: 0.10000000000000009, Result: 0.24832916617230621\n",
      "*** New best model found! \n",
      "New best model has MAP: 0.24832916617230621 with alpha: 0.2, beta: 0, theta: 0.8, norm: 1\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.90 sec. Users per second: 342\n",
      "Norm: 1, Alpha: 0.2, Beta: 0.8, Theta: 0.0, Result: 0.2474143042091516\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.79 sec. Users per second: 343\n",
      "Norm: 1, Alpha: 0.3, Beta: 0.0, Theta: 0.7, Result: 0.2374349684424068\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.57 sec. Users per second: 345\n",
      "Norm: 1, Alpha: 0.3, Beta: 0.1, Theta: 0.6, Result: 0.23941738843175098\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.75 sec. Users per second: 343\n",
      "Norm: 1, Alpha: 0.3, Beta: 0.2, Theta: 0.49999999999999994, Result: 0.24150529895381853\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 40.17 sec. Users per second: 340\n",
      "Norm: 1, Alpha: 0.3, Beta: 0.3, Theta: 0.39999999999999997, Result: 0.24336914241978028\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 40.09 sec. Users per second: 340\n",
      "Norm: 1, Alpha: 0.3, Beta: 0.4, Theta: 0.29999999999999993, Result: 0.24552100272421323\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 40.13 sec. Users per second: 340\n",
      "Norm: 1, Alpha: 0.3, Beta: 0.5, Theta: 0.19999999999999996, Result: 0.24790667478579753\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 40.04 sec. Users per second: 341\n",
      "Norm: 1, Alpha: 0.3, Beta: 0.6, Theta: 0.09999999999999998, Result: 0.248868230471633\n",
      "*** New best model found! \n",
      "New best model has MAP: 0.248868230471633 with alpha: 0.3, beta: 0, theta: 0.7, norm: 1\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.66 sec. Users per second: 344\n",
      "Norm: 1, Alpha: 0.3, Beta: 0.7, Theta: 0.0, Result: 0.24841377437193068\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.77 sec. Users per second: 343\n",
      "Norm: 1, Alpha: 0.4, Beta: 0.0, Theta: 0.6, Result: 0.2401366933504561\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.90 sec. Users per second: 342\n",
      "Norm: 1, Alpha: 0.4, Beta: 0.1, Theta: 0.5, Result: 0.2419715586170962\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.74 sec. Users per second: 343\n",
      "Norm: 1, Alpha: 0.4, Beta: 0.2, Theta: 0.39999999999999997, Result: 0.2435064493577978\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.67 sec. Users per second: 344\n",
      "Norm: 1, Alpha: 0.4, Beta: 0.3, Theta: 0.3, Result: 0.24541377611672993\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.82 sec. Users per second: 343\n",
      "Norm: 1, Alpha: 0.4, Beta: 0.4, Theta: 0.19999999999999996, Result: 0.24792710347121868\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.82 sec. Users per second: 343\n",
      "Norm: 1, Alpha: 0.4, Beta: 0.5, Theta: 0.09999999999999998, Result: 0.24874932534448135\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.69 sec. Users per second: 344\n",
      "Norm: 1, Alpha: 0.4, Beta: 0.6, Theta: 0.0, Result: 0.24902664365858693\n",
      "*** New best model found! \n",
      "New best model has MAP: 0.24902664365858693 with alpha: 0.4, beta: 0, theta: 0.6, norm: 1\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.76 sec. Users per second: 343\n",
      "Norm: 1, Alpha: 0.5, Beta: 0.0, Theta: 0.5, Result: 0.24194499114805412\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.73 sec. Users per second: 343\n",
      "Norm: 1, Alpha: 0.5, Beta: 0.1, Theta: 0.4, Result: 0.24360611807867386\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.85 sec. Users per second: 342\n",
      "Norm: 1, Alpha: 0.5, Beta: 0.2, Theta: 0.3, Result: 0.24531890559242947\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.79 sec. Users per second: 343\n",
      "Norm: 1, Alpha: 0.5, Beta: 0.3, Theta: 0.2, Result: 0.2470681652161574\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.66 sec. Users per second: 344\n",
      "Norm: 1, Alpha: 0.5, Beta: 0.4, Theta: 0.09999999999999998, Result: 0.24849848435148286\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.59 sec. Users per second: 345\n",
      "Norm: 1, Alpha: 0.5, Beta: 0.5, Theta: 0.0, Result: 0.2486369428566774\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.94 sec. Users per second: 342\n",
      "Norm: 1, Alpha: 0.6, Beta: 0.0, Theta: 0.4, Result: 0.24344924031462245\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.73 sec. Users per second: 343\n",
      "Norm: 1, Alpha: 0.6, Beta: 0.1, Theta: 0.30000000000000004, Result: 0.2449645689532832\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.75 sec. Users per second: 343\n",
      "Norm: 1, Alpha: 0.6, Beta: 0.2, Theta: 0.2, Result: 0.24648652201121823\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.77 sec. Users per second: 343\n",
      "Norm: 1, Alpha: 0.6, Beta: 0.3, Theta: 0.10000000000000003, Result: 0.24817278858389807\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.78 sec. Users per second: 343\n",
      "Norm: 1, Alpha: 0.6, Beta: 0.4, Theta: 0.0, Result: 0.24839012653280507\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.77 sec. Users per second: 343\n",
      "Norm: 1, Alpha: 0.7, Beta: 0.0, Theta: 0.30000000000000004, Result: 0.24448797135738412\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.68 sec. Users per second: 344\n",
      "Norm: 1, Alpha: 0.7, Beta: 0.1, Theta: 0.20000000000000004, Result: 0.24605340770828898\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.99 sec. Users per second: 341\n",
      "Norm: 1, Alpha: 0.7, Beta: 0.2, Theta: 0.10000000000000003, Result: 0.2472320454392126\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.93 sec. Users per second: 342\n",
      "Norm: 1, Alpha: 0.7, Beta: 0.3, Theta: 5.551115123125783e-17, Result: 0.2481876397293005\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.90 sec. Users per second: 342\n",
      "Norm: 1, Alpha: 0.8, Beta: 0.0, Theta: 0.19999999999999996, Result: 0.24548773813594965\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.76 sec. Users per second: 343\n",
      "Norm: 1, Alpha: 0.8, Beta: 0.1, Theta: 0.09999999999999995, Result: 0.24646057685373204\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.91 sec. Users per second: 342\n",
      "Norm: 1, Alpha: 0.8, Beta: 0.2, Theta: -5.551115123125783e-17, Result: 0.24739070871399077\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.97 sec. Users per second: 341\n",
      "Norm: 1, Alpha: 0.9, Beta: 0.0, Theta: 0.09999999999999998, Result: 0.24604778945629738\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.76 sec. Users per second: 343\n",
      "Norm: 1, Alpha: 0.9, Beta: 0.1, Theta: -2.7755575615628914e-17, Result: 0.24692799390018375\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 39.68 sec. Users per second: 344\n",
      "Norm: 1, Alpha: 1.0, Beta: 0.0, Theta: 0.0, Result: 0.24585284309141175\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.77 min. Users per second: 82\n",
      "Norm: 2, Alpha: 0.0, Beta: 0.0, Theta: 1.0, Result: 0.22963454317678955\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.73 min. Users per second: 83\n",
      "Norm: 2, Alpha: 0.0, Beta: 0.1, Theta: 0.9, Result: 0.23212158223004034\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.65 min. Users per second: 86\n",
      "Norm: 2, Alpha: 0.0, Beta: 0.2, Theta: 0.8, Result: 0.23462159677002908\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.61 min. Users per second: 87\n",
      "Norm: 2, Alpha: 0.0, Beta: 0.3, Theta: 0.7, Result: 0.23707255338502678\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.61 min. Users per second: 87\n",
      "Norm: 2, Alpha: 0.0, Beta: 0.4, Theta: 0.6, Result: 0.2397148708034678\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.59 min. Users per second: 88\n",
      "Norm: 2, Alpha: 0.0, Beta: 0.5, Theta: 0.5, Result: 0.2420639980551304\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.65 min. Users per second: 86\n",
      "Norm: 2, Alpha: 0.0, Beta: 0.6, Theta: 0.4, Result: 0.24323448175987356\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.62 min. Users per second: 87\n",
      "Norm: 2, Alpha: 0.0, Beta: 0.7, Theta: 0.30000000000000004, Result: 0.24391217613627045\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.62 min. Users per second: 87\n",
      "Norm: 2, Alpha: 0.0, Beta: 0.8, Theta: 0.19999999999999996, Result: 0.24357741323115778\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.62 min. Users per second: 87\n",
      "Norm: 2, Alpha: 0.0, Beta: 0.9, Theta: 0.09999999999999998, Result: 0.242182275054729\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.58 min. Users per second: 88\n",
      "Norm: 2, Alpha: 0.0, Beta: 1.0, Theta: 0.0, Result: 0.23818227156513022\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.62 min. Users per second: 87\n",
      "Norm: 2, Alpha: 0.1, Beta: 0.0, Theta: 0.9, Result: 0.23237156536365103\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.59 min. Users per second: 88\n",
      "Norm: 2, Alpha: 0.1, Beta: 0.1, Theta: 0.8, Result: 0.23467706392244786\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.60 min. Users per second: 87\n",
      "Norm: 2, Alpha: 0.1, Beta: 0.2, Theta: 0.7, Result: 0.23732322280614845\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.60 min. Users per second: 88\n",
      "Norm: 2, Alpha: 0.1, Beta: 0.3, Theta: 0.6000000000000001, Result: 0.2403025277481162\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.60 min. Users per second: 87\n",
      "Norm: 2, Alpha: 0.1, Beta: 0.4, Theta: 0.5, Result: 0.2430030807330022\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.64 min. Users per second: 86\n",
      "Norm: 2, Alpha: 0.1, Beta: 0.5, Theta: 0.4, Result: 0.24447813650840194\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.60 min. Users per second: 87\n",
      "Norm: 2, Alpha: 0.1, Beta: 0.6, Theta: 0.30000000000000004, Result: 0.2453795722451373\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.62 min. Users per second: 87\n",
      "Norm: 2, Alpha: 0.1, Beta: 0.7, Theta: 0.20000000000000007, Result: 0.24555166756232863\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.58 min. Users per second: 88\n",
      "Norm: 2, Alpha: 0.1, Beta: 0.8, Theta: 0.09999999999999998, Result: 0.24491532782442327\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.57 min. Users per second: 88\n",
      "Norm: 2, Alpha: 0.1, Beta: 0.9, Theta: 0.0, Result: 0.24214527078113474\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.62 min. Users per second: 87\n",
      "Norm: 2, Alpha: 0.2, Beta: 0.0, Theta: 0.8, Result: 0.2346541867027728\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.61 min. Users per second: 87\n",
      "Norm: 2, Alpha: 0.2, Beta: 0.1, Theta: 0.7000000000000001, Result: 0.23710423893041516\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.62 min. Users per second: 87\n",
      "Norm: 2, Alpha: 0.2, Beta: 0.2, Theta: 0.6000000000000001, Result: 0.24021617765773662\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.62 min. Users per second: 87\n",
      "Norm: 2, Alpha: 0.2, Beta: 0.3, Theta: 0.5, Result: 0.24303579861765406\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.61 min. Users per second: 87\n",
      "Norm: 2, Alpha: 0.2, Beta: 0.4, Theta: 0.4, Result: 0.245117721571994\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.60 min. Users per second: 87\n",
      "Norm: 2, Alpha: 0.2, Beta: 0.5, Theta: 0.30000000000000004, Result: 0.24637236564467974\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.62 min. Users per second: 87\n",
      "Norm: 2, Alpha: 0.2, Beta: 0.6, Theta: 0.20000000000000007, Result: 0.24723946955791457\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.60 min. Users per second: 87\n",
      "Norm: 2, Alpha: 0.2, Beta: 0.7, Theta: 0.10000000000000009, Result: 0.24686149671163612\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.60 min. Users per second: 87\n",
      "Norm: 2, Alpha: 0.2, Beta: 0.8, Theta: 0.0, Result: 0.24504377990875942\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.65 min. Users per second: 86\n",
      "Norm: 2, Alpha: 0.3, Beta: 0.0, Theta: 0.7, Result: 0.236988247617187\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.63 min. Users per second: 87\n",
      "Norm: 2, Alpha: 0.3, Beta: 0.1, Theta: 0.6, Result: 0.23975337269599303\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.62 min. Users per second: 87\n",
      "Norm: 2, Alpha: 0.3, Beta: 0.2, Theta: 0.49999999999999994, Result: 0.24235181133374673\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.62 min. Users per second: 87\n",
      "Norm: 2, Alpha: 0.3, Beta: 0.3, Theta: 0.39999999999999997, Result: 0.24515141363595197\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.62 min. Users per second: 87\n",
      "Norm: 2, Alpha: 0.3, Beta: 0.4, Theta: 0.29999999999999993, Result: 0.2470596098862629\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.62 min. Users per second: 87\n",
      "Norm: 2, Alpha: 0.3, Beta: 0.5, Theta: 0.19999999999999996, Result: 0.24816241575529893\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.62 min. Users per second: 87\n",
      "Norm: 2, Alpha: 0.3, Beta: 0.6, Theta: 0.09999999999999998, Result: 0.24827389094775124\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.61 min. Users per second: 87\n",
      "Norm: 2, Alpha: 0.3, Beta: 0.7, Theta: 0.0, Result: 0.24688830845250326\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.62 min. Users per second: 87\n",
      "Norm: 2, Alpha: 0.4, Beta: 0.0, Theta: 0.6, Result: 0.23959186249124748\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.61 min. Users per second: 87\n",
      "Norm: 2, Alpha: 0.4, Beta: 0.1, Theta: 0.5, Result: 0.24190252274635987\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.63 min. Users per second: 87\n",
      "Norm: 2, Alpha: 0.4, Beta: 0.2, Theta: 0.39999999999999997, Result: 0.24416705343039152\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.59 min. Users per second: 88\n",
      "Norm: 2, Alpha: 0.4, Beta: 0.3, Theta: 0.3, Result: 0.24691076110448124\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.61 min. Users per second: 87\n",
      "Norm: 2, Alpha: 0.4, Beta: 0.4, Theta: 0.19999999999999996, Result: 0.24843294098625285\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.63 min. Users per second: 86\n",
      "Norm: 2, Alpha: 0.4, Beta: 0.5, Theta: 0.09999999999999998, Result: 0.24871520871282768\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.61 min. Users per second: 87\n",
      "Norm: 2, Alpha: 0.4, Beta: 0.6, Theta: 0.0, Result: 0.24806927258176706\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.64 min. Users per second: 86\n",
      "Norm: 2, Alpha: 0.5, Beta: 0.0, Theta: 0.5, Result: 0.2416650672678086\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.59 min. Users per second: 88\n",
      "Norm: 2, Alpha: 0.5, Beta: 0.1, Theta: 0.4, Result: 0.2440003495413504\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.60 min. Users per second: 88\n",
      "Norm: 2, Alpha: 0.5, Beta: 0.2, Theta: 0.3, Result: 0.24610915984450382\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.62 min. Users per second: 87\n",
      "Norm: 2, Alpha: 0.5, Beta: 0.3, Theta: 0.2, Result: 0.24842952699668955\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.61 min. Users per second: 87\n",
      "Norm: 2, Alpha: 0.5, Beta: 0.4, Theta: 0.09999999999999998, Result: 0.24873616083787467\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.63 min. Users per second: 86\n",
      "Norm: 2, Alpha: 0.5, Beta: 0.5, Theta: 0.0, Result: 0.24863066739715617\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.63 min. Users per second: 87\n",
      "Norm: 2, Alpha: 0.6, Beta: 0.0, Theta: 0.4, Result: 0.24312979674257834\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.65 min. Users per second: 86\n",
      "Norm: 2, Alpha: 0.6, Beta: 0.1, Theta: 0.30000000000000004, Result: 0.245311097618001\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.63 min. Users per second: 87\n",
      "Norm: 2, Alpha: 0.6, Beta: 0.2, Theta: 0.2, Result: 0.24761114658868516\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.60 min. Users per second: 88\n",
      "Norm: 2, Alpha: 0.6, Beta: 0.3, Theta: 0.10000000000000003, Result: 0.2487747296143534\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.62 min. Users per second: 87\n",
      "Norm: 2, Alpha: 0.6, Beta: 0.4, Theta: 0.0, Result: 0.24899772652722152\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.61 min. Users per second: 87\n",
      "Norm: 2, Alpha: 0.7, Beta: 0.0, Theta: 0.30000000000000004, Result: 0.2442342049184715\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.59 min. Users per second: 88\n",
      "Norm: 2, Alpha: 0.7, Beta: 0.1, Theta: 0.20000000000000004, Result: 0.24647500052343946\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.64 min. Users per second: 86\n",
      "Norm: 2, Alpha: 0.7, Beta: 0.2, Theta: 0.10000000000000003, Result: 0.24833613664333387\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.61 min. Users per second: 87\n",
      "Norm: 2, Alpha: 0.7, Beta: 0.3, Theta: 5.551115123125783e-17, Result: 0.2486127221419619\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.62 min. Users per second: 87\n",
      "Norm: 2, Alpha: 0.8, Beta: 0.0, Theta: 0.19999999999999996, Result: 0.24538617921642336\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.60 min. Users per second: 87\n",
      "Norm: 2, Alpha: 0.8, Beta: 0.1, Theta: 0.09999999999999995, Result: 0.24700055135640728\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.63 min. Users per second: 86\n",
      "Norm: 2, Alpha: 0.8, Beta: 0.2, Theta: -5.551115123125783e-17, Result: 0.24811739703942534\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.62 min. Users per second: 87\n",
      "Norm: 2, Alpha: 0.9, Beta: 0.0, Theta: 0.09999999999999998, Result: 0.24600140979739388\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.61 min. Users per second: 87\n",
      "Norm: 2, Alpha: 0.9, Beta: 0.1, Theta: -2.7755575615628914e-17, Result: 0.24724584098136748\n",
      "----\n",
      "EvaluatorHoldout: Processed 13646 (100.0%) in 2.59 min. Users per second: 88\n",
      "Norm: 2, Alpha: 1.0, Beta: 0.0, Theta: 0.0, Result: 0.24585284309141175\n",
      "----\n",
      "Best model has MAP: 0.24902664365858693 with alpha: 0.4, beta: 0, norm: 1\n"
     ]
    }
   ],
   "source": [
    "recommender_object = DifferentLossScoresHybridRecommender(URM_train, recommender_SLIMElasticNet, recommender_SLIM_BPR_Cython, recommender_pureSVD)\n",
    "\n",
    "best_model = {\n",
    "    \"MAP\" : 0,\n",
    "    \"alpha\" : 0,\n",
    "    \"beta\" : 0,\n",
    "    \"norm\" : 0\n",
    "}\n",
    "\n",
    "for norm in [1,2]:\n",
    "    for alpha in np.arange(0.0, 1.1, 0.1):\n",
    "        for beta in np.arange(0.0, 1.1, 0.1):\n",
    "            \n",
    "            #truncate digits since np.arange sometimes doesn't\n",
    "            alpha = round(alpha,1)\n",
    "            beta = round(beta,1)\n",
    "            \n",
    "            \n",
    "            #discard cases in which the sum is greater than 1 \n",
    "            if ( (alpha+beta) <= 1): \n",
    "                theta = round(1-alpha-beta,1)\n",
    "            \n",
    "                print(\"----\")\n",
    "                recommender_object.fit(norm, alpha, beta)\n",
    "                result_df, _ = evaluator_valid.evaluateRecommender(recommender_object)\n",
    "                print(\"Norm: {}, Alpha: {}, Beta: {}, Theta: {}, Result: {}\".format(norm, alpha, beta, 1-alpha-beta, result_df.loc[10][\"MAP\"]))\n",
    "\n",
    "                if result_df.loc[10][\"MAP\"] > best_model[\"MAP\"]:\n",
    "                    best_model[\"MAP\"] = result_df.loc[10][\"MAP\"]\n",
    "                    best_model[\"alpha\"] = alpha\n",
    "                    best_model[\"norm\"] = norm\n",
    "\n",
    "                    print(\"*** New best model found! \")\n",
    "                    print(\"New best model has MAP: {} with alpha: {}, beta: {}, theta: {}, norm: {}\".format(best_model[\"MAP\"], best_model[\"alpha\"], best_model[\"beta\"],\n",
    "                                                                                                            1-best_model[\"alpha\"]-best_model[\"beta\"], best_model[\"norm\"]))\n",
    "\n",
    "print(\"----\")\n",
    "print(\"Best model has MAP: {} with alpha: {}, beta: {}, norm: {}\".format(best_model[\"MAP\"], best_model[\"alpha\"], best_model[\"beta\"], best_model[\"norm\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ff99702",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-10T21:51:35.828385Z",
     "iopub.status.busy": "2021-12-10T21:51:35.827707Z",
     "iopub.status.idle": "2021-12-10T21:51:35.830436Z",
     "shell.execute_reply": "2021-12-10T21:51:35.829923Z",
     "shell.execute_reply.started": "2021-12-09T21:19:43.777793Z"
    },
    "papermill": {
     "duration": 0.521953,
     "end_time": "2021-12-10T21:51:35.830587",
     "exception": false,
     "start_time": "2021-12-10T21:51:35.308634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#recommender_SLIMElasticNet = SLIMElasticNetRecommender(URM_all)\n",
    "#recommender_SLIMElasticNet.fit(epochs = 500, l1_ratio = 0.0023170159712850467, alpha = 0.09078974149197175, \n",
    "                #positive_only = True, topK = 363)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e16d1135",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-10T21:51:36.857491Z",
     "iopub.status.busy": "2021-12-10T21:51:36.856742Z",
     "iopub.status.idle": "2021-12-10T21:51:36.859680Z",
     "shell.execute_reply": "2021-12-10T21:51:36.859137Z",
     "shell.execute_reply.started": "2021-12-09T22:21:29.418482Z"
    },
    "papermill": {
     "duration": 0.514001,
     "end_time": "2021-12-10T21:51:36.859830",
     "exception": false,
     "start_time": "2021-12-10T21:51:36.345829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#recommender_SLIM_BPR_Cython = SLIM_BPR_Cython(URM_all)\n",
    "#recommender_SLIM_BPR_Cython.fit(epochs=650, sgd_mode = \"sgd\", topK = 483, lambda_i = 0.0006712905081189398, \n",
    "                #lambda_j = 0.06584150350451998, learning_rate = 0.0036482363905043207)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "150b61ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-10T21:51:37.885956Z",
     "iopub.status.busy": "2021-12-10T21:51:37.885245Z",
     "iopub.status.idle": "2021-12-10T21:51:37.888421Z",
     "shell.execute_reply": "2021-12-10T21:51:37.887748Z",
     "shell.execute_reply.started": "2021-12-09T22:21:29.42075Z"
    },
    "papermill": {
     "duration": 0.513339,
     "end_time": "2021-12-10T21:51:37.888565",
     "exception": false,
     "start_time": "2021-12-10T21:51:37.375226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#recommender_pureSVD = PureSVDRecommender(URM_all)\n",
    "#recommender_pureSVD.fit(num_factors=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "517a2935",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-10T21:51:38.918033Z",
     "iopub.status.busy": "2021-12-10T21:51:38.917263Z",
     "iopub.status.idle": "2021-12-10T21:51:38.919094Z",
     "shell.execute_reply": "2021-12-10T21:51:38.919642Z",
     "shell.execute_reply.started": "2021-12-09T22:21:29.422953Z"
    },
    "papermill": {
     "duration": 0.521111,
     "end_time": "2021-12-10T21:51:38.919816",
     "exception": false,
     "start_time": "2021-12-10T21:51:38.398705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#recommender = DifferentLossScoresHybridRecommender(URM_all, recommender_SLIMElasticNet, recommender_SLIM_BPR_Cython, recommender_pureSVD)\n",
    "#recommender.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83eb2314",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-10T21:51:39.952205Z",
     "iopub.status.busy": "2021-12-10T21:51:39.951363Z",
     "iopub.status.idle": "2021-12-10T21:51:39.954192Z",
     "shell.execute_reply": "2021-12-10T21:51:39.954826Z",
     "shell.execute_reply.started": "2021-12-09T22:21:29.425084Z"
    },
    "papermill": {
     "duration": 0.521273,
     "end_time": "2021-12-10T21:51:39.955120",
     "exception": false,
     "start_time": "2021-12-10T21:51:39.433847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test_users = pd.read_csv('../input/recommender-system-2021-challenge-polimi/data_target_users_test.csv')\n",
    "#test_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9786da9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-10T21:51:40.999145Z",
     "iopub.status.busy": "2021-12-10T21:51:40.998368Z",
     "iopub.status.idle": "2021-12-10T21:51:41.001185Z",
     "shell.execute_reply": "2021-12-10T21:51:41.001730Z",
     "shell.execute_reply.started": "2021-12-09T22:21:29.426786Z"
    },
    "papermill": {
     "duration": 0.518687,
     "end_time": "2021-12-10T21:51:41.001914",
     "exception": false,
     "start_time": "2021-12-10T21:51:40.483227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#user_id = test_users['user_id']\n",
    "#recommendations = []\n",
    "#for user in user_id:\n",
    "    #recommendations.append(recommender.recommend(user,cutoff = 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e27b04d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-10T21:51:42.030211Z",
     "iopub.status.busy": "2021-12-10T21:51:42.029555Z",
     "iopub.status.idle": "2021-12-10T21:51:42.031183Z",
     "shell.execute_reply": "2021-12-10T21:51:42.031679Z",
     "shell.execute_reply.started": "2021-12-09T22:21:29.427996Z"
    },
    "papermill": {
     "duration": 0.522742,
     "end_time": "2021-12-10T21:51:42.031854",
     "exception": false,
     "start_time": "2021-12-10T21:51:41.509112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#for index in range(len(recommendations)):\n",
    "    #recommendations[index]=np.array(recommendations[index])\n",
    "    \n",
    "#test_users['item_list']= recommendations\n",
    "#test_users['item_list'] = pd.DataFrame([str(line).strip('[').strip(']').replace(\"'\",\"\") for line in test_users['item_list']])\n",
    "#test_users.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17243.318409,
   "end_time": "2021-12-10T21:51:43.593578",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-12-10T17:04:20.275169",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
